{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8e514422-4482-44d2-9ec3-dc737eea0161",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlagEmbedding import BGEM3FlagModel, FlagReranker\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import MarkdownTextSplitter\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import tempfile\n",
    "import pymupdf4llm\n",
    "import arxiv\n",
    "import requests\n",
    "import re\n",
    "import shutil\n",
    "from typing import Optional, Tuple, List\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from rouge_score import rouge_scorer, scoring\n",
    "from sacrebleu import corpus_bleu, BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2dbee3e-7c0c-4119-93cf-ff039cf4abce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 35.35533905932737\n"
     ]
    }
   ],
   "source": [
    "references = [\"Это эталонная суммаризация.\"]\n",
    "hypotheses = [\"Это сгенерированная суммаризация.\"]\n",
    "bleu = sacrebleu.corpus_bleu(hypotheses, [references], tokenize='intl')\n",
    "print(\"BLEU:\", bleu.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdec4d8-9631-485b-9fd2-858cfaef5bca",
   "metadata": {},
   "source": [
    "# Оценка Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc508a14-7c85-4458-9631-d354bc8c63ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_arxiv_id(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Извлекает arXiv ID из URL.\n",
    "\n",
    "    Args:\n",
    "        url (str): Ссылка на статью arXiv.\n",
    "\n",
    "    Returns:\n",
    "        str: Извлечённый ID или None, если не удалось.\n",
    "    \"\"\"\n",
    "    match = re.search(r'arxiv\\.org/(abs|pdf)/([0-9]+\\.[0-9]+)(v\\d+)?', url)\n",
    "    return match.group(2) if match else None\n",
    "\n",
    "\n",
    "def download_pdf(arxiv_id: str, save_path: str = \"article.pdf\") -> str:\n",
    "    \"\"\"\n",
    "    Скачивает PDF-файл по arXiv ID и сохраняет на диск.\n",
    "\n",
    "    Args:\n",
    "        arxiv_id (str): Идентификатор статьи на arXiv.\n",
    "        save_path (str): Путь, по которому сохранить файл.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[str, str]: Путь до сохранённого файла и название статьи.\n",
    "    \"\"\"\n",
    "    client = arxiv.Client()\n",
    "    search = arxiv.Search(id_list=[arxiv_id])\n",
    "    result = next(client.results(search))\n",
    "    pdf_url = result.pdf_url\n",
    "\n",
    "    response = requests.get(pdf_url)\n",
    "    with open(save_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    return save_path, result.title\n",
    "    \n",
    "\n",
    "def trim_markdown_after_section(md_text: str, section=\"references\", aliases: Optional[List[str]] = None) -> str:\n",
    "    \"\"\"\n",
    "    Удаляет всё из markdown-текста начиная с указанной секции (по умолчанию — References).\n",
    "\n",
    "    Args:\n",
    "        md_text (str): Исходный Markdown.\n",
    "        section (str): Основной заголовок для поиска.\n",
    "        aliases (List[str]): Альтернативные варианты заголовка.\n",
    "\n",
    "    Returns:\n",
    "        str: Markdown до найденного заголовка.\n",
    "    \"\"\"\n",
    "    all_keys = [section.lower()] + [a.lower() for a in aliases or []]\n",
    "\n",
    "    pattern = re.compile(\n",
    "        rf'^#+\\s*\\**({\"|\".join(map(re.escape, all_keys))})\\**.*$',\n",
    "        re.IGNORECASE | re.MULTILINE\n",
    "    )\n",
    "    match = pattern.search(md_text)\n",
    "    return md_text[:match.start()] if match else md_text\n",
    "\n",
    "\n",
    "def clean_markdown_for_rag(md_raw: str) -> str:\n",
    "    \"\"\"\n",
    "    Очищает markdown от визуального мусора, лишних символов и пустых строк.\n",
    "\n",
    "    Args:\n",
    "        md_text (str): Исходный Markdown текст.\n",
    "\n",
    "    Returns:\n",
    "        str: Очищенный и нормализованный Markdown.\n",
    "    \"\"\"\n",
    "    lines = md_raw.splitlines()\n",
    "    cleaned_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        stripped = line.strip()\n",
    "\n",
    "        if stripped == \"-----\":\n",
    "            continue\n",
    "\n",
    "        if re.fullmatch(r'[\\d\\s\\.,%]+', stripped):\n",
    "            continue\n",
    "\n",
    "        line = re.sub(r'\\*\\[(,|\\*|\\d+)\\]\\*', '', line)\n",
    "        line = re.sub(r'\\*(,+|\\s*[,\\.])\\*', '', line)\n",
    "        line = re.sub(r'^(#{1,6})\\s*\\*\\*(.*?)\\*\\*\\s*$', r'\\1 \\2', line)\n",
    "        line = re.sub(r'\\*{3,}', '**', line)\n",
    "        line = re.sub(r'\\s{2,}', ' ', line)\n",
    "\n",
    "        cleaned_lines.append(line)\n",
    "\n",
    "    # Склеиваем обратно и нормализуем множественные пустые строки\n",
    "    cleaned_text = \"\\n\".join(cleaned_lines)\n",
    "\n",
    "    # Заменяем 3+ пустых строк подряд на 2\n",
    "    cleaned_text = re.sub(r'\\n{3,}', '\\n\\n', cleaned_text)\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "def extract_section(md_text: str, section: str, aliases: Optional[List[str]] = None) -> str:\n",
    "    \"\"\"\n",
    "    Извлекает текст секции по заголовку, учитывая альтернативные варианты.\n",
    "\n",
    "    Args:\n",
    "        md_text (str): Markdown-документ.\n",
    "        section (str): Название секции.\n",
    "        aliases (List[str]): Возможные альтернативы (например, 'summary' для 'abstract').\n",
    "\n",
    "    Returns:\n",
    "        str: Извлечённый текст секции.\n",
    "    \"\"\"\n",
    "    lines = md_text.splitlines()\n",
    "    start_idx, end_idx = None, None\n",
    "\n",
    "    all_keys = [section.lower()] + [a.lower() for a in aliases or []]\n",
    "\n",
    "    # 1. Найдём заголовок секции\n",
    "    for i, line in enumerate(lines):\n",
    "        line_clean = re.sub(r'[\\*\\#]', '', line).strip().lower()\n",
    "        for key in all_keys:\n",
    "            if re.match(rf'^(\\d+[\\.\\d+]*)?\\s*{re.escape(key)}$', line_clean):\n",
    "                start_idx = i + 1\n",
    "                break\n",
    "        if start_idx:\n",
    "            break\n",
    "\n",
    "    if start_idx is None:\n",
    "        return \"\"\n",
    "\n",
    "    # 2. Поиск конца секции — следующего заголовка\n",
    "    for j in range(start_idx, len(lines)):\n",
    "        next_line_clean = re.sub(r'[\\*\\#]', '', lines[j]).strip().lower()\n",
    "        if re.match(r'^(\\d+[\\.\\d+]*)?\\s+\\w+', next_line_clean):\n",
    "            end_idx = j\n",
    "            break\n",
    "\n",
    "    section_lines = lines[start_idx:end_idx] if end_idx else lines[start_idx:]\n",
    "    return \"\\n\".join(section_lines).strip()\n",
    "\n",
    "\n",
    "\n",
    "def split_into_documents(md_cleaned: str, arxiv_id: str, title: str):\n",
    "    splitter = MarkdownTextSplitter(chunk_size=800, chunk_overlap=100)\n",
    "    docs = splitter.create_documents([md_cleaned])\n",
    "    for doc in docs:\n",
    "        doc.metadata = {\"arxiv_id\": arxiv_id, \"title\": title}\n",
    "    return docs\n",
    "\n",
    "\n",
    "\n",
    "def get_vector_store(docs, persist_directory=\"test_chroma_db\"):\n",
    "    model_name = \"BAAI/bge-m3\"\n",
    "    embedding_model = HuggingFaceBgeEmbeddings(model_name=model_name, model_kwargs={\"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"})\n",
    "    vectordb = Chroma.from_documents(documents=docs, embedding=embedding_model, persist_directory=persist_directory)\n",
    "    return vectordb\n",
    "\n",
    "\n",
    "\n",
    "def retrieve_and_rerank(question, vectordb, arxiv_id, top_k=5, top_n=2):\n",
    "    \"\"\"\n",
    "    Извлекает top_k кандидатов из Chroma и реранжирует их с помощью FlagReranker.\n",
    "    Возвращает top_n наиболее релевантных фрагментов.\n",
    "    \n",
    "    :param question: Вопрос пользователя\n",
    "    :param vectordb: Объект Chroma\n",
    "    :param top_k: Сколько фрагментов извлекать из Chroma\n",
    "    :param top_n: Сколько лучших возвращать после rerank\n",
    "    :return: Список кортежей (Document, score)\n",
    "    \"\"\"\n",
    "    retriever = vectordb.as_retriever(search_kwargs={\"k\": top_k, \"filter\": {\"arxiv_id\": arxiv_id}})\n",
    "    candidates = retriever.get_relevant_documents(question)\n",
    "\n",
    "    reranker = FlagReranker(\"BAAI/bge-reranker-v2-m3\", use_fp16=True)\n",
    "    pairs = [[question, doc.page_content] for doc in candidates]\n",
    "    scores = reranker.compute_score(pairs, normalize=True)\n",
    "\n",
    "    reranked = sorted(zip(candidates, scores), key=lambda x: -x[1])\n",
    "    \n",
    "    # print(\"🔍 Rerank результаты:\")\n",
    "    # for i, (doc, score) in enumerate(reranked):\n",
    "    #     print(f\"#Чанк{i+1} — {doc.page_content}...\")\n",
    "\n",
    "    return reranked[:top_n]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f25677c-6ba1-4061-893b-d775ad0f3f77",
   "metadata": {},
   "source": [
    "### Статья Attention is all you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3471f94-5922-4ca7-a944-f34d07de93ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# скачиваем и сохраняем статью attention is all you need\n",
    "arxiv_url = \"https://arxiv.org/abs/1706.03762\"\n",
    "arxiv_id = extract_arxiv_id(arxiv_url)\n",
    "\n",
    "pdf_path = f'./articles/{arxiv_id}.pdf'\n",
    "pdf_path, title = download_pdf(arxiv_id, pdf_path)\n",
    "md_raw = pymupdf4llm.to_markdown(pdf_path)\n",
    "md_trimmed = trim_markdown_after_section(md_raw)\n",
    "md_cleaned = clean_markdown_for_rag(md_trimmed)\n",
    "abstract = extract_section(md_cleaned, \"abstract\", [\"absctract\", \"summary\"])\n",
    "conclusion = extract_section(md_cleaned, \"conclusion\", [\"conclusions\", \"closing remarks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ae591c7-c24a-4c2d-bdb3-b75f572e6293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# разбиваем на чанки\n",
    "docs = split_into_documents(md_cleaned, arxiv_id, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c4ac3eb-e5a6-4cbb-8474-2637ad28a8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_12204\\2220767186.py:168: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceBgeEmbeddings(model_name=model_name, model_kwargs={\"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"})\n"
     ]
    }
   ],
   "source": [
    "# добавляем в бд\n",
    "vectordb = get_vector_store(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91bd0bba-8fa5-4806-a0b5-c4af4287d147",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['Какой оптимайзер и гиперпараметры использовались в модели?',\n",
    "            'Какие архитектурные компоненты заменяет Transformer в традиционных sequence-to-sequence моделях?',\n",
    "             'Что такое Scaled Dot-Product Attention и зачем в нем используется деление на √dk?',\n",
    "             'Как устроена структура encoder и decoder в Transformer?',\n",
    "             'Почему Multi-Head Attention улучшает производительность по сравнению с одной головой внимания?',\n",
    "             'Какие функции выполняют позиционные кодировки и почему были выбраны синусоиды?',\n",
    "             'В чем преимущества self-attention по сравнению с рекуррентными и сверточными слоями в плане вычислительной сложности и длины пути зависимостей?',\n",
    "             'Какие техники регуляризации использовались при обучении Transformer?',\n",
    "             'Какие результаты Transformer показал на задачах перевода EN→DE и EN→FR по сравнению с предыдущими SOTA?',\n",
    "             'Почему Transformer позволяет более эффективную параллелизацию при обучении?'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8501cbda-f5ae-49b2-9c87-3712441f3a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Почему Transformer позволяет более эффективную параллелизацию при обучении?\n",
      "\n",
      "Чанк 1: Attention mechanisms have become an integral part of compelling sequence modeling and transduction models in various tasks, allowing modeling of dependencies without regard to their distance in\n",
      "the input or output sequences [ 2, 19 ]. In all but a few cases [ 27 ], however, such attention mechanisms\n",
      "are used in conjunction with a recurrent network.\n",
      "\n",
      "In this work we propose the Transformer, a model architecture eschewing recurrence and instead\n",
      "relying entirely on an attention mechanism to draw global dependencies between input and output.\n",
      "The Transformer allows for significantly more parallelization and can reach a new state of the art in\n",
      "translation quality after being trained for as little as twelve hours on eight P100 GPUs.\n",
      "### 2 Background\n",
      "\n",
      "Чанк 2: [ 16 ], ByteNet [ 18 ] and ConvS2S [ 9 ], all of which use convolutional neural networks as basic building\n",
      "block, computing hidden representations in parallel for all input and output positions. In these models,\n",
      "the number of operations required to relate signals from two arbitrary input or output positions grows\n",
      "in the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\n",
      "it more difficult to learn dependencies between distant positions [ 12 ]. In the Transformer this is\n",
      "reduced to a constant number of operations, albeit at the cost of reduced effective resolution due\n",
      "to averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\n",
      "described in section 3.2.\n"
     ]
    }
   ],
   "source": [
    "n=9\n",
    "user_question = questions[n]\n",
    "top_chunks = retrieve_and_rerank(user_question, vectordb, arxiv_id, top_k=10, top_n=2)\n",
    "context = f'Вопрос: {user_question}' + \"\\n\\n\" + \"\\n\\n\".join(f'Чанк {i+1}: {doc.page_content}' for i, (doc, _) in enumerate(top_chunks))\n",
    "\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1472563d-a1a1-4b57-b49d-30bc7bb34407",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_marks_1 = [1, 1, 1, 1, 1, 1, 1, 0, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8aea281b-4d34-4519-8749-b29a3b4cc129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка ретривера на 10 вопросах: 90.0%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(f\"Оценка ретривера на 10 вопросах: {np.mean(vector_marks_1) * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258cc944-ed3e-4058-a62a-a6329b121d7e",
   "metadata": {},
   "source": [
    "### Статья TTRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "99530d54-2fad-40ac-8937-1ff2f840162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# скачиваем и сохраняем статью \n",
    "arxiv_url = \"https://arxiv.org/pdf/2504.16084\"\n",
    "arxiv_id = extract_arxiv_id(arxiv_url)\n",
    "\n",
    "pdf_path = f'./articles/{arxiv_id}.pdf'\n",
    "pdf_path, title = download_pdf(arxiv_id, pdf_path)\n",
    "md_raw = pymupdf4llm.to_markdown(pdf_path)\n",
    "md_trimmed = trim_markdown_after_section(md_raw)\n",
    "md_cleaned = clean_markdown_for_rag(md_trimmed)\n",
    "abstract = extract_section(md_cleaned, \"abstract\", [\"absctract\", \"summary\"])\n",
    "conclusion = extract_section(md_cleaned, \"conclusion\", [\"conclusions\", \"closing remarks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "24613245-8249-48f4-9a55-b7366d78d6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# разбиваем на чанки\n",
    "docs = split_into_documents(md_cleaned, arxiv_id, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "120abde3-d43e-48e4-8be2-c4418ef7016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавляем в бд\n",
    "vectordb = get_vector_store(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2546348c-6255-46a9-ab1b-b151c34b2f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['В чем заключается основная идея метода Test-Time Reinforcement Learning (TTRL)?',\n",
    "             'Каким бразом осуществляется оценка вознаграждения в TTRL без доступа к истинным меткам?',\n",
    "             'Какую роль играет метод большинства голосов (majority voting) в архитектуре TTRL?',\n",
    "             'Какие улучшения производительности были достигнуты с помощью TTRL на бенчмарке AIME 2024?',\n",
    "             'Как TTRL сравнивается с RL на размеченных тестовых данных по эффективности?',\n",
    "             'Почему TTRL способен работать даже при неточных оценках меток?',\n",
    "             'Какие модели и бенчмарки использовались для оценки эффективности TTRL?',\n",
    "             'Какие факторы могут привести к сбою или неэффективности TTRL?',\n",
    "             'Как TTRL масштабируется при увеличении размера модели?',\n",
    "             'С какими алгоритмами обучения с подкреплением совместим TTRL и какие из них использовались в экспериментах?'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d4ec9324-46a8-4e15-b0ac-4d3bc8d77ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: С какими алгоритмами обучения с подкреплением совместим TTRL и какие из них использовались в экспериментах?\n",
      "\n",
      "Чанк 1: **TTRL is compatible with different RL algorithms.** Figure 4 presents the results. We\n",
      "apply **TTRL** using PPO (Schulman et al., 2017) on MATH-500 to assess its compatibility\n",
      "with different reinforcement learning algorithms. The performance trajectories of PPO and\n",
      "GRPO are closely aligned. Compared to GRPO, PPO yields more stable outcomes while\n",
      "achieving similar overall performance.\n",
      "\n",
      "**3.3** **Training Dynamics**\n",
      "\n",
      "Чанк 2: In this paper, we propose Test-Time Reinforcement Learning ( **TTRL** ), a novel framework\n",
      "for training large language models with Reinforcement Learning (RL) on test data without\n",
      "access to ground-truth labels. A key component of **TTRL** is its majority voting reward\n",
      "function, which generates rule-based rewards based on consensus among model predictions.\n",
      "Our experiments demonstrate the strong potential of **TTRL**, achieving consistent improvements across a variety of models and tasks. We view **TTRL** as a preliminary step toward\n",
      "RL with self-labeled rewards, marking an important direction of learning from continuous\n",
      "streams of experience.\n",
      "### 7 Limitations and Future Works\n"
     ]
    }
   ],
   "source": [
    "n=9\n",
    "user_question = questions[n]\n",
    "top_chunks = retrieve_and_rerank(user_question, vectordb, arxiv_id, top_k=10, top_n=2)\n",
    "context = f'Вопрос: {user_question}' + \"\\n\\n\" + \"\\n\\n\".join(f'Чанк {i+1}: {doc.page_content}' for i, (doc, _) in enumerate(top_chunks))\n",
    "\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a6369917-6669-450d-b68a-2c1077fd5743",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_marks_2 = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8fda5a67-a1a5-46c2-b997-7b12f3f32d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка ретривера на 10 вопросах: 100.0%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(f\"Оценка ретривера на 10 вопросах: {np.mean(vector_marks_2) * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55e722b-e4f9-451d-9b36-6c2bb7626068",
   "metadata": {},
   "source": [
    "### Статья Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c3cce6a-9d19-42ab-b865-9b6bd8dc1dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# скачиваем и сохраняем статью \n",
    "arxiv_url = \"https://arxiv.org/pdf/2005.11401\"\n",
    "arxiv_id = extract_arxiv_id(arxiv_url)\n",
    "\n",
    "pdf_path = f'./articles/{arxiv_id}.pdf'\n",
    "pdf_path, title = download_pdf(arxiv_id, pdf_path)\n",
    "md_raw = pymupdf4llm.to_markdown(pdf_path)\n",
    "md_trimmed = trim_markdown_after_section(md_raw)\n",
    "md_cleaned = clean_markdown_for_rag(md_trimmed)\n",
    "abstract = extract_section(md_cleaned, \"abstract\", [\"absctract\", \"summary\"])\n",
    "conclusion = extract_section(md_cleaned, \"conclusion\", [\"conclusions\", \"closing remarks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8fec7102-b7f7-4f51-8b7d-527247578a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# разбиваем на чанки\n",
    "docs = split_into_documents(md_cleaned, arxiv_id, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b136450-bd2f-4abe-8a80-ad962704679a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_8780\\737500078.py:150: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceBgeEmbeddings(model_name=model_name, model_kwargs={\"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"})\n"
     ]
    }
   ],
   "source": [
    "# добавляем в бд\n",
    "vectordb = get_vector_store(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e37d219c-fb86-4f97-8ffc-6cc16bce6a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['Какая модель используется в качестве генератора в RAG?',\n",
    "             'Какая модель используется в качестве ретривера в RAG и как она инициализируется?',\n",
    "             'Чем отличаются архитектуры RAG-Token и RAG-Sequence?',\n",
    "             'Какой объем документов используется в векторном индексе Wikipedia?',\n",
    "             'Какие задачи были использованы для оценки RAG-моделей?',\n",
    "             'Почему авторы считают генерацию предпочтительной по сравнению с извлечением при ответе на вопросы?',\n",
    "             'Какую производительность показал RAG на задаче Jeopardy Question Generation по сравнению с BART?',\n",
    "             'Как осуществляется совместное обучение генератора и ретривера в RAG?',\n",
    "             'Какой эффект даёт \"hot-swapping\" индекса документов в RAG?',\n",
    "             'Какие аппроксимации используются при декодировании в RAG-Sequence и RAG-Token?'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "43b53139-2b44-4a37-82e0-d428f53c4943",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие аппроксимации используются при декодировании в RAG-Sequence и RAG-Token?\n",
      "\n",
      "Чанк 1: **2.5** **Decoding**\n",
      "\n",
      "At test time, RAG-Sequence and RAG-Token require different ways to approximate arg max *y* *p* ( *y|x* ) .\n",
      "\n",
      "**RAG-Token** The RAG-Token model can be seen as a standard, autoregressive seq2seq generator with transition probability: *p* *[′]* *θ* [(] *[y]* *[i]* *[|][x, y]* [1:] *[i][−]* [1] [) =][ �] *z∈* top- *k* ( *p* ( *·|x* )) *[p]* *[η]* [(] *[z]* *[i]* *[|][x]* [)] *[p]* *[θ]* [(] *[y]* *[i]* *[|][x, z]* *[i]* *[, y]* [1:] *[i][−]* [1] [)] [ To]\n",
      "\n",
      "decode, we can plug *p* *[′]* *θ* [(] *[y]* *[i]* *[|][x, y]* [1:] *[i][−]* [1] [)][ into a standard beam decoder.]\n",
      "\n",
      "Чанк 2: **2.1** **Models**\n",
      "\n",
      "**RAG-Sequence Model** The RAG-Sequence model uses the same retrieved document to generate\n",
      "the complete *sequence* . Technically, it treats the retrieved document as a single latent variable that\n",
      "is marginalized to get the seq2seq probability *p* ( *y|x* ) via a top-K approximation. Concretely, the\n",
      "top K documents are retrieved using the retriever, and the generator produces the output sequence\n",
      "probability for each document, which are then marginalized,\n",
      "\n",
      "*N*\n",
      "\n",
      "*p* RAG-Sequence ( *y|x* ) *≈* � *p* *η* ( *z|x* ) *p* *θ* ( *y|x, z* ) = � *p* *η* ( *z|x* ) � *p* *θ* ( *y* *i* *|x, z, y* 1: *i−* 1 )\n",
      "\n",
      "*z∈* top- *k* ( *p* ( *·|x* )) *z∈* top- *k* ( *p* ( *·|x* )) *i*\n"
     ]
    }
   ],
   "source": [
    "# тут повторно записал статью поэтому выкидываю дубликаты по чанкам\n",
    "\n",
    "n=9\n",
    "user_question = questions[n]\n",
    "top_chunks = retrieve_and_rerank(user_question, vectordb, arxiv_id, top_k=10, top_n=4)\n",
    "del top_chunks[1:3]\n",
    "context = f'Вопрос: {user_question}' + \"\\n\\n\" + \"\\n\\n\".join(f'Чанк {i+1}: {doc.page_content}' for i, (doc, _) in enumerate(top_chunks))\n",
    "\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "48e5dfc5-c7e0-48a4-b054-6a253a876684",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_marks_3 = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c5e593e8-a60c-4043-a08b-b91bc07cc04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка ретривера на 10 вопросах: 100.0%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(f\"Оценка ретривера на 10 вопросах: {np.mean(vector_marks_3) * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0ba66a-9494-45c7-aa15-0da5699af885",
   "metadata": {},
   "source": [
    "### Статья Efficient Estimation of Word Representations in Vector Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4439fc06-6f2c-422a-8191-53ed72137dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# скачиваем и сохраняем статью \n",
    "arxiv_url = \"https://arxiv.org/pdf/1301.3781\"\n",
    "arxiv_id = extract_arxiv_id(arxiv_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c9ccc07e-a389-4560-aa56-dd2d57cbda0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['Какие две модели архитектур были предложены авторами для обучения векторных представлений слов?',\n",
    "             'В чём основное различие между архитектурами CBOW и Skip-gram?',\n",
    "             'Какие типы отношений включены в Semantic-Syntactic Word Relationship test set?',\n",
    "             'Какие значения точности показала модель Skip-gram на семантических и синтаксических подзадачах?',\n",
    "             'Какой подход используется в Skip-gram модели для выбора контекстных слов?',\n",
    "             'Какова формула вычислительной сложности модели CBOW?',\n",
    "             'Почему авторы отказались от использования скрытого слоя в новых архитектурах?',\n",
    "             'Как масштабировалась тренировка моделей в распределённой системе DistBelief?',\n",
    "             'Как были сгенерированы вопросы в тестовом наборе для оценки word vectors?',\n",
    "             'Какой метод используется для ответа на аналогии вроде “king - man + woman = ?”?'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1aeb5629-81bb-4aca-b49b-9834ebaceb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какой метод используется для ответа на аналогии вроде “king - man + woman = ?”?\n",
      "\n",
      "Чанк 1: Somewhat surprisingly, it was found that similarity of word representations goes beyond simple\n",
      "syntactic regularities. Using a word offset technique where simple algebraic operations are performed on the word vectors, it was shown for example that *vector(”King”) - vector(”Man”) + vec-*\n",
      "*tor(”Woman”)* results in a vector that is closest to the vector representation of the word *Queen* [20].\n",
      "\n",
      "Чанк 2: We evaluate the overall accuracy for all question types, and for each question type separately (semantic, syntactic). Question is assumed to be correctly answered only if the closest word to the\n",
      "vector computed using the above method is exactly the same as the correct word in the question;\n",
      "synonyms are thus counted as mistakes. This also means that reaching 100% accuracy is likely\n",
      "to be impossible, as the current models do not have any input information about word morphology.\n",
      "However, we believe that usefulness of the word vectors for certain applications should be positively\n",
      "correlated with this accuracy metric. Further progress can be achieved by incorporating information\n",
      "about structure of words, especially for the syntactic questions.\n",
      "\n",
      "**4.2** **Maximization of Accuracy**\n"
     ]
    }
   ],
   "source": [
    "# тут повторно записал статью поэтому выкидываю дубликаты по чанкам\n",
    "\n",
    "n=9\n",
    "user_question = questions[n]\n",
    "top_chunks = retrieve_and_rerank(user_question, vectordb, arxiv_id, top_k=10, top_n=2)\n",
    "context = f'Вопрос: {user_question}' + \"\\n\\n\" + \"\\n\\n\".join(f'Чанк {i+1}: {doc.page_content}' for i, (doc, _) in enumerate(top_chunks))\n",
    "\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e3463855-03ff-4a7d-849a-bcd18cfe84fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_marks_4 = [0, 1, 0, 1, 1, 1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "04fcc165-14a1-468f-8a30-3996d3412e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка ретривера на 10 вопросах: 80.0%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(f\"Оценка ретривера на 10 вопросах: {np.mean(vector_marks_4) * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e9ef30-0a54-4dc9-89e4-ab572f5882a0",
   "metadata": {},
   "source": [
    "### Статья LADDER: SELF-IMPROVING LLMS THROUGH RECURSIVE PROBLEM DECOMPOSITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "dcb8da5d-1bd5-4f8e-86fb-53ce05a4284d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# скачиваем и сохраняем статью \n",
    "arxiv_url = \"https://arxiv.org/pdf/2503.00735\"\n",
    "arxiv_id = extract_arxiv_id(arxiv_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "046d1212-21a3-4723-a6b5-fb0e65656ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['В чём заключается ключевая идея фреймворка LADDER?',\n",
    "             'Какой метод используется для верификации правильности решений интегралов в LADDER?',\n",
    "             'Как осуществляется генерация вариантов задач в LADDER?',\n",
    "             'Что такое TTRL и чем он отличается от LADDER?',\n",
    "             'Какие результаты достигнуты моделью Qwen2.5 7B на экзамене MIT Integration Bee после применения LADDER и TTRL?',\n",
    "             'Какая функция вознаграждения используется в GRPO в рамках обучения в LADDER?',\n",
    "             'Почему RL без использования вариантов задач показывает плохие результаты на задачах интегрирования?',\n",
    "             'Какие техники использовались для увеличения разнообразия генерируемых вариантов задач?',\n",
    "             'Как LADDER масштабирует обучение без увеличения размера модели?',\n",
    "             'Какие ограничения или сложности были замечены при генерации вариантов задач?'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a4ead99d-0aec-4b3a-b666-6ba60d3f3aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие ограничения или сложности были замечены при генерации вариантов задач?\n",
      "\n",
      "Чанк 1: Analysis of the remaining unsolved problems reveals nuanced challenges in the model’s mathematical integration\n",
      "capabilities. The model demonstrates difficulty with integrals requiring multiple technique combinations and novel\n",
      "substitution patterns. These complex scenarios highlight limitations in the current approach, suggesting that while the\n",
      "variant generation successfully teaches individual techniques, synthesizing these methods for more intricate problems\n",
      "remains a challenge.\n",
      "\n",
      "Чанк 2: *x* [2] + 1\n",
      "Original problem:\n",
      "� *x* [4] + 2 *x* [2] + 1 *[dx]*\n",
      "\n",
      "*x* [2]\n",
      "Level 1 variant:\n",
      "� *x* [4] + 1 *[dx]*\n",
      "\n",
      "Level 2 variant:\n",
      "� *x* [2] + 1 *[dx]*\n",
      "\n",
      "Level 3 variant:\n",
      "� *x* [2] *[ dx]*\n",
      "\n",
      "Quality control presented a significant challenge in our variant generation process. While we prompted the model to\n",
      "generate \"easier\" or \"equivalent\" variants, the actual difficulty of the resulting integrals often deviated substantially\n",
      "from the intended level. Small perturbations in coefficients or function composition could transform seemingly simple\n",
      "integrals into much harder ones - for instance, changing a coefficient from 1 to 2 in a rational function could introduce\n",
      "complex roots that make the integral significantly more challenging.\n"
     ]
    }
   ],
   "source": [
    "n=9\n",
    "user_question = questions[n]\n",
    "top_chunks = retrieve_and_rerank(user_question, vectordb, arxiv_id, top_k=10, top_n=2)\n",
    "context = f'Вопрос: {user_question}' + \"\\n\\n\" + \"\\n\\n\".join(f'Чанк {i+1}: {doc.page_content}' for i, (doc, _) in enumerate(top_chunks))\n",
    "\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "dc21c587-e5c9-48cb-90fe-38696d621323",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_marks_5 = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "918d1e51-0e4c-4aba-a166-23887e5cecf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка ретривера на 10 вопросах: 100.0%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(f\"Оценка ретривера на 10 вопросах: {np.mean(vector_marks_5) * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aff70d6-95ad-4c81-88c0-89b30eee5ff0",
   "metadata": {},
   "source": [
    "## Оценка ретривера на 5 статьях (50 вопросов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1fe9657f-a73c-43eb-8e98-5a49eefa7d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка ретривера: 94.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Оценка ретривера: {np.mean(vector_marks_1 + vector_marks_2 + vector_marks_3 + vector_marks_4 + vector_marks_5) * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f633ca1-938e-430f-aad3-f81e77ccb158",
   "metadata": {},
   "source": [
    "# Оценка суммаризации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fd6964-1eb4-4b2c-be70-d209db9c861b",
   "metadata": {},
   "source": [
    "## Сбор и загрузка данных в ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c6ebcb1-ee4b-45e0-bf0a-e1f71f516905",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = ['https://arxiv.org/pdf/2504.16084',\n",
    "        'https://arxiv.org/abs/1706.03762',\n",
    "        'https://arxiv.org/pdf/2112.02242',\n",
    "        'https://arxiv.org/pdf/2405.12819',\n",
    "        'https://arxiv.org/pdf/2005.11401',\n",
    "        'https://arxiv.org/pdf/1301.3781',\n",
    "        'https://arxiv.org/pdf/2501.07391',\n",
    "        'https://arxiv.org/pdf/2503.00735',\n",
    "        'https://arxiv.org/pdf/2501.19399',\n",
    "        'https://arxiv.org/pdf/2205.14135']\n",
    "\n",
    "data_lst = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85489ac1-f33b-4591-9ff6-6d65f4b60966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_6364\\737500078.py:150: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceBgeEmbeddings(model_name=model_name, model_kwargs={\"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"})\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:44<00:00, 10.44s/it]\n"
     ]
    }
   ],
   "source": [
    "for arxiv_url in tqdm(urls):\n",
    "    arxiv_id = extract_arxiv_id(arxiv_url)\n",
    "    \n",
    "    pdf_path = f'./articles/{arxiv_id}.pdf'\n",
    "    pdf_path, title = download_pdf(arxiv_id, pdf_path)\n",
    "    md_raw = pymupdf4llm.to_markdown(pdf_path)\n",
    "    md_trimmed = trim_markdown_after_section(md_raw)\n",
    "    md_cleaned = clean_markdown_for_rag(md_trimmed)\n",
    "    abstract = extract_section(md_cleaned, \"abstract\", [\"absctract\", \"summary\"])\n",
    "    conclusion = extract_section(md_cleaned, \"conclusion\", [\"conclusions\", \"closing remarks\"])\n",
    "    \n",
    "    final = abstract + \"\\n\\n\" + conclusion\n",
    "    data_lst.append(final)\n",
    "\n",
    "    docs = split_into_documents(md_cleaned, arxiv_id, title)\n",
    "    vectordb = get_vector_store(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "438e0754-1a09-4db8-9568-9373431c01a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Эталонные суммаризации\n",
    "gt = ['В данной работе представлен метод Test-Time Reinforcement Learning (TTRL) — новый подход к обучению больших языковых моделей (LLMs) с использованием обучения с подкреплением на неразмеченных тестовых данных. Ключевая идея TTRL заключается в применении majority voting для оценки вознаграждения без доступа к истинным меткам. Метод позволяет LLM самостоятельно улучшать свои ответы, опираясь на собственные предсказания. Эксперименты показывают, что TTRL обеспечивает значительный прирост производительности, включая увеличение pass@1 на 159% на AIME 2024, и показывает сопоставимые результаты с моделями, обученными на размеченных данных. Таким образом, TTRL открывает путь к масштабируемому RL с самогенерируемыми наградами и применению в более широком спектре задач.',\n",
    "      'В статье представлен Transformer — первая архитектура для преобразования последовательностей, основанная исключительно на механизме внимания, без рекуррентных и сверточных слоёв. Transformer достигает нового уровня качества в машинном переводе на задачах WMT 2014 (28.4 BLEU для EN→DE и 41.8 BLEU для EN→FR), при этом обучается быстрее и параллелится лучше, чем предыдущие модели. Авторы подчеркивают потенциал архитектуры для широкого применения, включая неречевые модальности, и планируют дальнейшие исследования в области локального внимания и более эффективной генерации',\n",
    "      'В работе предлагается подход к обучению рекомендательных систем с учётом долгосрочной памяти пользователей на основе неявного фидбека. Авторы представляют онлайн-алгоритм, обновляющий модель по пользовательским блокам взаимодействий. Основной вклад заключается в стратегии фильтрации пользователей по стационарности и устойчивости поведения, что позволяет существенно повысить качество рекомендаций (MAP, NDCG) при обучении на сильно сокращенном, но более информативном подмножестве данных. Метод показал значительные улучшения, особенно на больших датасетах',\n",
    "      'Авторы представляют первый систематический обзор применения больших языковых моделей (LLMs) в задачах NLP, предлагая единую таксономию подходов: с замороженными параметрами (parameter-frozen) и с адаптацией (parameter-tuning). Работа также выделяет новые исследовательские направления и вызовы, с целью стимулировать дальнейшие прорывы в области. В дополнение, создан публичный ресурс для отслеживания последних публикаций, что делает обзор не только аналитическим, но и практическим инструментом для исследователей',\n",
    "      'Авторы представляют общий подход к дообучению RAG-моделей, сочетающих параметрическую память (предобученные seq2seq модели) и непараметрическую (векторный индекс Википедии, доступный через нейронный ретривер). Они сравнивают две версии: с фиксированными и токен-зависимыми извлечениями. Модель демонстрирует новое состояние искусства в задачах открытого вопросно-ответного поиска и генерирует более точный и разнообразный текст, чем чисто параметрические seq2seq модели, показывая потенциал RAG в задачах, требующих доступа к знаниям',\n",
    "      'Авторы представляют два простых и эффективных архитектурных подхода — CBOW и Skip-gram — для обучения векторных представлений слов на масштабных корпусах. Эти модели обеспечивают значительное улучшение качества синтаксических и семантических представлений при низких вычислительных затратах, позволяя обучать векторы даже на триллионе слов. Векторы достигают state-of-the-art результатов в задачах оценки семантической близости и находят применение в ряде NLP-задач, включая машинный перевод, анализ тональности и расширение знаний в базах данных. Работа демонстрирует потенциал простых моделей как базового элемента для будущих приложений в NLP',\n",
    "      'В работе представлено систематическое исследование архитектур и компонентов Retrieval-Augmented Generation (RAG) систем. Авторы изучают влияние таких факторов, как размер модели, дизайн промпта, размер чанков, объём базы знаний, стратегии извлечения, query expansion и Contrastive In-Context Learning, в том числе в мультиязычном контексте. Эксперименты показывают, как конфигурации RAG влияют на качество ответов, предлагая практические рекомендации по созданию эффективных и адаптируемых RAG-систем для различных задач. Код и реализации опубликованы в открытом доступе.',\n",
    "      'Авторы представляют LADDER — фреймворк, улучшающий способности языковых моделей к решению задач с помощью рекурсивной декомпозиции, обучения с подкреплением с верифицируемыми наградами и его расширения на инференс — TTRL. Метод позволяет моделям самостоятельно упрощать сложные задачи и обучаться на этих вариантах, достигая прорывных результатов в математических задачах (например, рост точности с 1% до 82% на задачах интегрирования и 90% на MIT Integration Bee). Работа подчёркивает ценность стратегического самообучения, проверяемых наград и тестового самоулучшения, демонстрируя потенциал применения подхода в других доменах, таких как синтез программ и автоматическое доказательство теорем.',\n",
    "      'Scalable-Softmax (SSMax) — это новая замена функции Softmax в слоях внимания Transformer-моделей, разработанная для решения проблемы \"затухания внимания\" при увеличении размера входного контекста. SSMax сохраняет способность модели фокусироваться на ключевой информации даже при длинных входах, улучшая обобщающую способность по длине, скорость сходимости на этапе предобучения и точность извлечения информации. SSMax можно внедрять как с начала обучения, так и на уже предобученные модели, получая стабильные улучшения. Работа показывает, что SSMax — перспективный кандидат для замены Softmax в будущих архитектурах трансформеров, особенно в задачах с длинным контекстом',\n",
    "      'Авторы представляют FlashAttention — IO-ориентированный алгоритм точного внимания, оптимизированный для GPU-архитектур. Он использует тайлинг, чтобы минимизировать количество операций чтения и записи между высокоскоростной памятью (HBM) и локальной SRAM, что значительно ускоряет обучение трансформеров. FlashAttention обеспечивает реальный прирост скорости (до 3× на GPT-2, 15% на BERT-large) без ущерба для качества модели. Расширенная версия с блок-спарсностью опережает существующие приближённые методы по скорости и позволяет моделям работать с контекстами до 64K токенов, впервые демонстрируя выше случайного уровня точности на задачах Path-X и Path-256. Метод открывает путь к более длинным, качественным и эффективным трансформерам']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa961773-7302-40c6-8513-fbe62f64d4b3",
   "metadata": {},
   "source": [
    "## T-Lite-8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06259e57-70b9-4cf0-8652-14a360736815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e37a6c9b13734153b66c22c6baf118fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_27976\\295889804.py:12: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceBgeEmbeddings(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_27976\\295889804.py:19: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(persist_directory=\"test_chroma_db\", embedding_function=embedding_model)\n"
     ]
    }
   ],
   "source": [
    "model_name = \"t-bank-ai/T-lite-instruct-0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "quant_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=quant_config, device_map=\"auto\")\n",
    "\n",
    "llm = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, return_full_text=False)\n",
    "terminators = list({\n",
    "        tokenizer.eos_token_id,\n",
    "        tokenizer.convert_tokens_to_ids(\"<|eot_id|>\") or tokenizer.eos_token_id,\n",
    "    })\n",
    "\n",
    "embedding_model = HuggingFaceBgeEmbeddings(\n",
    "        model_name=\"BAAI/bge-m3\",\n",
    "        model_kwargs={\"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"}\n",
    "    )\n",
    "\n",
    "reranker = FlagReranker(\"BAAI/bge-reranker-v2-m3\", use_fp16=True)\n",
    "\n",
    "vectorstore = Chroma(persist_directory=\"test_chroma_db\", embedding_function=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3611ff-c265-4c82-9899-62013ebc34c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_MSG = (\n",
    "    \"Ты — помощник по научным статьям. \"\n",
    "    \"Сформулируй краткое и точное резюме по тексту ниже.\"\n",
    ")\n",
    "\n",
    "def build_messages(abstract, conclusion) -> list[dict]:\n",
    "    full_text = f\"Abstract:\\n{abstract}\\n\\nConclusion:\\n{conclusion}\"\n",
    "\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_MSG},\n",
    "        {\"role\": \"user\", \"content\": full_text},\n",
    "        {\"role\": \"assistant\", \"content\": \"Краткое резюме:\"},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37ffeefa-8f9f-4de5-8b4a-2a2b24ac3c50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 1/10 [00:19<02:54, 19.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: TTRL: Test-Time Reinforcement Learning\n",
      "\n",
      "Суммаризация:  В статье представлен метод Test-Time Reinforcement Learning ( **TTRL** ), который использует Reinforcement Learning для улучшения больших языковых моделей (LLMs) на основе данных без меток. Основная задача — создание подходящих вознаграждений для обучения на основе консенсуса предсказаний модели. **TTRL** применяет метод большинства голосов для оценки вознаграждений, что показывает значительные улучшения в различных задачах и моделях. В частности, на тесте AIME 2024 **TTRL** увеличивает точность на 159% по сравнению с исходной моделью. Результаты подтверждают эффективность **TTRL** и открывают перспективы для дальнейшего развития самообучающихся систем на основе опыта.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 2/10 [00:41<02:49, 21.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: Attention Is All You Need\n",
      "\n",
      "Суммаризация:  В статье представлен новый архитектурный подход к моделированию последовательностей — Transformer, который полностью основан на механизмах внимания, отказываясь от рекуррентных и свёрточных сетей. В ходе экспериментов на задачах машинного перевода на данных WMT 2014, Transformer показывает значительное улучшение в качестве перевода и скорости обучения по сравнению с традиционными моделями. На англо-немецком направлении модель достигает 28.4 BLEU, превосходя предыдущие результаты, а на англо-французском — 41.8 BLEU, что является новым рекордом для одиночной модели. Авторы также демонстрируют успешное применение Transformer для парсинга текста и подчеркивают перспективы дальнейшего использования и адаптации этой технологии для других задач и данных. \n",
      "\n",
      "Ссылки на код и библиотеку: `https://github.com/tensorflow/tensor2tensor` \n",
      "\n",
      "Авторы благодарят коллег за помощь и поддержку в разработке и тестировании.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 3/10 [00:53<01:59, 17.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: Recommender systems: when memory matters\n",
      "\n",
      "Суммаризация:  В данной работе исследуется влияние долгосрочной памяти на обучение последовательных рекомендательных систем, используя неявные пользовательские данные. Предлагается онлайн-алгоритм, обновляющий параметры модели для каждого пользователя на основе блоков взаимодействий. Эмпирические результаты показывают значительное улучшение метрик MAP и NDCG при обучении на отфильтрованном подмножестве пользователей с высокой степенью долгосрочной памяти в их поведении, что подтверждает эффективность стратегии для крупномасштабных систем.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 4/10 [01:12<01:45, 17.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: Large Language Models Meet NLP: A Survey\n",
      "\n",
      "Суммаризация:  \n",
      "\n",
      "Исследование посвящено анализу использования больших языковых моделей (LLM) в задачах обработки естественного языка (NLP). Оно направлено на систематическое изучение текущих применений и перспектив LLM в этой области. Основные вопросы включают: как модели применяются в NLP, решены ли уже традиционные задачи с их помощью, и какие возможности открываются для будущего. В работе вводится классификация методов: замороженные параметры и настраиваемые параметры, что помогает структурировать существующие подходы. Также рассматриваются новые направления исследований и связанные с ними вызовы. Авторы стремятся предложить полезные данные и рекомендации для дальнейшего прогресса в этой области, а также создать ресурс для отслеживания актуальных достижений.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [01:30<01:28, 17.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\n",
      "\n",
      "Суммаризация:  В статье рассматриваются модели, сочетающие параметрическую и непараметрическую память для генерации текста (RAG). Авторы предлагают два варианта RAG, где параметрическая память — это предобученная seq2seq модель, а непараметрическая — плотный индекс Википедии, доступный через нейронный ретривер. Модели показывают значительное улучшение на задачах, требующих доступа к знаниям, включая задачи вопрос-ответа, превосходя как параметрические, так и специализированные модели. Для генерации текста RAG модели демонстрируют более точные, разнообразные и фактологически корректные результаты по сравнению с чисто параметрическими моделями.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [01:45<01:07, 16.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: Efficient Estimation of Word Representations in Vector Space\n",
      "\n",
      "Суммаризация:  В статье представлены два новых архитектурных решения для создания непрерывных векторных представлений слов на основе больших данных. Эти модели показывают значительное улучшение точности в задачах измерения семантической и синтаксической близости слов по сравнению с предыдущими методами, включая нейронные сети. Векторы обучаются быстрее и с меньшими вычислительными затратами, что позволяет использовать данные на порядки большие, чем ранее. В статье также обсуждаются перспективы применения этих векторов в задачах машинного перевода, анализа настроений и других NLP-задачах, а также их потенциал для улучшения существующих методов и создания новых приложений.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [02:03<00:51, 17.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: Enhancing Retrieval-Augmented Generation: A Study of Best Practices\n",
      "\n",
      "Суммаризация:  \n",
      "\n",
      "В статье рассматриваются и анализируются различные аспекты и конфигурации систем Retrieval-Augmented Generation (RAG), направленные на улучшение их производительности и адаптивности. Исследование охватывает влияние таких факторов, как размер языковой модели, структура запросов, размеры документов и баз знаний, методы запросного расширения, контекстное обучение и мультиязычные базы данных. В ходе экспериментов выявлены оптимальные параметры для повышения точности и контекстуальной релевантности ответов. Результаты работы предоставляют практические рекомендации для создания более эффективных и универсальных RAG систем, что важно для их применения в различных прикладных задачах. Исследование также открывает возможности для дальнейших улучшений в этой области. \n",
      "\n",
      "[1] - ссылка на публичный доступ к коду и материалам исследования.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [02:19<00:33, 16.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: LADDER: Self-Improving LLMs Through Recursive Problem Decomposition\n",
      "\n",
      "Суммаризация:  В статье представлен LADDER — метод, улучшающий способность моделей решать задачи через рекурсивное разложение проблем и обучение с подкреплением на основе верифицируемых вознаграждений. Включение тестового обучения (TTRL) позволило значительно повысить эффективность в решении математических задач, таких как интеграция, достигнув 90% точности на MIT Integration Bee. Работа подчеркивает важность стратегического обучения и использования проверяемых обратных связей для повышения производительности ИИ. Принципы могут быть применены в различных областях, где есть возможность верификации, и способствуют развитию систем, которые могут самостоятельно улучшать свои навыки в сложных задачах.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [02:41<00:18, 18.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: Scalable-Softmax Is Superior for Attention\n",
      "\n",
      "Суммаризация:  В статье представлен Scalable-Softmax (SSMax) — альтернативный подход к использованию функции Softmax в трансформерных моделях для улучшения работы с длинными контекстами и повышения эффективности внимания. SSMax решает проблему \"затухания\" внимания, возникающего при увеличении размера входных данных, и улучшает способность модели удерживать внимание на ключевых элементах информации. \n",
      "\n",
      "### Основные выводы:\n",
      "1. **Проблема Softmax**: Максимальный элемент Softmax уменьшается с ростом размера входного вектора, что ухудшает распределение внимания.\n",
      "2. **SSMax решение**: Предложенная функция SSMax сохраняет внимание на ключевых элементах, даже при больших размерах контекста.\n",
      "3. **Экспериментальные результаты**:\n",
      "   - **Ускорение обучения**: Модели с SSMax быстрее снижают потери во время обучения.\n",
      "   - **Улучшение в длинных контекстах**: SSMax значительно улучшает производительность в длинных последовательностях.\n",
      "   - **\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [03:06<00:00, 18.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness\n",
      "\n",
      "Суммаризация:  \n",
      "FlashAttention — это новый подход к реализации внимания в трансформерах, который решает проблему высокой вычислительной и памяти-затратности на длинных последовательностях. В отличие от традиционных методов, FlashAttention учитывает операции ввода-вывода (IO) между уровнями памяти GPU, что позволяет значительно уменьшить количество обращений к высокоскоростной памяти (HBM) и улучшить производительность. \n",
      "\n",
      "Основные достижения:\n",
      "- FlashAttention обеспечивает до 15% ускорения в тренировке BERT-large и до 3-кратного ускорения для GPT-2 по сравнению с текущими рекордами.\n",
      "- Внедрение в блок-спарсивание внимания позволяет достичь еще большего ускорения и улучшает качество моделей.\n",
      "- Увеличение контекста в моделях приводит к улучшению метрик (перплексии и точности) и новым возможностям, таким как достижение лучших результатов на задачах с длинными последовательностями (Path-X и Path-256).\n",
      "\n",
      "FlashAttention\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "times = []\n",
    "for arxiv_url in tqdm(urls):\n",
    "    arxiv_id = extract_arxiv_id(arxiv_url)\n",
    "    \n",
    "    pdf_path = f'./articles/{arxiv_id}.pdf'\n",
    "    pdf_path, title = download_pdf(arxiv_id, pdf_path)\n",
    "    md_raw = pymupdf4llm.to_markdown(pdf_path)\n",
    "    md_trimmed = trim_markdown_after_section(md_raw)\n",
    "    md_cleaned = clean_markdown_for_rag(md_trimmed)\n",
    "    abstract = extract_section(md_cleaned, \"abstract\", [\"absctract\", \"summary\"])\n",
    "    conclusion = extract_section(md_cleaned, \"conclusion\", [\"conclusions\", \"closing remarks\"])\n",
    "    \n",
    "    messages = build_messages(abstract, conclusion)\n",
    "    start = time.time()\n",
    "\n",
    "    answer = llm(messages, max_new_tokens=256, do_sample=False, eos_token_id=terminators)[0]['generated_text']\n",
    "\n",
    "    end = time.time()\n",
    "    inf_time = end - start\n",
    "    \n",
    "    times.append(inf_time)\n",
    "    print(f'Название статьи: {title}\\n')\n",
    "    print(f'Суммаризация: {answer}\\n\\n')\n",
    "    outputs.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b24fe5e2-964e-4191-baff-abf2acc6c127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14.314668655395508,\n",
       " 17.953752756118774,\n",
       " 9.457916498184204,\n",
       " 13.708330154418945,\n",
       " 13.110188961029053,\n",
       " 12.668460130691528,\n",
       " 15.162318706512451,\n",
       " 12.614119529724121,\n",
       " 19.203843116760254,\n",
       " 18.3269145488739]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f492b366-67e6-423e-8d8b-dd771880a4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее время суммаризации модели Тбанк: 15 сек\n"
     ]
    }
   ],
   "source": [
    "print(f'Среднее время суммаризации модели Тбанк: {np.mean(times):.0f} сек')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eff3c2c0-8900-4fda-8402-60b258e46e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summarization = pd.DataFrame()\n",
    "\n",
    "df_summarization['gt'] = gt\n",
    "df_summarization['Tbank'] = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05171c91-acf5-43d7-805d-f722ed6ff211",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summarization.to_csv('summarize_examples.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97a651e5-0c05-4627-be0b-b6b52a9f5b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gt</th>\n",
       "      <th>Tbank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>В данной работе представлен метод Test-Time Re...</td>\n",
       "      <td>В статье представлен метод Test-Time Reinforc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>В статье представлен Transformer — первая архи...</td>\n",
       "      <td>В статье представлен новый архитектурный подх...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>В работе предлагается подход к обучению рекоме...</td>\n",
       "      <td>В данной работе исследуется влияние долгосроч...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Авторы представляют первый систематический обз...</td>\n",
       "      <td>\\n\\nИсследование посвящено анализу использова...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Авторы представляют общий подход к дообучению ...</td>\n",
       "      <td>В статье рассматриваются модели, сочетающие п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Авторы представляют два простых и эффективных ...</td>\n",
       "      <td>В статье представлены два новых архитектурных...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>В работе представлено систематическое исследов...</td>\n",
       "      <td>\\n\\nВ статье рассматриваются и анализируются ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Авторы представляют LADDER — фреймворк, улучша...</td>\n",
       "      <td>В статье представлен LADDER — метод, улучшающ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Scalable-Softmax (SSMax) — это новая замена фу...</td>\n",
       "      <td>В статье представлен Scalable-Softmax (SSMax)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Авторы представляют FlashAttention — IO-ориент...</td>\n",
       "      <td>\\nFlashAttention — это новый подход к реализа...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  gt  \\\n",
       "0  В данной работе представлен метод Test-Time Re...   \n",
       "1  В статье представлен Transformer — первая архи...   \n",
       "2  В работе предлагается подход к обучению рекоме...   \n",
       "3  Авторы представляют первый систематический обз...   \n",
       "4  Авторы представляют общий подход к дообучению ...   \n",
       "5  Авторы представляют два простых и эффективных ...   \n",
       "6  В работе представлено систематическое исследов...   \n",
       "7  Авторы представляют LADDER — фреймворк, улучша...   \n",
       "8  Scalable-Softmax (SSMax) — это новая замена фу...   \n",
       "9  Авторы представляют FlashAttention — IO-ориент...   \n",
       "\n",
       "                                               Tbank  \n",
       "0   В статье представлен метод Test-Time Reinforc...  \n",
       "1   В статье представлен новый архитектурный подх...  \n",
       "2   В данной работе исследуется влияние долгосроч...  \n",
       "3   \\n\\nИсследование посвящено анализу использова...  \n",
       "4   В статье рассматриваются модели, сочетающие п...  \n",
       "5   В статье представлены два новых архитектурных...  \n",
       "6   \\n\\nВ статье рассматриваются и анализируются ...  \n",
       "7   В статье представлен LADDER — метод, улучшающ...  \n",
       "8   В статье представлен Scalable-Softmax (SSMax)...  \n",
       "9   \\nFlashAttention — это новый подход к реализа...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf6e46f-3b2e-4a03-ab86-1639b67a47cb",
   "metadata": {},
   "source": [
    "## YandexGPT5-lite 8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dd5182a-3456-43f8-b1a6-82c80808e451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d14aaddeed704c8cad8b911579cb12ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_4456\\1072813799.py:8: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceBgeEmbeddings(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_4456\\1072813799.py:15: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(persist_directory=\"test_chroma_db\", embedding_function=embedding_model)\n"
     ]
    }
   ],
   "source": [
    "model_name = \"yandex/YandexGPT-5-Lite-8B-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "quant_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=quant_config, device_map=\"auto\")\n",
    "\n",
    "llm = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, return_full_text=False)\n",
    "\n",
    "embedding_model = HuggingFaceBgeEmbeddings(\n",
    "        model_name=\"BAAI/bge-m3\",\n",
    "        model_kwargs={\"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"}\n",
    "    )\n",
    "\n",
    "reranker = FlagReranker(\"BAAI/bge-reranker-v2-m3\", use_fp16=True)\n",
    "\n",
    "vectorstore = Chroma(persist_directory=\"test_chroma_db\", embedding_function=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2147abde-107d-455c-8ce7-1eea43b9263a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_MSG = (\n",
    "    \"Ты — помощник по научным статьям. \"\n",
    "    \"Сформулируй краткое и точное резюме по тексту ниже. Отвечай строго на русском языке\"\n",
    ")\n",
    "\n",
    "def build_messages(abstract, conclusion) -> list[dict]:\n",
    "    full_text = f\"Abstract:\\n{abstract}\\n\\nConclusion:\\n{conclusion}\"\n",
    "\n",
    "    return [\n",
    "        {\"role\": \"user\", \"content\": SYSTEM_MSG},\n",
    "        {\"role\": \"user\", \"content\": full_text}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a44702c-bfba-4f01-8026-dd39eb30b703",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiril\\miniconda3\\envs\\nlp_finetune\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.3` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kiril\\miniconda3\\envs\\nlp_finetune\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 10%|████████▎                                                                          | 1/10 [00:20<03:06, 20.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: TTRL: Test-Time Reinforcement Learning\n",
      "\n",
      "Суммаризация:  В статье представлен метод Test-Time Reinforcement Learning (TTRL) для обучения больших языковых моделей (LLM) с помощью RL на немаркированных данных. TTRL использует предварительные знания из предварительно обученных моделей и позволяет им «самоэволюционировать».\n",
      "\n",
      "Эксперименты показали, что TTRL последовательно улучшает производительность различных моделей и задач. Например, TTRL повысил показатель pass@1 модели Qwen-2.5-Math-7B примерно на 159% на AIME 2024, используя только немаркированные тестовые данные.\n",
      "\n",
      "Метод TTRL демонстрирует свою эффективность и потенциал для более широкого применения в различных задачах и областях.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 20%|████████████████▌                                                                  | 2/10 [00:44<02:58, 22.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: Attention Is All You Need\n",
      "\n",
      "Суммаризация:  В работе представлена новая архитектура нейронной сети — Transformer, основанная исключительно на механизмах внимания, без использования рекуррентных и свёрточных слоёв. Эксперименты по машинному переводу показали, что модели на основе Transformer превосходят по качеству существующие модели, при этом они более параллелизуемы и требуют значительно меньше времени на обучение.\n",
      "\n",
      "На задачах перевода Transformer демонстрирует лучшие результаты по сравнению с другими архитектурами, обучаясь значительно быстрее. Модель Transformer достигла новых рекордных показателей BLEU на задачах WMT 2014 по переводу с английского на немецкий (28,4 BLEU) и с английского на французский (41,8 BLEU).\n",
      "\n",
      "Авторы планируют применять модели на основе внимания к другим задачам, а также исследовать локальные механизмы внимания для эффективной обработки больших входных и выходных данных, таких как изображения, аудио и видео.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 30%|████████████████████████▉                                                          | 3/10 [00:54<01:56, 16.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: Recommender systems: when memory matters\n",
      "\n",
      "Суммаризация:  В статье изучается влияние долговременной памяти на обучаемость последовательной системы рекомендаций с учётом неявной обратной связи пользователей. Предложен онлайн-алгоритм, обновляющий параметры модели поблочно. Эмпирические оценки показали, что фильтрация пользователей по степени долговременной памяти в их взаимодействиях с системой существенно улучшает показатели MAP и NDCG при обучении крупномасштабных рекомендательных систем.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 40%|█████████████████████████████████▏                                                 | 4/10 [01:07<01:33, 15.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: Large Language Models Meet NLP: A Survey\n",
      "\n",
      "Суммаризация:  В статье представлен системный обзор больших языковых моделей (LLM) в задачах обработки естественного языка (NLP). Авторы вводят унифицированную таксономию, включающую приложения с замороженными параметрами и приложения с настройкой параметров. \n",
      "\n",
      "Цель работы — ответить на вопросы о текущем применении LLM в NLP, решении традиционных задач NLP с помощью LLM и перспективах развития LLM в этой области. Также выделены новые направления исследований и связанные с ними вызовы. Статья может служить практическим руководством для создания эффективных LLM в NLP.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [01:23<01:17, 15.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\n",
      "\n",
      "Суммаризация:  В статье рассматривается проблема ограниченного доступа больших предварительно обученных языковых моделей к знаниям и их манипулирования ими. Представлен общий рецепт тонкой настройки для моделей генерации с дополнением на основе поиска (RAG), которые сочетают предварительно обученную параметрическую и непараметрическую память. Модели RAG тестировались на широком спектре задач, требующих глубоких знаний, и установили новый стандарт в трёх задачах вопросов и ответов с открытым доменом. Они генерируют более конкретный, разнообразный и фактологически верный язык по сравнению с параметрическими seq2seq моделями.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [01:39<01:03, 15.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: Efficient Estimation of Word Representations in Vector Space\n",
      "\n",
      "Суммаризация:  В статье предложены две новые архитектуры моделей для вычисления непрерывных векторных представлений слов из очень больших наборов данных. Представленные модели демонстрируют значительное улучшение точности при гораздо меньших вычислительных затратах.\n",
      "\n",
      "Описанные модели обеспечивают современные результаты в задачах измерения синтаксических и семантических сходств слов. Они могут быть обучены на корпусах размером в триллион слов и имеют потенциал для применения в различных задачах обработки естественного языка, таких как анализ тональности и обнаружение парафраз.\n",
      "\n",
      "Авторы также указывают на успешное применение векторных представлений слов для автоматического расширения фактов в базах знаний и проверки их корректности, а также на многообещающие результаты экспериментов по машинному переводу.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [01:51<00:43, 14.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: Enhancing Retrieval-Augmented Generation: A Study of Best Practices\n",
      "\n",
      "Суммаризация:  В статье представлены усовершенствованные дизайны систем Retrieval-Augmented Generation (RAG), которые включают расширение запросов, новые стратегии поиска и контрастное инконтекстное обучение. Исследование систематически изучает ключевые факторы, влияющие на качество ответов, такие как размер языковой модели, дизайн подсказок, размер фрагментов документов, размер базы знаний и другие. Результаты предлагают практические идеи для разработки RAG-систем, обеспечивая баланс между контекстуальной насыщенностью и эффективностью генерации поиска.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [02:08<00:30, 15.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: LADDER: Self-Improving LLMs Through Recursive Problem Decomposition\n",
      "\n",
      "Суммаризация:  В статье представлен фреймворк LADDER для улучшения способностей языковых моделей к решению задач через рекурсивную декомпозицию задач и обучение с подкреплением с проверяемыми вознаграждениями. Также описано его расширение для времени тестирования (TTRL).\n",
      "\n",
      "LADDER позволяет моделям генерировать и обучаться на постепенно упрощающихся вариантах сложных задач. Подход демонстрирует значительные улучшения без необходимости архитектурного масштабирования или человеческого надзора.\n",
      "\n",
      "Эффективность подхода подтверждена на примере математических задач: точность решения интегралов повысилась с 1% до 82%, а на MIT Integration Bee — до 90%.\n",
      "\n",
      "Принципы, продемонстрированные в статье, могут быть применены в любых областях с чёткими механизмами проверки, от синтеза программ до доказательства теорем.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [02:27<00:16, 16.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: Scalable-Softmax Is Superior for Attention\n",
      "\n",
      "Суммаризация:  В статье предлагается Scalable-Softmax (SSMax) как альтернатива функции Softmax в механизмах внимания Transformer. SSMax решает проблему «затухания» внимания и улучшает обобщение для длинных контекстов.\n",
      "\n",
      "Эксперименты показали, что модели с SSMax достигают более быстрого снижения потерь при предварительном обучении и значительно улучшают производительность в длинных контекстах и при извлечении ключевой информации. Модели, использующие SSMax с начала предварительного обучения, демонстрируют наибольшую способность к обобщению, но и уже обученные модели могут получить преимущества от замены Softmax на SSMax во время или после предварительного обучения.\n",
      "\n",
      "SSMax является перспективным подходом для решения ограничений Softmax в механизмах внимания Transformer, особенно для задач с расширенными контекстами.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [02:48<00:00, 16.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness\n",
      "\n",
      "Суммаризация:  В статье предлагается FlashAttention — алгоритм точного внимания, учитывающий операции ввода-вывода (IO-aware). Он использует тайлинг для сокращения количества операций чтения/записи между памятью GPU и сокращает время работы трансформеров по сравнению с существующими методами.\n",
      "\n",
      "FlashAttention обеспечивает ускорение работы трансформеров по сравнению с базовыми алгоритмами: на 15% для BERT-large, в 3 раза для GPT-2 и в 2,4 раза для long-range arena. Также алгоритм позволяет увеличить длину контекста в трансформерах, что повышает качество моделей и открывает новые возможности.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "times = []\n",
    "for arxiv_url in tqdm(urls):\n",
    "    arxiv_id = extract_arxiv_id(arxiv_url)\n",
    "    \n",
    "    pdf_path = f'./articles/{arxiv_id}.pdf'\n",
    "    pdf_path, title = download_pdf(arxiv_id, pdf_path)\n",
    "    md_raw = pymupdf4llm.to_markdown(pdf_path)\n",
    "    md_trimmed = trim_markdown_after_section(md_raw)\n",
    "    md_cleaned = clean_markdown_for_rag(md_trimmed)\n",
    "    abstract = extract_section(md_cleaned, \"abstract\", [\"absctract\", \"summary\"])\n",
    "    conclusion = extract_section(md_cleaned, \"conclusion\", [\"conclusions\", \"closing remarks\"])\n",
    "    \n",
    "    messages = build_messages(abstract, conclusion)\n",
    "    start = time.time()\n",
    "\n",
    "    answer = llm(messages, max_new_tokens=256, do_sample=False)[0]['generated_text']\n",
    "    \n",
    "    end = time.time()\n",
    "    inf_time = end - start\n",
    "    \n",
    "    times.append(inf_time)\n",
    "    print(f'Название статьи: {title}\\n')\n",
    "    print(f'Суммаризация: {answer}\\n\\n')\n",
    "    outputs.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77775015-1e72-4c93-93f2-dd70db9a8e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14.131155252456665,\n",
       " 16.678635597229004,\n",
       " 7.474043846130371,\n",
       " 9.699246644973755,\n",
       " 10.073513269424438,\n",
       " 12.498071432113647,\n",
       " 8.384318590164185,\n",
       " 14.539063930511475,\n",
       " 13.785437822341919,\n",
       " 11.562705516815186]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1cad183-d568-4657-af50-05c323dfdb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее время суммаризации модели YandexGPT5: 12 сек\n"
     ]
    }
   ],
   "source": [
    "print(f'Среднее время суммаризации модели YandexGPT5: {np.mean(times):.0f} сек')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f745b891-da72-4b0f-bf32-c0ad3a97ec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summarization = pd.read_csv('summarize_examples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8715ae7-24ce-499f-b6d4-947f7d636bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summarization['YandexGPT'] = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1073e9b3-328d-4676-880b-770f14620b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summarization.to_csv('summarize_examples.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "182f0409-51b9-47ba-ba39-baf3b98f7ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gt</th>\n",
       "      <th>Tbank</th>\n",
       "      <th>YandexGPT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>В данной работе представлен метод Test-Time Re...</td>\n",
       "      <td>В статье представлен метод Test-Time Reinforc...</td>\n",
       "      <td>В статье представлен метод Test-Time Reinforce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>В статье представлен Transformer — первая архи...</td>\n",
       "      <td>В статье представлен новый архитектурный подх...</td>\n",
       "      <td>В работе представлена новая архитектура нейрон...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>В работе предлагается подход к обучению рекоме...</td>\n",
       "      <td>В данной работе исследуется влияние долгосроч...</td>\n",
       "      <td>В статье изучается влияние долговременной памя...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Авторы представляют первый систематический обз...</td>\n",
       "      <td>\\n\\nИсследование посвящено анализу использова...</td>\n",
       "      <td>В статье представлен системный обзор больших я...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Авторы представляют общий подход к дообучению ...</td>\n",
       "      <td>В статье рассматриваются модели, сочетающие п...</td>\n",
       "      <td>В статье рассматривается проблема ограниченног...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Авторы представляют два простых и эффективных ...</td>\n",
       "      <td>В статье представлены два новых архитектурных...</td>\n",
       "      <td>В статье предложены две новые архитектуры моде...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>В работе представлено систематическое исследов...</td>\n",
       "      <td>\\n\\nВ статье рассматриваются и анализируются ...</td>\n",
       "      <td>В статье представлены усовершенствованные диза...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Авторы представляют LADDER — фреймворк, улучша...</td>\n",
       "      <td>В статье представлен LADDER — метод, улучшающ...</td>\n",
       "      <td>В статье представлен фреймворк LADDER для улуч...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Scalable-Softmax (SSMax) — это новая замена фу...</td>\n",
       "      <td>В статье представлен Scalable-Softmax (SSMax)...</td>\n",
       "      <td>В статье предлагается Scalable-Softmax (SSMax)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Авторы представляют FlashAttention — IO-ориент...</td>\n",
       "      <td>\\nFlashAttention — это новый подход к реализа...</td>\n",
       "      <td>В статье предлагается FlashAttention — алгорит...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  gt  \\\n",
       "0  В данной работе представлен метод Test-Time Re...   \n",
       "1  В статье представлен Transformer — первая архи...   \n",
       "2  В работе предлагается подход к обучению рекоме...   \n",
       "3  Авторы представляют первый систематический обз...   \n",
       "4  Авторы представляют общий подход к дообучению ...   \n",
       "5  Авторы представляют два простых и эффективных ...   \n",
       "6  В работе представлено систематическое исследов...   \n",
       "7  Авторы представляют LADDER — фреймворк, улучша...   \n",
       "8  Scalable-Softmax (SSMax) — это новая замена фу...   \n",
       "9  Авторы представляют FlashAttention — IO-ориент...   \n",
       "\n",
       "                                               Tbank  \\\n",
       "0   В статье представлен метод Test-Time Reinforc...   \n",
       "1   В статье представлен новый архитектурный подх...   \n",
       "2   В данной работе исследуется влияние долгосроч...   \n",
       "3   \\n\\nИсследование посвящено анализу использова...   \n",
       "4   В статье рассматриваются модели, сочетающие п...   \n",
       "5   В статье представлены два новых архитектурных...   \n",
       "6   \\n\\nВ статье рассматриваются и анализируются ...   \n",
       "7   В статье представлен LADDER — метод, улучшающ...   \n",
       "8   В статье представлен Scalable-Softmax (SSMax)...   \n",
       "9   \\nFlashAttention — это новый подход к реализа...   \n",
       "\n",
       "                                           YandexGPT  \n",
       "0  В статье представлен метод Test-Time Reinforce...  \n",
       "1  В работе представлена новая архитектура нейрон...  \n",
       "2  В статье изучается влияние долговременной памя...  \n",
       "3  В статье представлен системный обзор больших я...  \n",
       "4  В статье рассматривается проблема ограниченног...  \n",
       "5  В статье предложены две новые архитектуры моде...  \n",
       "6  В статье представлены усовершенствованные диза...  \n",
       "7  В статье представлен фреймворк LADDER для улуч...  \n",
       "8  В статье предлагается Scalable-Softmax (SSMax)...  \n",
       "9  В статье предлагается FlashAttention — алгорит...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3d2b32-54bd-45db-b035-fc710b8f7f5d",
   "metadata": {},
   "source": [
    "## QWEN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0dcbba6-f110-44b6-93da-a116057994f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e74689f969a47589c71407d09748768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"Qwen/Qwen3-8B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "quant_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    #quantization_config=quant_config,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"cuda\"\n",
    ")\n",
    "\n",
    "llm = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, return_full_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cbfa72b-39b5-40d3-8000-383ae320e256",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_MSG = (\n",
    "    \"Ты — помощник по научным статьям. \"\n",
    "    \"Сформулируй краткое и точное резюме по тексту ниже. Отвечай строго на русском языке\"\n",
    ")\n",
    "\n",
    "def build_messages(abstract, conclusion) -> list[dict]:\n",
    "    full_text = f\"Abstract:\\n{abstract}\\n\\nConclusion:\\n{conclusion}\"\n",
    "\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_MSG},\n",
    "        {\"role\": \"user\", \"content\": full_text},\n",
    "        {\"role\": \"assistant\", \"content\": \"Краткое резюме:\"},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbac92ae-a2a3-4a95-b6f0-d634b86c7ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 1/10 [00:22<03:25, 22.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: TTRL: Test-Time Reinforcement Learning\n",
      "\n",
      "Суммаризация: В данной работе предложен новый метод обучения больших языковых моделей (LLM) с использованием усиленного обучения (RL) на неотмеченных тестовых данных, названный Test-Time Reinforcement Learning (TTRL). Основная идея заключается в использовании метода голосования большинства для оценки вознаграждений без доступа к истинным меткам. Эксперименты показали, что TTRL значительно улучшает производительность моделей на различных задачах, включая математические задачи, и приближает их к уровню моделей, обученных на данных с истинными метками. TTRL демонстрирует высокую эффективность и потенциал для применения в различных задачах и областях.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 2/10 [00:41<02:43, 20.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: Attention Is All You Need\n",
      "\n",
      "Суммаризация: В данной работе предложен архитектура Transformer, основанная исключительно на механизмах внимания, заменяющая традиционные рекуррентные и свёрточные сети. Эксперименты на задачах машинного перевода показали, что модель достигает более высокого качества перевода, обладает лучшей параллелизуемостью и требует меньше времени на обучение. Transformer установил новые рекорды по BLEU на задачах английско-немецкого и английско-французского перевода. Модель успешно применялась и на других задачах, таких как разбор предложения. Код доступен по ссылке.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 3/10 [01:06<02:36, 22.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: Recommender systems: when memory matters\n",
      "\n",
      "Суммаризация: В статье исследуется влияние долгосрочной памяти на обучаемость последовательного рекомендательного системы с учетом неявной обратной связи пользователей. Предложена онлайн-алгоритм, где параметры модели обновляются по пользователям на блоках элементов, состоящих из последовательности непросмотренных элементов, за которыми следует просмотренный. Эмпирические оценки показали, что фильтрация пользователей по степени долгосрочной памяти в их взаимодействии значительно улучшает производительность системы по метрикам MAP и NDCG, особенно при обучении больших рекомендательных систем. В заключении подчеркивается, что учет неявной обратной связи и фильтрация данных по однородности и устойчивости поведения пользователей приводит к значительному улучшению качества рекомендаций.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 4/10 [01:25<02:05, 21.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: Large Language Models Meet NLP: A Survey\n",
      "\n",
      "Суммаризация: Статья представляет собой первый систематический обзор применения больших языковых моделей (LLM) в области обработки естественного языка (NLP). В работе вводится унифицированная классификация, включающая параметры \"замороженных\" и \"настроенных\" применений, а также выявляются новые направления исследований и вызовы. Целью является предоставление ценных инсайтов и практических рекомендаций для разработки эффективных LLM в NLP, а также поддержка дальнейших исследований через публичный ресурс.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [01:45<01:44, 20.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\n",
      "\n",
      "Суммаризация: Авторы исследуют модель RAG (Retrieval-Augmented Generation), которая сочетает параметрическую предобученную seq2seq-модель с не параметрической памятью в виде плотного индекса Википедии. Они сравнивают два подхода к использованию этой памяти и показывают, что RAG-модели превосходят параметрические seq2seq-модели и архитектуры retrieve-and-extract на задачах, требующих знаний, включая открытые QA-задачи. Также RAG-модели генерируют более точную, разнообразную и фактурную информацию.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [02:12<01:31, 22.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: Efficient Estimation of Word Representations in Vector Space\n",
      "\n",
      "Суммаризация: В статье предлагаются два новых архитектурных подхода для вычисления непрерывных векторных представлений слов на основе очень больших данных. Предложенные методы демонстрируют значительное улучшение точности в задачах определения схожести слов по сравнению с существующими методами, при этом требуя значительно меньше вычислительных ресурсов. Высококачественные векторы можно обучить за менее чем день на данных объемом 1,6 миллиарда слов. Эти векторы достигают состояния искусства в задачах синтаксической и семантической схожести слов. Также показано, что предложенные модели могут быть применены для работы с корпорами объемом в триллионы слов, что в несколько порядков превышает предыдущие результаты. Векторы успешно применяются в задачах, таких как расширение знаний в базах данных, проверка достоверности фактов и машинный перевод. Авторы ожидают, что их подходы помогут улучшить существ\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [02:30<01:03, 21.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: Enhancing Retrieval-Augmented Generation: A Study of Best Practices\n",
      "\n",
      "Суммаризация: В данной работе представлены продвинутые дизайн-решения RAG-систем, включающие расширение запроса, новые стратегии поиска и Contrastive In-Context Learning. Проведено системное исследование ключевых факторов, влияющих на качество ответов, таких как размер модели, дизайн промптов, размер документов, размер базы знаний и другие. Результаты исследования дают практические рекомендации для оптимизации RAG-систем, обеспечивая баланс между контекстной информативностью и эффективностью поиска-генерации. Реализация и код доступны для дальнейшего использования.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [02:52<00:43, 21.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: LADDER: Self-Improving LLMs Through Recursive Problem Decomposition\n",
      "\n",
      "Суммаризация: LADDER — это фреймворк, улучшающий способности языковых моделей решать задачи за счёт рекурсивного разложения проблем и обучения с подкреплением с проверяемыми наградами. Его расширение TTRL позволяет модели эффективно улучшать свои навыки в режиме работы. Эксперименты показали значительное повышение способностей к математическому мышлению, что демонстрирует эффективность подхода. Работа основана на трёх ключевых идеях: рекурсивном разложении задач, важности проверяемых наград и стратегическом использовании вычислительных ресурсов. Принципы LADDER могут быть применены в различных областях с возможностью проверки результатов, позволяя моделям систематически расширять свои возможности.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [03:17<00:22, 22.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: Scalable-Softmax Is Superior for Attention\n",
      "\n",
      "Суммаризация: В данной работе предложен новый подход — Scalable-Softmax (SSMax), который заменяет классическую функцию Softmax в слоях внимания трансформеров. SSMax решает проблему ухудшения распределения внимания при увеличении длины контекста, позволяя моделям эффективно фокусироваться на ключевой информации. Эксперименты показали, что модели с SSMax демонстрируют улучшенную скорость обучения, лучшую генерализацию на длинные контексты и более высокую точность в задачах извлечения ключевой информации. SSMax может быть легко интегрирован в существующие архитектуры трансформеров и приносит пользу как при обучении с нуля, так и при модификации уже обученных моделей.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [03:42<00:00, 22.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness\n",
      "\n",
      "Суммаризация: FlashAttention — это новый алгоритм точного внимания, учитывающий ограничения памяти (IO-оптимизированный), который значительно ускоряет обработку длинных последовательностей в трансформерах. Он использует тайлинг для минимизации операций чтения/записи между высокопроизводительной памятью HBM и SRAM. FlashAttention позволяет ускорить обучение моделей, таких как BERT-large, GPT-2 и Long Range Arena, и улучшает качество моделей, позволяя обрабатывать более длинные контексты. Расширение FlashAttention — блок-спарсное внимание — обеспечивает еще более высокую производительность при приближенном внимании.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "times = []\n",
    "for arxiv_url in tqdm(urls):\n",
    "    arxiv_id = extract_arxiv_id(arxiv_url)\n",
    "    \n",
    "    pdf_path = f'../articles/{arxiv_id}.pdf'\n",
    "    pdf_path, title = download_pdf(arxiv_id, pdf_path)\n",
    "    md_raw = pymupdf4llm.to_markdown(pdf_path)\n",
    "    md_trimmed = trim_markdown_after_section(md_raw)\n",
    "    md_cleaned = clean_markdown_for_rag(md_trimmed)\n",
    "    abstract = extract_section(md_cleaned, \"abstract\", [\"absctract\", \"summary\"])\n",
    "    conclusion = extract_section(md_cleaned, \"conclusion\", [\"conclusions\", \"closing remarks\"])\n",
    "    \n",
    "    messages = build_messages(abstract, conclusion)\n",
    "    messages = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True, enable_thinking=False)\n",
    "    start = time.time()\n",
    "\n",
    "    answer = llm(messages, max_new_tokens=256, temperature=0.7, top_p=0.8, top_k=20, min_p=0)[0]['generated_text']\n",
    "\n",
    "    end = time.time()\n",
    "    inf_time = end - start\n",
    "    \n",
    "    times.append(inf_time)\n",
    "    print(f'Название статьи: {title}\\n')\n",
    "    print(f'Суммаризация: {answer}\\n\\n')\n",
    "    outputs.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "210eb6ec-dda0-4b65-b80b-c0e2ff1793a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 1/10 [00:24<03:39, 24.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: TTRL: Test-Time Reinforcement Learning\n",
      "\n",
      "Суммаризация:   \n",
      "В статье предложен метод Test-Time Reinforcement Learning (TTRL), позволяющий обучать большие языковые модели с использованием усилительного обучения на неотмеченных тестовых данных. Основная идея заключается в использовании функции награды на основе большинства голосов, основанной на согласии предсказаний модели. Эксперименты показали, что TTRL значительно улучшает производительность на различных задачах, включая математические задачи, и приближает результаты к уровням моделей, обученных на данных с правильными метками.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 2/10 [00:47<03:08, 23.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: Attention Is All You Need\n",
      "\n",
      "Суммаризация:   \n",
      "Статья представляет архитектуру Transformer — модель, основанную полностью на механизмах внимания, которая заменяет традиционные рекуррентные и свёрточные сети. Эксперименты показали, что Transformer превосходит существующие модели по качеству перевода, обладает лучшей параллелизуемостью и требует меньше времени на обучение. На задачах перевода с английского на немецкий и французкий модель достигла новых рекордов по метрике BLEU. Также Transformer успешно применялся для других задач, таких как синтаксический анализ.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 3/10 [01:10<02:43, 23.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: Recommender systems: when memory matters\n",
      "\n",
      "Суммаризация:   \n",
      "В статье исследуется влияние долгосрочной памяти на обучаемость последовательного рекомендательного системы с учетом неявной обратной связи пользователей. Предложен онлайн-алгоритм, обновляющий параметры модели по пользователям на блоках элементов, состоящих из последовательности непросмотренных элементов, за которыми следует просмотренный. Эмпирические исследования показали, что фильтрация пользователей по степени долгосрочной памяти в их взаимодействии значительно улучшает производительность системы по метрикам MAP и NDCG, особенно при обучении масштабных рекомендательных систем. В выводе отмечается, что использование фильтрованного набора данных с учетом однородности и устойчивости поведения пользователей приводит к значительному улучшению качества рекомендаций.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 4/10 [01:29<02:08, 21.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: Large Language Models Meet NLP: A Survey\n",
      "\n",
      "Суммаризация:   \n",
      "Статья представляет собой первый систематический обзор применения больших языковых моделей (LLM) в области обработки естественного языка (NLP). В работе вводится унифицированная классификация, включающая параметры \"замороженных\" и \"настроенных\" применений, а также выявляются новые направления исследований и вызовы. Цель — предоставить ценные инсайты и практические рекомендации для дальнейшего развития LLM в NLP, а также поддерживать публичный ресурс для отслеживания последних достижений в этой области.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [01:51<01:49, 21.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\n",
      "\n",
      "Суммаризация:   \n",
      "Статья представляет обобщенный подход к тонкой настройке моделей Retrieval-Augmented Generation (RAG), сочетающих параметрическую и непараметрическую память для генерации текста. В работе предлагаются две формулировки RAG: одна использует одинаковые извлеченные документы на протяжении всей генерации, а другая — разные документы для каждого токена. Модели оцениваются на задачах, требующих знаний, и демонстрируют лучшие результаты по сравнению с параметрическими seq2seq-моделями и архитектурами retrieve-and-extract. RAG-модели показывают более точную, разнообразную и фактурную генерацию текста.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [02:18<01:34, 23.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: Efficient Estimation of Word Representations in Vector Space\n",
      "\n",
      "Суммаризация:   \n",
      "В статье предложены два новых архитектура моделей для вычисления непрерывных векторных представлений слов на основе больших данных. Эти модели демонстрируют значительное улучшение точности в задачах сходства слов по сравнению с существующими методами, при этом требуя значительно меньше вычислительных ресурсов. Векторы показывают состояние-оф-арт результаты на тестовых наборах для синтаксических и семантических задач. Использование этих моделей позволяет эффективно обучать векторы даже на данных объемом в триллионы слов. Векторы успешно применяются в задачах NLP, включая расширение знаний в базах данных и машинный перевод, и могут стать важным элементом будущих приложений.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [02:35<01:03, 21.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: Enhancing Retrieval-Augmented Generation: A Study of Best Practices\n",
      "\n",
      "Суммаризация:   \n",
      "В статье представлены продвинутые дизайн-решения RAG-систем, включающие расширение запроса, новые стратегии поиска и Contrastive In-Context Learning. Проведено системное исследование ключевых факторов, влияющих на качество ответов, таких как размер модели, дизайн промптов, размер документов, размер базы знаний и другие. Результаты дают практические рекомендации по оптимизации RAG-систем, обеспечивая баланс между контекстной информативностью и эффективностью генерации. Реализация и код доступны для исследований.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [02:55<00:41, 20.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: LADDER: Self-Improving LLMs Through Recursive Problem Decomposition\n",
      "\n",
      "Суммаризация:   \n",
      "LADDER — это фреймворк, улучшающий способности языковых моделей к решению задач через рекурсивное разложение проблем и обучение с подтвержденными наградами. Его расширение TTRL позволяет модели эффективно улучшать свои навыки в режиме тестирования. Эксперименты показали значительное повышение способностей к математическому мышлению, что демонстрирует эффективность подхода. Работа подчеркивает важность стратегического взаимодействия моделей с окружением, а не только архитектурных инноваций. Принципы LADDER могут быть применены в различных областях с четкими механизмами проверки, способствуя систематическому расширению возможностей ИИ.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [03:27<00:24, 24.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: Scalable-Softmax Is Superior for Attention\n",
      "\n",
      "Суммаризация:   \n",
      "В статье предложен новый метод Scalable-Softmax (SSMax), который улучшает работу внимания в трансформерных моделях, особенно при работе с длинными контекстами. SSMax решает проблему уплощения распределения внимания, характерную для стандартного Softmax, и позволяет моделям лучше фокусироваться на ключевой информации. Эксперименты показали, что модели с SSMax демонстрируют более быструю сходимость, улучшенную обобщаемость на длинные контексты и лучшую точность в задачах извлечения ключевой информации. SSMax может быть легко интегрирован в существующие архитектуры и эффективно работает как при обучении с нуля, так и при замене Softmax в уже обученных моделях.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [03:47<00:00, 22.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Название статьи: FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness\n",
      "\n",
      "Суммаризация:   \n",
      "FlashAttention — это алгоритм точного внимания, учитывающий ограничения памяти (IO-оптимизированный), который значительно ускоряет обучение трансформеров, сокращая количество обращений к высокопроизводительной памяти GPU. Он позволяет использовать более длинные контексты, улучшая качество моделей и открывая новые возможности, такие как высокая точность на задачах с очень длинными последовательностями.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "times = []\n",
    "for arxiv_url in tqdm(urls):\n",
    "    arxiv_id = extract_arxiv_id(arxiv_url)\n",
    "    \n",
    "    pdf_path = f'./articles/{arxiv_id}.pdf'\n",
    "    pdf_path, title = download_pdf(arxiv_id, pdf_path)\n",
    "    md_raw = pymupdf4llm.to_markdown(pdf_path)\n",
    "    md_trimmed = trim_markdown_after_section(md_raw)\n",
    "    md_cleaned = clean_markdown_for_rag(md_trimmed)\n",
    "    abstract = extract_section(md_cleaned, \"abstract\", [\"absctract\", \"summary\"])\n",
    "    conclusion = extract_section(md_cleaned, \"conclusion\", [\"conclusions\", \"closing remarks\"])\n",
    "    \n",
    "    messages = build_messages(abstract, conclusion)\n",
    "    start = time.time()\n",
    "\n",
    "    answer = llm(messages, max_new_tokens=256, do_sample=False, temperature=None, top_p=None, top_k=None)[0]['generated_text']\n",
    "\n",
    "    end = time.time()\n",
    "    inf_time = end - start\n",
    "    \n",
    "    times.append(inf_time)\n",
    "    print(f'Название статьи: {title}\\n')\n",
    "    print(f'Суммаризация: {answer}\\n\\n')\n",
    "    outputs.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7498a2cb-075e-4265-b9fa-da351234bbe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18.104891061782837,\n",
       " 19.647082090377808,\n",
       " 16.988260507583618,\n",
       " 12.867859601974487,\n",
       " 16.346726655960083,\n",
       " 23.98879098892212,\n",
       " 13.167678594589233,\n",
       " 15.985154390335083,\n",
       " 26.50315833091736,\n",
       " 11.247574806213379]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d60172a-97e9-4455-bc6c-c6278479fe6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее время суммаризации модели Qwen3: 17 сек\n"
     ]
    }
   ],
   "source": [
    "print(f'Среднее время суммаризации модели Qwen3: {np.mean(times):.0f} сек')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0af858f3-4933-42fc-8a4d-d9f0c8d555dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summarization = pd.read_csv('summarize_examples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd3f8745-f829-48f7-941b-98d45bdb68b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [x.split('\\n')[1] for x in outputs]\n",
    "df_summarization['Qwen3'] = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d90a072f-974e-4062-91c8-c2f511322e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summarization = df_summarization[['gt', 'Tbank', 'YandexGPT', 'Qwen3', 'summarize_best_llm', 'sim_scores_tbank', 'sim_scores_yandex']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fc527b0-29b5-4308-8224-60867ca9235a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gt</th>\n",
       "      <th>Tbank</th>\n",
       "      <th>YandexGPT</th>\n",
       "      <th>Qwen3</th>\n",
       "      <th>summarize_best_llm</th>\n",
       "      <th>sim_scores_tbank</th>\n",
       "      <th>sim_scores_yandex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>В данной работе представлен метод Test-Time Re...</td>\n",
       "      <td>В статье представлен метод Test-Time Reinforc...</td>\n",
       "      <td>В статье представлен метод Test-Time Reinforce...</td>\n",
       "      <td>В данной работе предложен новый метод обучения...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.909943</td>\n",
       "      <td>0.930276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>В статье представлен Transformer — первая архи...</td>\n",
       "      <td>В статье представлен новый архитектурный подх...</td>\n",
       "      <td>В работе представлена новая архитектура нейрон...</td>\n",
       "      <td>Статья представляет архитектуру Transformer — ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.797422</td>\n",
       "      <td>0.852751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>В работе предлагается подход к обучению рекоме...</td>\n",
       "      <td>В данной работе исследуется влияние долгосроч...</td>\n",
       "      <td>В статье изучается влияние долговременной памя...</td>\n",
       "      <td>В статье исследуется влияние долгосрочной памя...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.774107</td>\n",
       "      <td>0.773998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Авторы представляют первый систематический обз...</td>\n",
       "      <td>\\n\\nИсследование посвящено анализу использова...</td>\n",
       "      <td>В статье представлен системный обзор больших я...</td>\n",
       "      <td>Статья представляет собой первый систематическ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.755156</td>\n",
       "      <td>0.731499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Авторы представляют общий подход к дообучению ...</td>\n",
       "      <td>В статье рассматриваются модели, сочетающие п...</td>\n",
       "      <td>В статье рассматривается проблема ограниченног...</td>\n",
       "      <td>Статья представляет обобщённый подход к тонкой...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.737129</td>\n",
       "      <td>0.688586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Авторы представляют два простых и эффективных ...</td>\n",
       "      <td>В статье представлены два новых архитектурных...</td>\n",
       "      <td>В статье предложены две новые архитектуры моде...</td>\n",
       "      <td>В статье предложены два новых архитектурных по...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.739331</td>\n",
       "      <td>0.708769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>В работе представлено систематическое исследов...</td>\n",
       "      <td>\\n\\nВ статье рассматриваются и анализируются ...</td>\n",
       "      <td>В статье представлены усовершенствованные диза...</td>\n",
       "      <td>В статье представлены продвинутые дизайн-систе...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.856174</td>\n",
       "      <td>0.903531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Авторы представляют LADDER — фреймворк, улучша...</td>\n",
       "      <td>В статье представлен LADDER — метод, улучшающ...</td>\n",
       "      <td>В статье представлен фреймворк LADDER для улуч...</td>\n",
       "      <td>LADDER — это фреймворк, улучшающий способности...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.804446</td>\n",
       "      <td>0.914699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Scalable-Softmax (SSMax) — это новая замена фу...</td>\n",
       "      <td>В статье представлен Scalable-Softmax (SSMax)...</td>\n",
       "      <td>В статье предлагается Scalable-Softmax (SSMax)...</td>\n",
       "      <td>В статье предложен новый метод Scalable-Softma...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.864461</td>\n",
       "      <td>0.898752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Авторы представляют FlashAttention — IO-ориент...</td>\n",
       "      <td>\\nFlashAttention — это новый подход к реализа...</td>\n",
       "      <td>В статье предлагается FlashAttention — алгорит...</td>\n",
       "      <td>FlashAttention — это точный алгоритм внимания,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.899040</td>\n",
       "      <td>0.914540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  gt  \\\n",
       "0  В данной работе представлен метод Test-Time Re...   \n",
       "1  В статье представлен Transformer — первая архи...   \n",
       "2  В работе предлагается подход к обучению рекоме...   \n",
       "3  Авторы представляют первый систематический обз...   \n",
       "4  Авторы представляют общий подход к дообучению ...   \n",
       "5  Авторы представляют два простых и эффективных ...   \n",
       "6  В работе представлено систематическое исследов...   \n",
       "7  Авторы представляют LADDER — фреймворк, улучша...   \n",
       "8  Scalable-Softmax (SSMax) — это новая замена фу...   \n",
       "9  Авторы представляют FlashAttention — IO-ориент...   \n",
       "\n",
       "                                               Tbank  \\\n",
       "0   В статье представлен метод Test-Time Reinforc...   \n",
       "1   В статье представлен новый архитектурный подх...   \n",
       "2   В данной работе исследуется влияние долгосроч...   \n",
       "3   \\n\\nИсследование посвящено анализу использова...   \n",
       "4   В статье рассматриваются модели, сочетающие п...   \n",
       "5   В статье представлены два новых архитектурных...   \n",
       "6   \\n\\nВ статье рассматриваются и анализируются ...   \n",
       "7   В статье представлен LADDER — метод, улучшающ...   \n",
       "8   В статье представлен Scalable-Softmax (SSMax)...   \n",
       "9   \\nFlashAttention — это новый подход к реализа...   \n",
       "\n",
       "                                           YandexGPT  \\\n",
       "0  В статье представлен метод Test-Time Reinforce...   \n",
       "1  В работе представлена новая архитектура нейрон...   \n",
       "2  В статье изучается влияние долговременной памя...   \n",
       "3  В статье представлен системный обзор больших я...   \n",
       "4  В статье рассматривается проблема ограниченног...   \n",
       "5  В статье предложены две новые архитектуры моде...   \n",
       "6  В статье представлены усовершенствованные диза...   \n",
       "7  В статье представлен фреймворк LADDER для улуч...   \n",
       "8  В статье предлагается Scalable-Softmax (SSMax)...   \n",
       "9  В статье предлагается FlashAttention — алгорит...   \n",
       "\n",
       "                                               Qwen3  summarize_best_llm  \\\n",
       "0  В данной работе предложен новый метод обучения...                   1   \n",
       "1  Статья представляет архитектуру Transformer — ...                   1   \n",
       "2  В статье исследуется влияние долгосрочной памя...                   0   \n",
       "3  Статья представляет собой первый систематическ...                   1   \n",
       "4  Статья представляет обобщённый подход к тонкой...                   0   \n",
       "5  В статье предложены два новых архитектурных по...                   0   \n",
       "6  В статье представлены продвинутые дизайн-систе...                   0   \n",
       "7  LADDER — это фреймворк, улучшающий способности...                   1   \n",
       "8  В статье предложен новый метод Scalable-Softma...                   1   \n",
       "9  FlashAttention — это точный алгоритм внимания,...                   0   \n",
       "\n",
       "   sim_scores_tbank  sim_scores_yandex  \n",
       "0          0.909943           0.930276  \n",
       "1          0.797422           0.852751  \n",
       "2          0.774107           0.773998  \n",
       "3          0.755156           0.731499  \n",
       "4          0.737129           0.688586  \n",
       "5          0.739331           0.708769  \n",
       "6          0.856174           0.903531  \n",
       "7          0.804446           0.914699  \n",
       "8          0.864461           0.898752  \n",
       "9          0.899040           0.914540  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bfa43f67-f4e0-4d41-9011-ff8dd9854cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эталонная суммаризация: Авторы представляют FlashAttention — IO-ориентированный алгоритм точного внимания, оптимизированный для GPU-архитектур. Он использует тайлинг, чтобы минимизировать количество операций чтения и записи между высокоскоростной памятью (HBM) и локальной SRAM, что значительно ускоряет обучение трансформеров. FlashAttention обеспечивает реальный прирост скорости (до 3× на GPT-2, 15% на BERT-large) без ущерба для качества модели. Расширенная версия с блок-спарсностью опережает существующие приближённые методы по скорости и позволяет моделям работать с контекстами до 64K токенов, впервые демонстрируя выше случайного уровня точности на задачах Path-X и Path-256. Метод открывает путь к более длинным, качественным и эффективным трансформерам\n",
      "\n",
      "Суммаризация Tbank:  \n",
      "FlashAttention — это новый подход к реализации внимания в трансформерах, который решает проблему высокой вычислительной и памяти-затратности на длинных последовательностях. В отличие от традиционных методов, FlashAttention учитывает операции ввода-вывода (IO) между уровнями памяти GPU, что позволяет значительно уменьшить количество обращений к высокоскоростной памяти (HBM) и улучшить производительность. \n",
      "\n",
      "Основные достижения:\n",
      "- FlashAttention обеспечивает до 15% ускорения в тренировке BERT-large и до 3-кратного ускорения для GPT-2 по сравнению с текущими рекордами.\n",
      "- Внедрение в блок-спарсивание внимания позволяет достичь еще большего ускорения и улучшает качество моделей.\n",
      "- Увеличение контекста в моделях приводит к улучшению метрик (перплексии и точности) и новым возможностям, таким как достижение лучших результатов на задачах с длинными последовательностями (Path-X и Path-256).\n",
      "\n",
      "FlashAttention\n",
      "\n",
      "Суммаризация YandexGPT: В статье предлагается FlashAttention — алгоритм точного внимания, учитывающий операции ввода-вывода (IO-aware). Он использует тайлинг для сокращения количества операций чтения/записи между памятью GPU и сокращает время работы трансформеров по сравнению с существующими методами.\n",
      "\n",
      "FlashAttention обеспечивает ускорение работы трансформеров по сравнению с базовыми алгоритмами: на 15% для BERT-large, в 3 раза для GPT-2 и в 2,4 раза для long-range arena. Также алгоритм позволяет увеличить длину контекста в трансформерах, что повышает качество моделей и открывает новые возможности.\n",
      "\n",
      "Суммаризация Qwen: FlashAttention — это точный алгоритм внимания, учитывающий особенности работы с памятью (IO-оптимизация), который значительно ускоряет обработку длинных последовательностей по сравнению с традиционными методами. Он позволяет тренировать трансформеры быстрее, улучшает качество моделей и открывает новые возможности для работы с очень длинными текстами.\n"
     ]
    }
   ],
   "source": [
    "n = 9\n",
    "str_gt = df_summarization['gt'].iloc[n]\n",
    "str_tbank = df_summarization['Tbank'].iloc[n]\n",
    "str_yandex = df_summarization['YandexGPT'].iloc[n]\n",
    "str_qwen = df_summarization['Qwen3'].iloc[n]\n",
    "\n",
    "print(f'Эталонная суммаризация: {str_gt}\\n')\n",
    "print(f'Суммаризация Tbank: {str_tbank}\\n')\n",
    "print(f'Суммаризация YandexGPT: {str_yandex}\\n')  \n",
    "print(f'Суммаризация Qwen: {str_qwen}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa7dade7-9036-4ded-894c-52f699ad76b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "df = pd.read_csv('summarize_examples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3d92ffe-4607-474f-bbcb-b7740a49ff21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эталонная суммаризация: Авторы представляют два простых и эффективных архитектурных подхода — CBOW и Skip-gram — для обучения векторных представлений слов на масштабных корпусах. Эти модели обеспечивают значительное улучшение качества синтаксических и семантических представлений при низких вычислительных затратах, позволяя обучать векторы даже на триллионе слов. Векторы достигают state-of-the-art результатов в задачах оценки семантической близости и находят применение в ряде NLP-задач, включая машинный перевод, анализ тональности и расширение знаний в базах данных. Работа демонстрирует потенциал простых моделей как базового элемента для будущих приложений в NLP\n",
      "\n",
      "Суммаризация Tbank:  В статье представлены два новых архитектурных решения для создания непрерывных векторных представлений слов на основе больших данных. Эти модели показывают значительное улучшение точности в задачах измерения семантической и синтаксической близости слов по сравнению с предыдущими методами, включая нейронные сети. Векторы обучаются быстрее и с меньшими вычислительными затратами, что позволяет использовать данные на порядки большие, чем ранее. В статье также обсуждаются перспективы применения этих векторов в задачах машинного перевода, анализа настроений и других NLP-задачах, а также их потенциал для улучшения существующих методов и создания новых приложений.\n",
      "\n",
      "Суммаризация YandexGPT: В статье предложены две новые архитектуры моделей для вычисления непрерывных векторных представлений слов из очень больших наборов данных. Представленные модели демонстрируют значительное улучшение точности при гораздо меньших вычислительных затратах.\n",
      "\n",
      "Описанные модели обеспечивают современные результаты в задачах измерения синтаксических и семантических сходств слов. Они могут быть обучены на корпусах размером в триллион слов и имеют потенциал для применения в различных задачах обработки естественного языка, таких как анализ тональности и обнаружение парафраз.\n",
      "\n",
      "Авторы также указывают на успешное применение векторных представлений слов для автоматического расширения фактов в базах знаний и проверки их корректности, а также на многообещающие результаты экспериментов по машинному переводу.\n",
      "\n",
      "Суммаризация Qwen: В статье предложены два новых архитектурных подхода для вычисления непрерывных векторных представлений слов на основе больших данных. Эти методы демонстрируют значительное улучшение точности по сравнению с существующими техниками, при этом требуют значительно меньше вычислительных ресурсов. Векторы, полученные с использованием моделей CBOW и Skip-gram, показывают высокую эффективность в задачах синтаксической и семантической схожести слов. Благодаря низкой сложности вычислений, такие векторы можно обучать на данных объемом до триллионов слов. Они успешно применяются в задачах NLP, включая анализ тональности, обнаружение параллельных конструкций, расширение знаний в базах данных и машинный перевод. Авторы ожидают, что их подходы помогут улучшить существующие методы оценки векторных представлений слов и станут важной частью будущих приложений в\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "str_gt = df['gt'].iloc[n]\n",
    "str_tbank = df['Tbank'].iloc[n]\n",
    "str_yandex = df['YandexGPT'].iloc[n]\n",
    "str_qwen = df['Qwen3'].iloc[n]\n",
    "\n",
    "print(f'Эталонная суммаризация: {str_gt}\\n')\n",
    "print(f'Суммаризация Tbank: {str_tbank}\\n')\n",
    "print(f'Суммаризация YandexGPT: {str_yandex}\\n')  \n",
    "print(f'Суммаризация Qwen: {str_qwen}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41159b5e-4d0d-49fa-84aa-d298654a5ee3",
   "metadata": {},
   "source": [
    "## LLM as a judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f6038f9e-742c-46a2-9eea-aba45a09a0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores [1-3] чем меньше тем лучше\n",
    "scores_tbank = [1, 3, 1, 3, 2, 3, 3, 2, 3, 1]\n",
    "scores_yandex = [3, 1, 2, 2, 3, 2, 2, 1, 2, 3]\n",
    "scores_qwen = [2, 2, 3, 1, 1, 1, 1, 3, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "749bc986-605e-4afe-af99-8df890c42be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summarization['summarize_tbank_rank'] = scores_tbank\n",
    "df_summarization['summarize_yandex_rank'] = scores_yandex\n",
    "df_summarization['summarize_qwen_rank'] = scores_qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0164442a-61e8-4436-b633-0387fd4d5652",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = ['gt',\n",
    " 'Tbank',\n",
    " 'YandexGPT',\n",
    " 'Qwen3',\n",
    "'summarize_tbank_rank',\n",
    " 'summarize_yandex_rank',\n",
    " 'summarize_qwen_rank',\n",
    " 'sim_scores_tbank',\n",
    " 'sim_scores_yandex',\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dd393aa9-0135-4964-9775-e93464e633c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summarization = df_summarization[lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "54b6d51f-a359-4ddb-a89b-1176790cce9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gt</th>\n",
       "      <th>Tbank</th>\n",
       "      <th>YandexGPT</th>\n",
       "      <th>Qwen3</th>\n",
       "      <th>summarize_tbank_rank</th>\n",
       "      <th>summarize_yandex_rank</th>\n",
       "      <th>summarize_qwen_rank</th>\n",
       "      <th>sim_scores_tbank</th>\n",
       "      <th>sim_scores_yandex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>В данной работе представлен метод Test-Time Re...</td>\n",
       "      <td>В статье представлен метод Test-Time Reinforc...</td>\n",
       "      <td>В статье представлен метод Test-Time Reinforce...</td>\n",
       "      <td>В данной работе предложен новый метод обучения...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.909943</td>\n",
       "      <td>0.930276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>В статье представлен Transformer — первая архи...</td>\n",
       "      <td>В статье представлен новый архитектурный подх...</td>\n",
       "      <td>В работе представлена новая архитектура нейрон...</td>\n",
       "      <td>Статья представляет архитектуру Transformer — ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.797422</td>\n",
       "      <td>0.852751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>В работе предлагается подход к обучению рекоме...</td>\n",
       "      <td>В данной работе исследуется влияние долгосроч...</td>\n",
       "      <td>В статье изучается влияние долговременной памя...</td>\n",
       "      <td>В статье исследуется влияние долгосрочной памя...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.774107</td>\n",
       "      <td>0.773998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Авторы представляют первый систематический обз...</td>\n",
       "      <td>\\n\\nИсследование посвящено анализу использова...</td>\n",
       "      <td>В статье представлен системный обзор больших я...</td>\n",
       "      <td>Статья представляет собой первый систематическ...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.755156</td>\n",
       "      <td>0.731499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Авторы представляют общий подход к дообучению ...</td>\n",
       "      <td>В статье рассматриваются модели, сочетающие п...</td>\n",
       "      <td>В статье рассматривается проблема ограниченног...</td>\n",
       "      <td>Статья представляет обобщённый подход к тонкой...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.737129</td>\n",
       "      <td>0.688586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Авторы представляют два простых и эффективных ...</td>\n",
       "      <td>В статье представлены два новых архитектурных...</td>\n",
       "      <td>В статье предложены две новые архитектуры моде...</td>\n",
       "      <td>В статье предложены два новых архитектурных по...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.739331</td>\n",
       "      <td>0.708769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>В работе представлено систематическое исследов...</td>\n",
       "      <td>\\n\\nВ статье рассматриваются и анализируются ...</td>\n",
       "      <td>В статье представлены усовершенствованные диза...</td>\n",
       "      <td>В статье представлены продвинутые дизайн-систе...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.856174</td>\n",
       "      <td>0.903531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Авторы представляют LADDER — фреймворк, улучша...</td>\n",
       "      <td>В статье представлен LADDER — метод, улучшающ...</td>\n",
       "      <td>В статье представлен фреймворк LADDER для улуч...</td>\n",
       "      <td>LADDER — это фреймворк, улучшающий способности...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.804446</td>\n",
       "      <td>0.914699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Scalable-Softmax (SSMax) — это новая замена фу...</td>\n",
       "      <td>В статье представлен Scalable-Softmax (SSMax)...</td>\n",
       "      <td>В статье предлагается Scalable-Softmax (SSMax)...</td>\n",
       "      <td>В статье предложен новый метод Scalable-Softma...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.864461</td>\n",
       "      <td>0.898752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Авторы представляют FlashAttention — IO-ориент...</td>\n",
       "      <td>\\nFlashAttention — это новый подход к реализа...</td>\n",
       "      <td>В статье предлагается FlashAttention — алгорит...</td>\n",
       "      <td>FlashAttention — это точный алгоритм внимания,...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.899040</td>\n",
       "      <td>0.914540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  gt  \\\n",
       "0  В данной работе представлен метод Test-Time Re...   \n",
       "1  В статье представлен Transformer — первая архи...   \n",
       "2  В работе предлагается подход к обучению рекоме...   \n",
       "3  Авторы представляют первый систематический обз...   \n",
       "4  Авторы представляют общий подход к дообучению ...   \n",
       "5  Авторы представляют два простых и эффективных ...   \n",
       "6  В работе представлено систематическое исследов...   \n",
       "7  Авторы представляют LADDER — фреймворк, улучша...   \n",
       "8  Scalable-Softmax (SSMax) — это новая замена фу...   \n",
       "9  Авторы представляют FlashAttention — IO-ориент...   \n",
       "\n",
       "                                               Tbank  \\\n",
       "0   В статье представлен метод Test-Time Reinforc...   \n",
       "1   В статье представлен новый архитектурный подх...   \n",
       "2   В данной работе исследуется влияние долгосроч...   \n",
       "3   \\n\\nИсследование посвящено анализу использова...   \n",
       "4   В статье рассматриваются модели, сочетающие п...   \n",
       "5   В статье представлены два новых архитектурных...   \n",
       "6   \\n\\nВ статье рассматриваются и анализируются ...   \n",
       "7   В статье представлен LADDER — метод, улучшающ...   \n",
       "8   В статье представлен Scalable-Softmax (SSMax)...   \n",
       "9   \\nFlashAttention — это новый подход к реализа...   \n",
       "\n",
       "                                           YandexGPT  \\\n",
       "0  В статье представлен метод Test-Time Reinforce...   \n",
       "1  В работе представлена новая архитектура нейрон...   \n",
       "2  В статье изучается влияние долговременной памя...   \n",
       "3  В статье представлен системный обзор больших я...   \n",
       "4  В статье рассматривается проблема ограниченног...   \n",
       "5  В статье предложены две новые архитектуры моде...   \n",
       "6  В статье представлены усовершенствованные диза...   \n",
       "7  В статье представлен фреймворк LADDER для улуч...   \n",
       "8  В статье предлагается Scalable-Softmax (SSMax)...   \n",
       "9  В статье предлагается FlashAttention — алгорит...   \n",
       "\n",
       "                                               Qwen3  summarize_tbank_rank  \\\n",
       "0  В данной работе предложен новый метод обучения...                     1   \n",
       "1  Статья представляет архитектуру Transformer — ...                     3   \n",
       "2  В статье исследуется влияние долгосрочной памя...                     1   \n",
       "3  Статья представляет собой первый систематическ...                     3   \n",
       "4  Статья представляет обобщённый подход к тонкой...                     2   \n",
       "5  В статье предложены два новых архитектурных по...                     3   \n",
       "6  В статье представлены продвинутые дизайн-систе...                     3   \n",
       "7  LADDER — это фреймворк, улучшающий способности...                     2   \n",
       "8  В статье предложен новый метод Scalable-Softma...                     3   \n",
       "9  FlashAttention — это точный алгоритм внимания,...                     1   \n",
       "\n",
       "   summarize_yandex_rank  summarize_qwen_rank  sim_scores_tbank  \\\n",
       "0                      3                    2          0.909943   \n",
       "1                      1                    2          0.797422   \n",
       "2                      2                    3          0.774107   \n",
       "3                      2                    1          0.755156   \n",
       "4                      3                    1          0.737129   \n",
       "5                      2                    1          0.739331   \n",
       "6                      2                    1          0.856174   \n",
       "7                      1                    3          0.804446   \n",
       "8                      2                    1          0.864461   \n",
       "9                      3                    2          0.899040   \n",
       "\n",
       "   sim_scores_yandex  \n",
       "0           0.930276  \n",
       "1           0.852751  \n",
       "2           0.773998  \n",
       "3           0.731499  \n",
       "4           0.688586  \n",
       "5           0.708769  \n",
       "6           0.903531  \n",
       "7           0.914699  \n",
       "8           0.898752  \n",
       "9           0.914540  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "25064ee1-5670-462b-9164-1aa706e4d4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summarize_tbank_rank</th>\n",
       "      <th>summarize_yandex_rank</th>\n",
       "      <th>summarize_qwen_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   summarize_tbank_rank  summarize_yandex_rank  summarize_qwen_rank\n",
       "0                     1                      3                    2\n",
       "1                     3                      1                    2\n",
       "2                     1                      2                    3\n",
       "3                     3                      2                    1\n",
       "4                     2                      3                    1\n",
       "5                     3                      2                    1\n",
       "6                     3                      2                    1\n",
       "7                     2                      1                    3\n",
       "8                     3                      2                    1\n",
       "9                     1                      3                    2"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summarization[['summarize_tbank_rank', 'summarize_yandex_rank', 'summarize_qwen_rank']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5b0e92e5-8479-4b6b-850a-a778db1d4a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "summarize_tbank_rank     2.2\n",
       "summarize_yandex_rank    2.1\n",
       "summarize_qwen_rank      1.7\n",
       "dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summarization[['summarize_tbank_rank', 'summarize_yandex_rank', 'summarize_qwen_rank']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d6e767f4-49bb-4aa5-97e2-df18d42aa781",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summarization.to_csv('summarize_examples.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b393d833-4ccb-4d11-8d50-ece90f80db2f",
   "metadata": {},
   "source": [
    "# Bleu/Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "98a63c3d-2cc7-4f11-8c20-21bc4bfcb607",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('summarize_examples.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1531c41f-0da7-41f4-b990-226ec8b8a43a",
   "metadata": {},
   "source": [
    "## Bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "67eccd17-6d00-4045-8c6f-2c0922db35ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps = df[\"Tbank\"].tolist()\n",
    "refs = df[\"gt\"].tolist()\n",
    "bleu = BLEU(tokenize=\"intl\", smooth_method=\"exp\", effective_order=True)   \n",
    "\n",
    "df[\"bleu_tbank\"] = [\n",
    "    bleu.sentence_score(h, [r]).score for h, r in zip(hyps, refs)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "189e0b22-a24f-4cdb-a365-5393c437585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps = df[\"YandexGPT\"].tolist()\n",
    "refs = df[\"gt\"].tolist()\n",
    "bleu = BLEU(tokenize=\"intl\", smooth_method=\"exp\", effective_order=True)   \n",
    "\n",
    "df[\"bleu_yandex\"] = [\n",
    "    bleu.sentence_score(h, [r]).score for h, r in zip(hyps, refs)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3e61fd00-59be-4e14-b277-b4e89ff12b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps = df[\"Qwen3\"].tolist()\n",
    "refs = df[\"gt\"].tolist()\n",
    "bleu = BLEU(tokenize=\"intl\", smooth_method=\"exp\", effective_order=True)   \n",
    "\n",
    "df[\"bleu_qwen\"] = [\n",
    "    bleu.sentence_score(h, [r]).score for h, r in zip(hyps, refs)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2dd28163-b6e1-4ede-a328-ce43c4a27fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bleu_tbank</th>\n",
       "      <th>bleu_yandex</th>\n",
       "      <th>bleu_qwen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.124650</td>\n",
       "      <td>20.594433</td>\n",
       "      <td>21.681487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.249080</td>\n",
       "      <td>6.779259</td>\n",
       "      <td>1.948774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.707592</td>\n",
       "      <td>8.007145</td>\n",
       "      <td>8.230425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.847037</td>\n",
       "      <td>7.050412</td>\n",
       "      <td>14.343329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.852588</td>\n",
       "      <td>2.320887</td>\n",
       "      <td>5.058517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.148636</td>\n",
       "      <td>5.149729</td>\n",
       "      <td>12.760426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12.118868</td>\n",
       "      <td>14.483633</td>\n",
       "      <td>17.328665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.896288</td>\n",
       "      <td>14.176252</td>\n",
       "      <td>10.095051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.201007</td>\n",
       "      <td>9.626733</td>\n",
       "      <td>12.271704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.649770</td>\n",
       "      <td>8.815559</td>\n",
       "      <td>1.047562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bleu_tbank  bleu_yandex  bleu_qwen\n",
       "0   14.124650    20.594433  21.681487\n",
       "1    3.249080     6.779259   1.948774\n",
       "2    9.707592     8.007145   8.230425\n",
       "3    5.847037     7.050412  14.343329\n",
       "4   14.852588     2.320887   5.058517\n",
       "5    6.148636     5.149729  12.760426\n",
       "6   12.118868    14.483633  17.328665\n",
       "7    5.896288    14.176252  10.095051\n",
       "8    8.201007     9.626733  12.271704\n",
       "9   10.649770     8.815559   1.047562"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['bleu_tbank', 'bleu_yandex', 'bleu_qwen']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9efa2b0f-02d7-4d43-8175-8ec933f3b767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bleu_tbank      9.079552\n",
       "bleu_yandex     9.700404\n",
       "bleu_qwen      10.476594\n",
       "dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['bleu_tbank', 'bleu_yandex', 'bleu_qwen']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bdf0de11-1654-4af1-a2e7-6cbe74597d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('summarize_examples.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bf7607-16e3-4daa-a952-3d851f185ba2",
   "metadata": {},
   "source": [
    "## Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8d07b2dd-6477-4703-a370-9975e9a5705e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('summarize_examples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3e101619-b7e9-407a-b2f7-e451295535ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stem = SnowballStemmer(\"russian\")\n",
    "\n",
    "class RussianTok(tokenizers.Tokenizer):\n",
    "    _re = re.compile(r\"[а-яё]+\", re.I)\n",
    "    def tokenize(self, txt):\n",
    "        return [stem.stem(w) for w in self._re.findall(txt.lower())]\n",
    "\n",
    "ru_tok = RussianTok()\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(\n",
    "    [\"rouge1\", \"rouge2\", \"rougeL\"],\n",
    "    use_stemmer=False,          \n",
    "    tokenizer=ru_tok            # свой токенайзер\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "65e604d2-88e5-4f8d-b929-36979b02e2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_scores = [\n",
    "    scorer.score(ref, hyp)          \n",
    "    for hyp, ref in zip(df[\"Tbank\"], df[\"gt\"])\n",
    "]\n",
    "\n",
    "df[\"rouge1_f_tbank\"] = [s[\"rouge1\"].fmeasure for s in pair_scores]\n",
    "df[\"rouge2_f_tbank\"] = [s[\"rouge2\"].fmeasure for s in pair_scores]\n",
    "df[\"rougeL_f_tbank\"] = [s[\"rougeL\"].fmeasure for s in pair_scores]\n",
    "\n",
    "df[\"rouge1_p_tbank\"] = [s[\"rouge1\"].precision for s in pair_scores]\n",
    "df[\"rouge2_p_tbank\"] = [s[\"rouge2\"].precision for s in pair_scores]\n",
    "df[\"rougeL_p_tbank\"] = [s[\"rougeL\"].precision for s in pair_scores]\n",
    "\n",
    "df[\"rouge1_r_tbank\"] = [s[\"rouge1\"].recall for s in pair_scores]\n",
    "df[\"rouge2_r_tbank\"] = [s[\"rouge2\"].recall for s in pair_scores]\n",
    "df[\"rougeL_r_tbank\"] = [s[\"rougeL\"].recall for s in pair_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ccb97736-1142-4b75-99f7-c895ac2ae77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_scores = [\n",
    "    scorer.score(ref, hyp)          \n",
    "    for hyp, ref in zip(df[\"YandexGPT\"], df[\"gt\"])\n",
    "]\n",
    "\n",
    "df[\"rouge1_f_yandex\"] = [s[\"rouge1\"].fmeasure for s in pair_scores]\n",
    "df[\"rouge2_f_yandex\"] = [s[\"rouge2\"].fmeasure for s in pair_scores]\n",
    "df[\"rougeL_f_yandex\"] = [s[\"rougeL\"].fmeasure for s in pair_scores]\n",
    "\n",
    "df[\"rouge1_p_yandex\"] = [s[\"rouge1\"].precision for s in pair_scores]\n",
    "df[\"rouge2_p_yandex\"] = [s[\"rouge2\"].precision for s in pair_scores]\n",
    "df[\"rougeL_p_yandex\"] = [s[\"rougeL\"].precision for s in pair_scores]\n",
    "\n",
    "df[\"rouge1_r_yandex\"] = [s[\"rouge1\"].recall for s in pair_scores]\n",
    "df[\"rouge2_r_yandex\"] = [s[\"rouge2\"].recall for s in pair_scores]\n",
    "df[\"rougeL_r_yandex\"] = [s[\"rougeL\"].recall for s in pair_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7e3c3c08-09f6-4f0b-abf0-ca552484cebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_scores = [\n",
    "    scorer.score(ref, hyp)          \n",
    "    for hyp, ref in zip(df[\"Qwen3\"], df[\"gt\"])\n",
    "]\n",
    "\n",
    "df[\"rouge1_f_qwen\"] = [s[\"rouge1\"].fmeasure for s in pair_scores]\n",
    "df[\"rouge2_f_qwen\"] = [s[\"rouge2\"].fmeasure for s in pair_scores]\n",
    "df[\"rougeL_f_qwen\"] = [s[\"rougeL\"].fmeasure for s in pair_scores]\n",
    "\n",
    "df[\"rouge1_p_qwen\"] = [s[\"rouge1\"].precision for s in pair_scores]\n",
    "df[\"rouge2_p_qwen\"] = [s[\"rouge2\"].precision for s in pair_scores]\n",
    "df[\"rougeL_p_qwen\"] = [s[\"rougeL\"].precision for s in pair_scores]\n",
    "\n",
    "df[\"rouge1_r_qwen\"] = [s[\"rouge1\"].recall for s in pair_scores]\n",
    "df[\"rouge2_r_qwen\"] = [s[\"rouge2\"].recall for s in pair_scores]\n",
    "df[\"rougeL_r_qwen\"] = [s[\"rougeL\"].recall for s in pair_scores]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cbb020-8070-45f1-9a5e-f8efea18880e",
   "metadata": {},
   "source": [
    "### F-measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "4fe25310-d55b-4901-a0be-f28901cadc62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rouge1_f_tbank    0.454545\n",
       "rouge2_f_tbank    0.128164\n",
       "rougeL_f_tbank    0.288164\n",
       "dtype: float64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['rouge1_f_tbank', 'rouge2_f_tbank', 'rougeL_f_tbank']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "2f3a1441-ec24-464f-8350-e3135b62e253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rouge1_f_yandex    0.458288\n",
       "rouge2_f_yandex    0.126939\n",
       "rougeL_f_yandex    0.296055\n",
       "dtype: float64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['rouge1_f_yandex', 'rouge2_f_yandex', 'rougeL_f_yandex']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c64623d9-6ff8-4540-a713-5d5ed9053eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rouge1_f_qwen    0.460138\n",
       "rouge2_f_qwen    0.154361\n",
       "rougeL_f_qwen    0.314638\n",
       "dtype: float64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['rouge1_f_qwen', 'rouge2_f_qwen', 'rougeL_f_qwen']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ffa453-420d-49e4-830a-52b7d886e746",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ef003792-79a3-49c0-92a7-7f7384579eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rouge1_p_tbank    0.423024\n",
       "rouge2_p_tbank    0.119411\n",
       "rougeL_p_tbank    0.265858\n",
       "dtype: float64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['rouge1_p_tbank', 'rouge2_p_tbank', 'rougeL_p_tbank']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "14a3b0e5-c879-478b-b77a-ed2d73b79460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rouge1_p_yandex    0.446262\n",
       "rouge2_p_yandex    0.123050\n",
       "rougeL_p_yandex    0.287735\n",
       "dtype: float64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['rouge1_p_yandex', 'rouge2_p_yandex', 'rougeL_p_yandex']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "18d619d5-c3e3-427b-ad25-77a2733c01e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rouge1_p_qwen    0.462337\n",
       "rouge2_p_qwen    0.150601\n",
       "rougeL_p_qwen    0.316523\n",
       "dtype: float64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['rouge1_p_qwen', 'rouge2_p_qwen', 'rougeL_p_qwen']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c721d5f8-50a9-4408-a9d6-940f405964e1",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "da111c3f-b408-49e5-a50d-2d8741ed29a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rouge1_r_tbank    0.504198\n",
       "rouge2_r_tbank    0.141827\n",
       "rougeL_r_tbank    0.323061\n",
       "dtype: float64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['rouge1_r_tbank', 'rouge2_r_tbank', 'rougeL_r_tbank']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0022061d-18d9-43a6-aa9f-db3c35dc0da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rouge1_r_yandex    0.483706\n",
       "rouge2_r_yandex    0.134893\n",
       "rougeL_r_yandex    0.313183\n",
       "dtype: float64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['rouge1_r_yandex', 'rouge2_r_yandex', 'rougeL_r_yandex']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e8e1d918-dc25-4dde-8dab-24b748cbe28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rouge1_r_qwen    0.472849\n",
       "rouge2_r_qwen    0.161655\n",
       "rougeL_r_qwen    0.322263\n",
       "dtype: float64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['rouge1_r_qwen', 'rouge2_r_qwen', 'rougeL_r_qwen']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "455fe916-42f6-4987-9542-19702409b461",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('summarize_examples.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e8dc8f-6846-4cb1-9cf9-26a9f2596e67",
   "metadata": {},
   "source": [
    "# Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a46306cc-1c47-4608-8818-0194851444d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = ['https://arxiv.org/pdf/2504.16084',\n",
    "        'https://arxiv.org/abs/1706.03762',\n",
    "        'https://arxiv.org/pdf/2112.02242',\n",
    "        'https://arxiv.org/pdf/2405.12819',\n",
    "        'https://arxiv.org/pdf/2005.11401',\n",
    "        'https://arxiv.org/pdf/1301.3781',\n",
    "        'https://arxiv.org/pdf/2501.07391',\n",
    "        'https://arxiv.org/pdf/2503.00735',\n",
    "        'https://arxiv.org/pdf/2501.19399',\n",
    "        'https://arxiv.org/pdf/2205.14135']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a6ead235-3e9f-4045-82ea-259d54994ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "# Загрузим SOTA эмбеддер для русских текстов\n",
    "embedder = SentenceTransformer(\"ai-forever/FRIDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ec85615-8687-4313-9fc1-24b0fa656061",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summarization = pd.read_csv('summarize_examples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49396b78-e38e-46fd-a877-fb2b55f72f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gt</th>\n",
       "      <th>Tbank</th>\n",
       "      <th>YandexGPT</th>\n",
       "      <th>summarize_best_llm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>В данной работе представлен метод Test-Time Re...</td>\n",
       "      <td>В статье представлен метод Test-Time Reinforc...</td>\n",
       "      <td>В статье представлен метод Test-Time Reinforce...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>В статье представлен Transformer — первая архи...</td>\n",
       "      <td>В статье представлен новый архитектурный подх...</td>\n",
       "      <td>В работе представлена новая архитектура нейрон...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>В работе предлагается подход к обучению рекоме...</td>\n",
       "      <td>В данной работе исследуется влияние долгосроч...</td>\n",
       "      <td>В статье изучается влияние долговременной памя...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Авторы представляют первый систематический обз...</td>\n",
       "      <td>\\n\\nИсследование посвящено анализу использова...</td>\n",
       "      <td>В статье представлен системный обзор больших я...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Авторы представляют общий подход к дообучению ...</td>\n",
       "      <td>В статье рассматриваются модели, сочетающие п...</td>\n",
       "      <td>В статье рассматривается проблема ограниченног...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Авторы представляют два простых и эффективных ...</td>\n",
       "      <td>В статье представлены два новых архитектурных...</td>\n",
       "      <td>В статье предложены две новые архитектуры моде...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>В работе представлено систематическое исследов...</td>\n",
       "      <td>\\n\\nВ статье рассматриваются и анализируются ...</td>\n",
       "      <td>В статье представлены усовершенствованные диза...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Авторы представляют LADDER — фреймворк, улучша...</td>\n",
       "      <td>В статье представлен LADDER — метод, улучшающ...</td>\n",
       "      <td>В статье представлен фреймворк LADDER для улуч...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Scalable-Softmax (SSMax) — это новая замена фу...</td>\n",
       "      <td>В статье представлен Scalable-Softmax (SSMax)...</td>\n",
       "      <td>В статье предлагается Scalable-Softmax (SSMax)...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Авторы представляют FlashAttention — IO-ориент...</td>\n",
       "      <td>\\nFlashAttention — это новый подход к реализа...</td>\n",
       "      <td>В статье предлагается FlashAttention — алгорит...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  gt  \\\n",
       "0  В данной работе представлен метод Test-Time Re...   \n",
       "1  В статье представлен Transformer — первая архи...   \n",
       "2  В работе предлагается подход к обучению рекоме...   \n",
       "3  Авторы представляют первый систематический обз...   \n",
       "4  Авторы представляют общий подход к дообучению ...   \n",
       "5  Авторы представляют два простых и эффективных ...   \n",
       "6  В работе представлено систематическое исследов...   \n",
       "7  Авторы представляют LADDER — фреймворк, улучша...   \n",
       "8  Scalable-Softmax (SSMax) — это новая замена фу...   \n",
       "9  Авторы представляют FlashAttention — IO-ориент...   \n",
       "\n",
       "                                               Tbank  \\\n",
       "0   В статье представлен метод Test-Time Reinforc...   \n",
       "1   В статье представлен новый архитектурный подх...   \n",
       "2   В данной работе исследуется влияние долгосроч...   \n",
       "3   \\n\\nИсследование посвящено анализу использова...   \n",
       "4   В статье рассматриваются модели, сочетающие п...   \n",
       "5   В статье представлены два новых архитектурных...   \n",
       "6   \\n\\nВ статье рассматриваются и анализируются ...   \n",
       "7   В статье представлен LADDER — метод, улучшающ...   \n",
       "8   В статье представлен Scalable-Softmax (SSMax)...   \n",
       "9   \\nFlashAttention — это новый подход к реализа...   \n",
       "\n",
       "                                           YandexGPT  summarize_best_llm  \n",
       "0  В статье представлен метод Test-Time Reinforce...                   1  \n",
       "1  В работе представлена новая архитектура нейрон...                   1  \n",
       "2  В статье изучается влияние долговременной памя...                   0  \n",
       "3  В статье представлен системный обзор больших я...                   1  \n",
       "4  В статье рассматривается проблема ограниченног...                   0  \n",
       "5  В статье предложены две новые архитектуры моде...                   0  \n",
       "6  В статье представлены усовершенствованные диза...                   0  \n",
       "7  В статье представлен фреймворк LADDER для улуч...                   1  \n",
       "8  В статье предлагается Scalable-Softmax (SSMax)...                   1  \n",
       "9  В статье предлагается FlashAttention — алгорит...                   0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3518b2e6-0496-4ea9-8be4-2e14f95577a1",
   "metadata": {},
   "source": [
    "## Tbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0800f00-f12d-4039-bb6a-eb620ef09840",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_answers = df_summarization['gt'].tolist()\n",
    "generated_answers = df_summarization['Tbank'].tolist()\n",
    "articles = urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8045867d-79a7-453a-8b67-91beb8e854d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from typing import List, Dict\n",
    "\n",
    "def evaluate_similarity_frida(\n",
    "    questions: List[str], \n",
    "    generated_answers: List[str],\n",
    "    reference_answers: List[str]\n",
    ") -> List[float]:\n",
    "    \"\"\"\n",
    "    Вычисляет косинусную близость между сгенерированными и эталонными ответами\n",
    "    с помощью FRIDA SentenceTransformer.\n",
    "\n",
    "    :param questions: Список вопросов\n",
    "    :param generated_answers: Список ответов, сгенерированных LLM.\n",
    "    :param reference_answers: Список эталонных ответов.\n",
    "        \n",
    "    :return: Косинусная близость по каждой паре.\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = (\n",
    "        [f\"search_document: {text}\" for text in generated_answers] +\n",
    "        [f\"search_document: {text}\" for text in reference_answers]\n",
    "    )\n",
    "\n",
    "    embeddings = embedder.encode(inputs, convert_to_tensor=True)\n",
    "\n",
    "    gen_embs = embeddings[:len(generated_answers)]\n",
    "    ref_embs = embeddings[len(generated_answers):]\n",
    "\n",
    "    sim_scores = (gen_embs @ ref_embs.T).diagonal().tolist()\n",
    "    print(len(sim_scores))\n",
    "    for i, (question, generated, reference) in enumerate(zip(questions, generated_answers, reference_answers)):\n",
    "        \n",
    "        print(f\"Статья: {question}:\")\n",
    "        #print(f\"Ожидалось:\\n{reference}\")\n",
    "        #print(f\"Предсказано:\\n{generated}\")\n",
    "        print(f\"cosine_similarity: {sim_scores[i]:.4f}\\n\")\n",
    "        print(100 * '*')\n",
    "\n",
    "    avg_sim = sum(sim_scores) / len(sim_scores)\n",
    "    print(\"\\nОбщая оценка\")\n",
    "    print(f\"Средний similarity: {avg_sim:.4f}\")\n",
    "    \n",
    "    return sim_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f948a36-97d9-4a04-9d20-c9100e466fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Статья: https://arxiv.org/pdf/2504.16084:\n",
      "cosine_similarity: 0.9099\n",
      "\n",
      "****************************************************************************************************\n",
      "Статья: https://arxiv.org/abs/1706.03762:\n",
      "cosine_similarity: 0.7974\n",
      "\n",
      "****************************************************************************************************\n",
      "Статья: https://arxiv.org/pdf/2112.02242:\n",
      "cosine_similarity: 0.7741\n",
      "\n",
      "****************************************************************************************************\n",
      "Статья: https://arxiv.org/pdf/2405.12819:\n",
      "cosine_similarity: 0.7552\n",
      "\n",
      "****************************************************************************************************\n",
      "Статья: https://arxiv.org/pdf/2005.11401:\n",
      "cosine_similarity: 0.7371\n",
      "\n",
      "****************************************************************************************************\n",
      "Статья: https://arxiv.org/pdf/1301.3781:\n",
      "cosine_similarity: 0.7393\n",
      "\n",
      "****************************************************************************************************\n",
      "Статья: https://arxiv.org/pdf/2501.07391:\n",
      "cosine_similarity: 0.8562\n",
      "\n",
      "****************************************************************************************************\n",
      "Статья: https://arxiv.org/pdf/2503.00735:\n",
      "cosine_similarity: 0.8044\n",
      "\n",
      "****************************************************************************************************\n",
      "Статья: https://arxiv.org/pdf/2501.19399:\n",
      "cosine_similarity: 0.8645\n",
      "\n",
      "****************************************************************************************************\n",
      "Статья: https://arxiv.org/pdf/2205.14135:\n",
      "cosine_similarity: 0.8990\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "Общая оценка\n",
      "Средний similarity: 0.8137\n"
     ]
    }
   ],
   "source": [
    "scores_tbank = evaluate_similarity_frida(articles, generated_answers, reference_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98b95550-1521-4823-a560-904a20eac081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9099433422088623,\n",
       " 0.7974216341972351,\n",
       " 0.7741065621376038,\n",
       " 0.7551555037498474,\n",
       " 0.7371289134025574,\n",
       " 0.7393308281898499,\n",
       " 0.8561741709709167,\n",
       " 0.8044455647468567,\n",
       " 0.8644611239433289,\n",
       " 0.8990402817726135]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_tbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8c09745-e9e0-41b7-ae59-fcd5dcbec00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summarization['sim_scores_tbank'] = scores_tbank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61846c86-f397-4d5a-9250-e9d2669520a2",
   "metadata": {},
   "source": [
    "## YandexGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a923b09d-5b53-4e2c-b2cb-814b264633de",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_answers = df_summarization['gt'].tolist()\n",
    "generated_answers = df_summarization['YandexGPT'].tolist()\n",
    "articles = urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8981d32a-a4f7-4bef-81a7-b9da327f53ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Статья: https://arxiv.org/pdf/2504.16084:\n",
      "cosine_similarity: 0.9303\n",
      "\n",
      "****************************************************************************************************\n",
      "Статья: https://arxiv.org/abs/1706.03762:\n",
      "cosine_similarity: 0.8528\n",
      "\n",
      "****************************************************************************************************\n",
      "Статья: https://arxiv.org/pdf/2112.02242:\n",
      "cosine_similarity: 0.7740\n",
      "\n",
      "****************************************************************************************************\n",
      "Статья: https://arxiv.org/pdf/2405.12819:\n",
      "cosine_similarity: 0.7315\n",
      "\n",
      "****************************************************************************************************\n",
      "Статья: https://arxiv.org/pdf/2005.11401:\n",
      "cosine_similarity: 0.6886\n",
      "\n",
      "****************************************************************************************************\n",
      "Статья: https://arxiv.org/pdf/1301.3781:\n",
      "cosine_similarity: 0.7088\n",
      "\n",
      "****************************************************************************************************\n",
      "Статья: https://arxiv.org/pdf/2501.07391:\n",
      "cosine_similarity: 0.9035\n",
      "\n",
      "****************************************************************************************************\n",
      "Статья: https://arxiv.org/pdf/2503.00735:\n",
      "cosine_similarity: 0.9147\n",
      "\n",
      "****************************************************************************************************\n",
      "Статья: https://arxiv.org/pdf/2501.19399:\n",
      "cosine_similarity: 0.8988\n",
      "\n",
      "****************************************************************************************************\n",
      "Статья: https://arxiv.org/pdf/2205.14135:\n",
      "cosine_similarity: 0.9145\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "Общая оценка\n",
      "Средний similarity: 0.8317\n"
     ]
    }
   ],
   "source": [
    "scores_yandex = evaluate_similarity_frida(articles, generated_answers, reference_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b186da08-bbb9-4b9c-bb29-f6f7e3aa6a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summarization['sim_scores_yandex'] = scores_yandex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15eb6d26-a8aa-4294-952d-7f405f6e05c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gt</th>\n",
       "      <th>Tbank</th>\n",
       "      <th>YandexGPT</th>\n",
       "      <th>summarize_best_llm</th>\n",
       "      <th>sim_scores_tbank</th>\n",
       "      <th>sim_scores_yandex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>В данной работе представлен метод Test-Time Re...</td>\n",
       "      <td>В статье представлен метод Test-Time Reinforc...</td>\n",
       "      <td>В статье представлен метод Test-Time Reinforce...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.909943</td>\n",
       "      <td>0.930276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>В статье представлен Transformer — первая архи...</td>\n",
       "      <td>В статье представлен новый архитектурный подх...</td>\n",
       "      <td>В работе представлена новая архитектура нейрон...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.797422</td>\n",
       "      <td>0.852751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>В работе предлагается подход к обучению рекоме...</td>\n",
       "      <td>В данной работе исследуется влияние долгосроч...</td>\n",
       "      <td>В статье изучается влияние долговременной памя...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.774107</td>\n",
       "      <td>0.773998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Авторы представляют первый систематический обз...</td>\n",
       "      <td>\\n\\nИсследование посвящено анализу использова...</td>\n",
       "      <td>В статье представлен системный обзор больших я...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.755156</td>\n",
       "      <td>0.731499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Авторы представляют общий подход к дообучению ...</td>\n",
       "      <td>В статье рассматриваются модели, сочетающие п...</td>\n",
       "      <td>В статье рассматривается проблема ограниченног...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.737129</td>\n",
       "      <td>0.688586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Авторы представляют два простых и эффективных ...</td>\n",
       "      <td>В статье представлены два новых архитектурных...</td>\n",
       "      <td>В статье предложены две новые архитектуры моде...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.739331</td>\n",
       "      <td>0.708769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>В работе представлено систематическое исследов...</td>\n",
       "      <td>\\n\\nВ статье рассматриваются и анализируются ...</td>\n",
       "      <td>В статье представлены усовершенствованные диза...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.856174</td>\n",
       "      <td>0.903531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Авторы представляют LADDER — фреймворк, улучша...</td>\n",
       "      <td>В статье представлен LADDER — метод, улучшающ...</td>\n",
       "      <td>В статье представлен фреймворк LADDER для улуч...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.804446</td>\n",
       "      <td>0.914699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Scalable-Softmax (SSMax) — это новая замена фу...</td>\n",
       "      <td>В статье представлен Scalable-Softmax (SSMax)...</td>\n",
       "      <td>В статье предлагается Scalable-Softmax (SSMax)...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.864461</td>\n",
       "      <td>0.898752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Авторы представляют FlashAttention — IO-ориент...</td>\n",
       "      <td>\\nFlashAttention — это новый подход к реализа...</td>\n",
       "      <td>В статье предлагается FlashAttention — алгорит...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.899040</td>\n",
       "      <td>0.914540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  gt  \\\n",
       "0  В данной работе представлен метод Test-Time Re...   \n",
       "1  В статье представлен Transformer — первая архи...   \n",
       "2  В работе предлагается подход к обучению рекоме...   \n",
       "3  Авторы представляют первый систематический обз...   \n",
       "4  Авторы представляют общий подход к дообучению ...   \n",
       "5  Авторы представляют два простых и эффективных ...   \n",
       "6  В работе представлено систематическое исследов...   \n",
       "7  Авторы представляют LADDER — фреймворк, улучша...   \n",
       "8  Scalable-Softmax (SSMax) — это новая замена фу...   \n",
       "9  Авторы представляют FlashAttention — IO-ориент...   \n",
       "\n",
       "                                               Tbank  \\\n",
       "0   В статье представлен метод Test-Time Reinforc...   \n",
       "1   В статье представлен новый архитектурный подх...   \n",
       "2   В данной работе исследуется влияние долгосроч...   \n",
       "3   \\n\\nИсследование посвящено анализу использова...   \n",
       "4   В статье рассматриваются модели, сочетающие п...   \n",
       "5   В статье представлены два новых архитектурных...   \n",
       "6   \\n\\nВ статье рассматриваются и анализируются ...   \n",
       "7   В статье представлен LADDER — метод, улучшающ...   \n",
       "8   В статье представлен Scalable-Softmax (SSMax)...   \n",
       "9   \\nFlashAttention — это новый подход к реализа...   \n",
       "\n",
       "                                           YandexGPT  summarize_best_llm  \\\n",
       "0  В статье представлен метод Test-Time Reinforce...                   1   \n",
       "1  В работе представлена новая архитектура нейрон...                   1   \n",
       "2  В статье изучается влияние долговременной памя...                   0   \n",
       "3  В статье представлен системный обзор больших я...                   1   \n",
       "4  В статье рассматривается проблема ограниченног...                   0   \n",
       "5  В статье предложены две новые архитектуры моде...                   0   \n",
       "6  В статье представлены усовершенствованные диза...                   0   \n",
       "7  В статье представлен фреймворк LADDER для улуч...                   1   \n",
       "8  В статье предлагается Scalable-Softmax (SSMax)...                   1   \n",
       "9  В статье предлагается FlashAttention — алгорит...                   0   \n",
       "\n",
       "   sim_scores_tbank  sim_scores_yandex  \n",
       "0          0.909943           0.930276  \n",
       "1          0.797422           0.852751  \n",
       "2          0.774107           0.773998  \n",
       "3          0.755156           0.731499  \n",
       "4          0.737129           0.688586  \n",
       "5          0.739331           0.708769  \n",
       "6          0.856174           0.903531  \n",
       "7          0.804446           0.914699  \n",
       "8          0.864461           0.898752  \n",
       "9          0.899040           0.914540  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cac5a91-bee7-4fbe-96d1-cc5e5e7786ab",
   "metadata": {},
   "source": [
    "## Qwen3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "66f12a06-1230-48a0-a326-b887e07825d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_answers = df_summarization['gt'].tolist()\n",
    "generated_answers = df_summarization['Qwen3'].tolist()\n",
    "articles = urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "34351e24-cf9a-438a-bf4d-1e0344671d6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Статья: https://arxiv.org/pdf/2504.16084:\n",
      "cosine_similarity: 0.9530\n",
      "\n",
      "****************************************************************************************************\n",
      "Статья: https://arxiv.org/abs/1706.03762:\n",
      "cosine_similarity: 0.8079\n",
      "\n",
      "****************************************************************************************************\n",
      "Статья: https://arxiv.org/pdf/2112.02242:\n",
      "cosine_similarity: 0.7632\n",
      "\n",
      "****************************************************************************************************\n",
      "Статья: https://arxiv.org/pdf/2405.12819:\n",
      "cosine_similarity: 0.7767\n",
      "\n",
      "****************************************************************************************************\n",
      "Статья: https://arxiv.org/pdf/2005.11401:\n",
      "cosine_similarity: 0.7756\n",
      "\n",
      "****************************************************************************************************\n",
      "Статья: https://arxiv.org/pdf/1301.3781:\n",
      "cosine_similarity: 0.8769\n",
      "\n",
      "****************************************************************************************************\n",
      "Статья: https://arxiv.org/pdf/2501.07391:\n",
      "cosine_similarity: 0.7812\n",
      "\n",
      "****************************************************************************************************\n",
      "Статья: https://arxiv.org/pdf/2503.00735:\n",
      "cosine_similarity: 0.9197\n",
      "\n",
      "****************************************************************************************************\n",
      "Статья: https://arxiv.org/pdf/2501.19399:\n",
      "cosine_similarity: 0.9110\n",
      "\n",
      "****************************************************************************************************\n",
      "Статья: https://arxiv.org/pdf/2205.14135:\n",
      "cosine_similarity: 0.8464\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "Общая оценка\n",
      "Средний similarity: 0.8412\n"
     ]
    }
   ],
   "source": [
    "scores_qwen = evaluate_similarity_frida(articles, generated_answers, reference_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ec84613d-8a7a-4136-a68b-757366cd7e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_19996\\3967206300.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_summarization['sim_scores_qwen'] = scores_qwen\n"
     ]
    }
   ],
   "source": [
    "df_summarization['sim_scores_qwen'] = scores_qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4d442161-6b74-4650-85b0-fbcfa9e8c240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gt</th>\n",
       "      <th>Tbank</th>\n",
       "      <th>YandexGPT</th>\n",
       "      <th>Qwen3</th>\n",
       "      <th>summarize_tbank_rank</th>\n",
       "      <th>summarize_yandex_rank</th>\n",
       "      <th>summarize_qwen_rank</th>\n",
       "      <th>sim_scores_tbank</th>\n",
       "      <th>sim_scores_yandex</th>\n",
       "      <th>sim_scores_qwen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>В данной работе представлен метод Test-Time Re...</td>\n",
       "      <td>В статье представлен метод Test-Time Reinforc...</td>\n",
       "      <td>В статье представлен метод Test-Time Reinforce...</td>\n",
       "      <td>В данной работе предложен новый метод обучения...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.909943</td>\n",
       "      <td>0.930276</td>\n",
       "      <td>0.953033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>В статье представлен Transformer — первая архи...</td>\n",
       "      <td>В статье представлен новый архитектурный подх...</td>\n",
       "      <td>В работе представлена новая архитектура нейрон...</td>\n",
       "      <td>Статья представляет архитектуру Transformer — ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.797422</td>\n",
       "      <td>0.852751</td>\n",
       "      <td>0.807929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>В работе предлагается подход к обучению рекоме...</td>\n",
       "      <td>В данной работе исследуется влияние долгосроч...</td>\n",
       "      <td>В статье изучается влияние долговременной памя...</td>\n",
       "      <td>В статье исследуется влияние долгосрочной памя...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.774107</td>\n",
       "      <td>0.773998</td>\n",
       "      <td>0.763235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Авторы представляют первый систематический обз...</td>\n",
       "      <td>\\n\\nИсследование посвящено анализу использова...</td>\n",
       "      <td>В статье представлен системный обзор больших я...</td>\n",
       "      <td>Статья представляет собой первый систематическ...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.755156</td>\n",
       "      <td>0.731499</td>\n",
       "      <td>0.776702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Авторы представляют общий подход к дообучению ...</td>\n",
       "      <td>В статье рассматриваются модели, сочетающие п...</td>\n",
       "      <td>В статье рассматривается проблема ограниченног...</td>\n",
       "      <td>Статья представляет обобщённый подход к тонкой...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.737129</td>\n",
       "      <td>0.688586</td>\n",
       "      <td>0.775555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Авторы представляют два простых и эффективных ...</td>\n",
       "      <td>В статье представлены два новых архитектурных...</td>\n",
       "      <td>В статье предложены две новые архитектуры моде...</td>\n",
       "      <td>В статье предложены два новых архитектурных по...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.739331</td>\n",
       "      <td>0.708769</td>\n",
       "      <td>0.876854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>В работе представлено систематическое исследов...</td>\n",
       "      <td>\\n\\nВ статье рассматриваются и анализируются ...</td>\n",
       "      <td>В статье представлены усовершенствованные диза...</td>\n",
       "      <td>В статье представлены продвинутые дизайн-систе...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.856174</td>\n",
       "      <td>0.903531</td>\n",
       "      <td>0.781188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Авторы представляют LADDER — фреймворк, улучша...</td>\n",
       "      <td>В статье представлен LADDER — метод, улучшающ...</td>\n",
       "      <td>В статье представлен фреймворк LADDER для улуч...</td>\n",
       "      <td>LADDER — это фреймворк, улучшающий способности...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.804446</td>\n",
       "      <td>0.914699</td>\n",
       "      <td>0.919719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Scalable-Softmax (SSMax) — это новая замена фу...</td>\n",
       "      <td>В статье представлен Scalable-Softmax (SSMax)...</td>\n",
       "      <td>В статье предлагается Scalable-Softmax (SSMax)...</td>\n",
       "      <td>В статье предложен новый метод Scalable-Softma...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.864461</td>\n",
       "      <td>0.898752</td>\n",
       "      <td>0.911014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Авторы представляют FlashAttention — IO-ориент...</td>\n",
       "      <td>\\nFlashAttention — это новый подход к реализа...</td>\n",
       "      <td>В статье предлагается FlashAttention — алгорит...</td>\n",
       "      <td>FlashAttention — это точный алгоритм внимания,...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.899040</td>\n",
       "      <td>0.914540</td>\n",
       "      <td>0.846391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  gt  \\\n",
       "0  В данной работе представлен метод Test-Time Re...   \n",
       "1  В статье представлен Transformer — первая архи...   \n",
       "2  В работе предлагается подход к обучению рекоме...   \n",
       "3  Авторы представляют первый систематический обз...   \n",
       "4  Авторы представляют общий подход к дообучению ...   \n",
       "5  Авторы представляют два простых и эффективных ...   \n",
       "6  В работе представлено систематическое исследов...   \n",
       "7  Авторы представляют LADDER — фреймворк, улучша...   \n",
       "8  Scalable-Softmax (SSMax) — это новая замена фу...   \n",
       "9  Авторы представляют FlashAttention — IO-ориент...   \n",
       "\n",
       "                                               Tbank  \\\n",
       "0   В статье представлен метод Test-Time Reinforc...   \n",
       "1   В статье представлен новый архитектурный подх...   \n",
       "2   В данной работе исследуется влияние долгосроч...   \n",
       "3   \\n\\nИсследование посвящено анализу использова...   \n",
       "4   В статье рассматриваются модели, сочетающие п...   \n",
       "5   В статье представлены два новых архитектурных...   \n",
       "6   \\n\\nВ статье рассматриваются и анализируются ...   \n",
       "7   В статье представлен LADDER — метод, улучшающ...   \n",
       "8   В статье представлен Scalable-Softmax (SSMax)...   \n",
       "9   \\nFlashAttention — это новый подход к реализа...   \n",
       "\n",
       "                                           YandexGPT  \\\n",
       "0  В статье представлен метод Test-Time Reinforce...   \n",
       "1  В работе представлена новая архитектура нейрон...   \n",
       "2  В статье изучается влияние долговременной памя...   \n",
       "3  В статье представлен системный обзор больших я...   \n",
       "4  В статье рассматривается проблема ограниченног...   \n",
       "5  В статье предложены две новые архитектуры моде...   \n",
       "6  В статье представлены усовершенствованные диза...   \n",
       "7  В статье представлен фреймворк LADDER для улуч...   \n",
       "8  В статье предлагается Scalable-Softmax (SSMax)...   \n",
       "9  В статье предлагается FlashAttention — алгорит...   \n",
       "\n",
       "                                               Qwen3  summarize_tbank_rank  \\\n",
       "0  В данной работе предложен новый метод обучения...                     1   \n",
       "1  Статья представляет архитектуру Transformer — ...                     3   \n",
       "2  В статье исследуется влияние долгосрочной памя...                     1   \n",
       "3  Статья представляет собой первый систематическ...                     3   \n",
       "4  Статья представляет обобщённый подход к тонкой...                     2   \n",
       "5  В статье предложены два новых архитектурных по...                     3   \n",
       "6  В статье представлены продвинутые дизайн-систе...                     3   \n",
       "7  LADDER — это фреймворк, улучшающий способности...                     2   \n",
       "8  В статье предложен новый метод Scalable-Softma...                     3   \n",
       "9  FlashAttention — это точный алгоритм внимания,...                     1   \n",
       "\n",
       "   summarize_yandex_rank  summarize_qwen_rank  sim_scores_tbank  \\\n",
       "0                      3                    2          0.909943   \n",
       "1                      1                    2          0.797422   \n",
       "2                      2                    3          0.774107   \n",
       "3                      2                    1          0.755156   \n",
       "4                      3                    1          0.737129   \n",
       "5                      2                    1          0.739331   \n",
       "6                      2                    1          0.856174   \n",
       "7                      1                    3          0.804446   \n",
       "8                      2                    1          0.864461   \n",
       "9                      3                    2          0.899040   \n",
       "\n",
       "   sim_scores_yandex  sim_scores_qwen  \n",
       "0           0.930276         0.953033  \n",
       "1           0.852751         0.807929  \n",
       "2           0.773998         0.763235  \n",
       "3           0.731499         0.776702  \n",
       "4           0.688586         0.775555  \n",
       "5           0.708769         0.876854  \n",
       "6           0.903531         0.781188  \n",
       "7           0.914699         0.919719  \n",
       "8           0.898752         0.911014  \n",
       "9           0.914540         0.846391  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6a85ff7a-2fb8-4fd7-9999-c40ad0570277",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summarization.to_csv('summarize_examples.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e431e17f-986f-43d0-a690-105089658257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sim_scores_tbank     0.813721\n",
       "sim_scores_yandex    0.831740\n",
       "sim_scores_qwen      0.841162\n",
       "dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summarization[['sim_scores_tbank', 'sim_scores_yandex', 'sim_scores_qwen']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9eaf6022-0a77-445c-bbda-e9d5cd7358ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summarization.to_csv('summarize_examples.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb4677a-be2c-4029-b8ae-788fb3cd67c5",
   "metadata": {},
   "source": [
    "# Среднее время суммаризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce221867-4a1d-4659-b2a3-c4e87d04e434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее время суммаризации Tbank: 15 сек\n",
      "Среднее время суммаризации Yandex: 12 сек\n",
      "Среднее время суммаризации Qwen3: 17 сек\n"
     ]
    }
   ],
   "source": [
    "print(f'Среднее время суммаризации Tbank: 15 сек')\n",
    "print(f'Среднее время суммаризации Yandex: 12 сек')\n",
    "print(f'Среднее время суммаризации Qwen3: 17 сек')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155a3cf9-4ee5-4c05-995e-906058f8dbbf",
   "metadata": {},
   "source": [
    "# Средние ранги на основе similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "1ac64cfd-9e39-4e5a-b4c4-88db8890a386",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test_results/summarize_examples.csv')\n",
    "ranked = df[['sim_scores_tbank', 'sim_scores_yandex', 'sim_scores_qwen']].rank(axis=1, method='min', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "06260289-c40f-40e1-84b5-e45ced332c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sim_scores_qwen      1.7\n",
       "sim_scores_yandex    2.0\n",
       "sim_scores_tbank     2.3\n",
       "dtype: float64"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked.mean().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b09e71b-8d60-423b-98ae-345225d9b8c2",
   "metadata": {},
   "source": [
    "# Оценка генератора"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36e4ea2-dcb9-40df-931f-ec2da5782d87",
   "metadata": {},
   "source": [
    "Оценивать будем аналогичным образом с суммаризацией - намайним вопросы по статьям, эталонные ответы на них и в дальнейшем будем применять LLM as a judge + cos similarity подход"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69379af6-e7da-4cf4-a2b0-4be1f3694344",
   "metadata": {},
   "source": [
    "## Генерация эталонных ответов по 50 вопросам"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05049586-8cd7-41b5-9e85-93b20b89bc59",
   "metadata": {},
   "source": [
    "### Статья Attention is all you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a66c359d-62cc-4c77-a7f6-d9e26a4cd298",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_url = \"https://arxiv.org/abs/1706.03762\"\n",
    "arxiv_id = extract_arxiv_id(arxiv_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7283f03c-68ff-4b96-986f-762fa8242763",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['Какой оптимайзер и гиперпараметры использовались в модели?',\n",
    "            'Какие архитектурные компоненты заменяет Transformer в традиционных sequence-to-sequence моделях?',\n",
    "             'Что такое Scaled Dot-Product Attention и зачем в нем используется деление на √dk?',\n",
    "             'Как устроена структура encoder и decoder в Transformer?',\n",
    "             'Почему Multi-Head Attention улучшает производительность по сравнению с одной головой внимания?',\n",
    "             'Какие функции выполняют позиционные кодировки и почему были выбраны синусоиды?',\n",
    "             'В чем преимущества self-attention по сравнению с рекуррентными и сверточными слоями в плане вычислительной сложности и длины пути зависимостей?',\n",
    "             'Какие техники регуляризации использовались при обучении Transformer?',\n",
    "             'Какие результаты Transformer показал на задачах перевода EN→DE и EN→FR по сравнению с предыдущими SOTA?',\n",
    "             'Почему Transformer позволяет более эффективную параллелизацию при обучении?'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "771b6270-23bb-42d6-9454-0390d10bef1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = ['''В оригинальной статье использовался Adam с параметрами: β₁=0.9, β₂=0.98, ε=1e−9. Learning rate варьировался по scheduler’у с warm-up:\n",
    "lr = 𝑑 model − 0.5 ⋅ min(step−0.5,step⋅warmup_steps−1.5)lr=d model−0.5​⋅min(step −0.5,step⋅warmup_steps −1.5)\n",
    "Также использовался dropout (0.1) и label smoothing (ε=0.1).''',\n",
    "     'Transformer заменяет RNN или LSTM/GRU, использовавшиеся в encoder/decoder, на self-attention и feed-forward слои. Он также убирает необходимость в рекурсии.',\n",
    "     '''Это механизм внимания, который вычисляет:\n",
    "Attention(𝑄,𝐾,𝑉)=softmax(𝑄𝐾𝑇𝑑𝑘)Attention(Q,K,V)=softmax(dk​​QK T)\n",
    "Деление на 𝑑𝑘 предотвращает слишком большие значения dot product, которые могли бы привести к маленьким градиентам из-за saturation softmax.''',\n",
    "     'Encoder: N одинаковых блоков (обычно N=6), каждый включает: Multi-Head Self-Attention → Add & Norm → Feed-Forward → Add & Norm. Decoder: тоже N блоков, но с дополнительным masked self-attention и encoder-decoder attention.',\n",
    "     'Потому что каждая \"голова\" обучается фокусироваться на разных аспектах входа — синтаксис, семантика, позиционные зависимости и т.д., давая более богатое представление.',\n",
    "     'Позиционные кодировки добавляют информацию о порядке токенов, который теряется в self-attention. Синусоиды позволяют модели экстраполировать на более длинные последовательности, чем те, что были в обучении.',\n",
    "     'Self-attention: O(n²) по длине последовательности, но все элементы обрабатываются параллельно. RNN: O(n), но последовательно (нет параллелизма). Conv: O(log n) глубина, но требует много фильтров. Self-attention обеспечивает короткий путь между любыми двумя токенами.',\n",
    "     'Dropout (в attention, feed-forward, embeddings). Label smoothing. Early stopping, при необходимости',\n",
    "     '''EN→DE: BLEU 28.4 (vs. предыдущие ~26.4)\n",
    "EN→FR: BLEU 41.8 (vs. ~40.4) \n",
    "Transformer превзошел все предыдущие seq2seq модели, включая LSTM + attention.''',\n",
    "     '''Потому что self-attention не требует последовательной обработки, как в RNN — все токены обрабатываются одновременно, что идеально для GPU/TPU.''']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1b9d166d-a621-456d-aa27-cda4ec268e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "df['Questions'] = questions\n",
    "df['gt'] = gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a1cb9817-1a36-4906-b950-d128e3162a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_results/article_1_questions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b57159-f8e0-47a1-8081-97830974e73f",
   "metadata": {},
   "source": [
    "### Статья TTRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "fcc3fa5d-7acf-4785-a934-c1959fc6a020",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_url = \"https://arxiv.org/pdf/2504.16084\"\n",
    "arxiv_id = extract_arxiv_id(arxiv_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4fc8be02-f977-432a-9ca5-5f394873b3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['В чем заключается основная идея метода Test-Time Reinforcement Learning (TTRL)?',\n",
    "             'Каким бразом осуществляется оценка вознаграждения в TTRL без доступа к истинным меткам?',\n",
    "             'Какую роль играет метод большинства голосов (majority voting) в архитектуре TTRL?',\n",
    "             'Какие улучшения производительности были достигнуты с помощью TTRL на бенчмарке AIME 2024?',\n",
    "             'Как TTRL сравнивается с RL на размеченных тестовых данных по эффективности?',\n",
    "             'Почему TTRL способен работать даже при неточных оценках меток?',\n",
    "             'Какие модели и бенчмарки использовались для оценки эффективности TTRL?',\n",
    "             'Какие факторы могут привести к сбою или неэффективности TTRL?',\n",
    "             'Как TTRL масштабируется при увеличении размера модели?',\n",
    "             'С какими алгоритмами обучения с подкреплением совместим TTRL и какие из них использовались в экспериментах?'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6395af4e-9e43-49f4-a7de-347b9bbf40ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = ['TTRL — это метод обучения с подкреплением без доступа к истинным меткам на тестовых данных. Он позволяет LLM адаптироваться во время инференса, используя собственные предсказания и механизм majority voting для построения псевдонаград.',\n",
    "     '''Модель многократно генерирует ответы на один и тот же запрос. Ответ, встречающийся чаще всего (majority vote), принимается за \"псевдометку\", и каждое предсказание получает награду:\n",
    "1, если совпадает с псевдометкой\n",
    "0 — если нет.''',\n",
    "     'Majority voting используется для оценки метки и вычисления награды: он определяет наиболее вероятный правильный ответ на основе собственных сэмплов модели, заменяя реальные метки.',\n",
    "     'На AIME 2024 модель Qwen2.5-Math-7B улучшилась с 16.7% до 43.3% pass@1, что составляет +159.3% прироста без использования разметки',\n",
    "     'TTRL почти достигает производительности RL с доступом к истинным меткам (RL-leakage). Это значит, что псевдонаград, полученных через majority voting, достаточно для сильной адаптации модели',\n",
    "     '''Потому что:\n",
    "RL устойчив к шуму в наградах.\n",
    "Даже при ошибочной метке часть предсказаний всё равно может получить корректный негативный сигнал, усиливая обучение.\n",
    "Reward accuracy может быть высокой даже при низкой label accuracy''',\n",
    "     '''Модели: Qwen2.5-Math-1.5B, Qwen2.5-Math-7B, LLaMA-3.1-8B-Instruct\n",
    "Бенчмарки: AIME 2024, AMC, MATH-500''',\n",
    "     '''Недостаток предварительных знаний у модели (например, у LLaMA-3.1-8B-Instruct).\n",
    "Неправильные гиперпараметры (batch size, temperature и т.д.)\n",
    "Сложные и далекие от обучающего распределения тестовые данные''',\n",
    "     '''TTRL масштабируется положительно — более крупные модели (например, Qwen2.5-Math-7B) показывают больший прирост производительности, т.к. лучше оценивают метки и генерируют более стабильные предсказания''',\n",
    "     'Совместим с PPO и GRPO. В экспериментах использовались GRPO (основной) и PPO (альтернативный) — оба показали схожую эффективность, но PPO стабильнее']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "232a1a92-5e53-467c-998d-7622ed21110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "df['Questions'] = questions\n",
    "df['gt'] = gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f7d085fd-414d-49a0-baa1-54524d4d6ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_results/article_2_questions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509c815e-ebff-44c8-a7bd-efe8f8a0449a",
   "metadata": {},
   "source": [
    "### Статья Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6cc8d467-7e00-4db4-ac59-aad55415f6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_url = \"https://arxiv.org/pdf/2005.11401\"\n",
    "arxiv_id = extract_arxiv_id(arxiv_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "85196d68-7956-430f-bf69-29caa0378055",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['Какая модель используется в качестве генератора в RAG?',\n",
    "             'Какая модель используется в качестве ретривера в RAG и как она инициализируется?',\n",
    "             'Чем отличаются архитектуры RAG-Token и RAG-Sequence?',\n",
    "             'Какой объем документов используется в векторном индексе Wikipedia?',\n",
    "             'Какие задачи были использованы для оценки RAG-моделей?',\n",
    "             'Почему авторы считают генерацию предпочтительной по сравнению с извлечением при ответе на вопросы?',\n",
    "             'Какую производительность показал RAG на задаче Jeopardy Question Generation по сравнению с BART?',\n",
    "             'Как осуществляется совместное обучение генератора и ретривера в RAG?',\n",
    "             'Какой эффект даёт \"hot-swapping\" индекса документов в RAG?',\n",
    "             'Какие аппроксимации используются при декодировании в RAG-Sequence и RAG-Token?'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b86ea5d0-d2c1-4885-8429-90a8d7d6f712",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = ['BART-large (400M параметров) используется как генератор (pθ). Это seq2seq Transformer, обученный с денойзинг-объективом',\n",
    "     'DPR (Dense Passage Retriever) — bi-encoder на базе BERT-base. Один BERT кодирует запрос (q(x)), другой — документы (d(z)). Инициализируется моделью, обученной на TriviaQA и Natural Questions',\n",
    "     '''RAG-Sequence использует один и тот же документ для генерации всей последовательности.\n",
    "RAG-Token может использовать разные документы для каждого токена — более гибкий, но вычислительно затратный вариант''',\n",
    "     '21 миллион документов, каждая статья разбита на 100-словные чанки. Используется Wikipedia dump от декабря 2018 года',\n",
    "     '''Open-domain QA: Natural Questions, TriviaQA, WebQuestions, CuratedTrec\n",
    "Abstractive QA: MS-MARCO\n",
    "Question Generation: Jeopardy QGen\n",
    "Classification: FEVER''',\n",
    "     '''Потому что:\n",
    "Можно обобщать и генерировать ответ даже при отсутствии точного совпадения в документах.\n",
    "Ответ может быть фактуальным и разнообразным, даже если он не извлекается напрямую из текста''',\n",
    "     '''RAG-Token превзошёл BART по метрике Q-BLEU-1 (22.2 против 19.7). Также в human evaluation RAG оказался более фактуальным (42.7%) и специфичным (37.4%), чем BART''',\n",
    "     'Модель обучается end-to-end, минимизируя отрицательный log-likelihood. Только query-encoder BERTq и BART обучаются, document-encoder BERTd и индекс остаются фиксированными',\n",
    "     'Можно обновлять знания модели без переобучения, просто заменив векторный индекс. Например, при смене лидеров стран между 2016 и 2018 годами модель корректно меняла ответы при подмене индекса',\n",
    "     '''RAG-Token: стандартный beam search с суммой по top-K документов на каждом шаге.\n",
    "RAG-Sequence: beam search по каждому документу отдельно, с дополнительными forward-pass для маргинализации, либо \"Fast Decoding\" — без пересчёта гипотез, которых нет в биме''']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3e72b730-7424-4f37-9114-7ddafdca9d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "df['Questions'] = questions\n",
    "df['gt'] = gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b6c0becb-cec4-4627-bfa7-4f7dbc490814",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_results/article_3_questions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30ed9de-fc3b-4f9e-aece-0ef9732074d5",
   "metadata": {},
   "source": [
    "### Статья Efficient Estimation of Word Representations in Vector Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0047d593-0a88-4e61-b555-798bff07fc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_url = \"https://arxiv.org/pdf/1301.3781\"\n",
    "arxiv_id = extract_arxiv_id(arxiv_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "322ebb98-bc35-4b94-a613-ef5ff50b7784",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['Какие две модели архитектур были предложены авторами для обучения векторных представлений слов?',\n",
    "             'В чём основное различие между архитектурами CBOW и Skip-gram?',\n",
    "             'Какие типы отношений включены в Semantic-Syntactic Word Relationship test set?',\n",
    "             'Какие значения точности показала модель Skip-gram на семантических и синтаксических подзадачах?',\n",
    "             'Какой подход используется в Skip-gram модели для выбора контекстных слов?',\n",
    "             'Какова формула вычислительной сложности модели CBOW?',\n",
    "             'Почему авторы отказались от использования скрытого слоя в новых архитектурах?',\n",
    "             'Как масштабировалась тренировка моделей в распределённой системе DistBelief?',\n",
    "             'Как были сгенерированы вопросы в тестовом наборе для оценки word vectors?',\n",
    "             'Какой метод используется для ответа на аналогии вроде “king - man + woman = ?”?'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d6f6f88d-3792-4658-ba82-1131672b5f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = ['''CBOW (Continuous Bag-of-Words)\n",
    "Skip-gram\n",
    "Обе модели являются лог-линейными и лишены скрытого слоя для повышения скорости обучения''',\n",
    "     '''CBOW предсказывает текущие слово по контексту (среднее по окрестным словам).\n",
    "Skip-gram наоборот — предсказывает окрестные слова по текущему слову''',\n",
    "     '''Семантические (5 типов): столицы, валюты, отношения человек-женщина и т.д.\n",
    "Синтаксические (9 типов): степени сравнения, времена глаголов, национальности и др''',\n",
    "     '''Для Skip-gram с размерностью 300 и обучением на 783M слов:\n",
    "Semantic: 50.0%\n",
    "Syntactic: 55.9%\n",
    "Total: 53.3%''',\n",
    "     'Слово предсказывает контекст в окне размера C. Контекст выбирается случайно в пределах окна (от 1 до C). Более дальние слова встречаются реже (subsampling)',\n",
    "     '''Q=N⋅D+D⋅log 2​(V)\n",
    "Где:\n",
    "N — количество слов в контексте\n",
    "D — размерность векторов\n",
    "V — размер словаря''',\n",
    "     'Потому что основная вычислительная нагрузка приходилась на скрытый слой. Удаление скрытого слоя позволило обучать модели на гораздо больших корпусах с миллиардами слов за разумное время',\n",
    "     '''Использовалась асинхронная mini-batch SGD + AdaGrad\n",
    "До 100 копий моделей на множестве CPU\n",
    "Skip-gram 1000D на 6B слов обучался за ~2.5 дня на 125 CPU-ядер''',\n",
    "     '''Сначала вручную созданы списки пар слов.\n",
    "Затем автоматически сформированы тысячи вопросов путём случайной комбинации двух пар из одного типа (например, города и штаты).\n",
    "Используются только однословные термины''',\n",
    "     '''Применяется векторная арифметика:\n",
    "vec(\"king\") − vec(\"man\") + vec(\"woman\") ≈ vec(\"queen\")\n",
    "Ответ — ближайшее по косинусному расстоянию слово к полученному вектору''']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "724b9422-12f7-486e-adc1-fdbba766d1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "df['Questions'] = questions\n",
    "df['gt'] = gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "bc8e0c36-1da5-4da2-9b4d-cbec89070782",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_results/article_4_questions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f6dfe3-cc40-4d6c-8061-e2965061dfb8",
   "metadata": {},
   "source": [
    "### Статья LADDER: SELF-IMPROVING LLMS THROUGH RECURSIVE PROBLEM DECOMPOSITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "616f2485-33e9-4a6b-b454-827e40d63353",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_url = \"https://arxiv.org/pdf/2503.00735\"\n",
    "arxiv_id = extract_arxiv_id(arxiv_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "9de48fbe-653d-4317-9379-11898803d1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['В чём заключается ключевая идея фреймворка LADDER?',\n",
    "             'Какой метод используется для верификации правильности решений интегралов в LADDER?',\n",
    "             'Как осуществляется генерация вариантов задач в LADDER?',\n",
    "             'Что такое TTRL и чем он отличается от LADDER?',\n",
    "             'Какие результаты достигнуты моделью Qwen2.5 7B на экзамене MIT Integration Bee после применения LADDER и TTRL?',\n",
    "             'Какая функция вознаграждения используется в GRPO в рамках обучения в LADDER?',\n",
    "             'Почему RL без использования вариантов задач показывает плохие результаты на задачах интегрирования?',\n",
    "             'Какие техники использовались для увеличения разнообразия генерируемых вариантов задач?',\n",
    "             'Как LADDER масштабирует обучение без увеличения размера модели?',\n",
    "             'Какие ограничения или сложности были замечены при генерации вариантов задач?'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8afaa694-acae-4cd9-aa92-3071d964539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = ['''Модель самостоятельно улучшает свои способности, генерируя и решая проще сформулированные варианты сложных задач. Это создаёт градиент сложности, по которому она учится решать всё более трудные задачи без внешней разметки или помощи человека''',\n",
    "     'Применяется численная верификация: сравнение ответа модели с численным значением интеграла на 5 случайных отрезках в диапазоне [-10, 10], с учётом сингулярностей и порогом точности 1e−2',\n",
    "     '''Варианты создаются по дереву:\n",
    "Применяются 3–5 заранее определённых математических трансформаций.\n",
    "Используются batch prompting, temperature cycling и персонажи (перспективы) (например, \"думай как Эйлер\").\n",
    "Генерация идёт рекурсивно, до 3-х уровней глубины''',\n",
    "     '''TTRL (Test-Time RL) — это тестовое применение RL: при инференсе модель генерирует варианты текущей задачи и обучается на них.\n",
    "Разница:\n",
    "LADDER — обучение на train-наборе заранее.\n",
    "TTRL — обучение в момент теста на текущей задаче''',\n",
    "     '''LADDER: 73% (вышел на уровень квалификации)\n",
    "LADDER + TTRL: 90%, лучший результат среди моделей, включая OpenAI o1 (80%)''',\n",
    "     '''GRPO использует два компонента:\n",
    "Accuracy reward: 1, если интеграл решён правильно (по численной верификации).\n",
    "Format reward: 1, если ответ оформлен в <ANSWER>...</ANSWER>\n",
    "Преимущества GRPO: без критика, с групповой нормализацией через advantage''',\n",
    "     'Без градиента сложности RL быстро проваливается: задачи слишком сложны, и отсутствие положительных примеров приводит к катастрофической деградации — до 0% accuracy за 30 шагов обучения',\n",
    "     '''Batch prompting (по 10 за раз)\n",
    "Temperature cycling (0.8–1.4)\n",
    "Persona prompting (разные стили мышления)\n",
    "Рекурсивная генерация до глубины 3''',\n",
    "     'Путём генерации тысяч вариантов и обучения на них. Модель (всего 7B параметров) опережает GPT-4o и другие более крупные модели, не увеличивая архитектуру, а лишь правильно направляя обучение',\n",
    "     '''Примерно 8% вариантов оказались нерешаемыми\n",
    "Некоторые “облегчённые” варианты на деле оказались сложнее, из-за случайных усложняющих трансформаций\n",
    "Верификация требовала большого числа проверок и таймаутов\n",
    "Была потребность в фильтрации “мусорных” ответов (например, символ интеграла как ответ)''']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e52ea806-72b2-4509-b59a-6d49f3f648da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "df['Questions'] = questions\n",
    "df['gt'] = gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "aea9f17b-361a-4b32-bcb4-ad2e24a2362f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_results/article_5_questions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0261df0-5c43-4b8b-b0ff-c29f15720156",
   "metadata": {},
   "source": [
    "## Генерация ответов моими LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74c5dc2e-59b9-498c-89f8-04f515d23857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_and_rerank(question, vectordb, reranker, arxiv_id, top_k=5, top_n=2):\n",
    "    \"\"\"\n",
    "    Извлекает top_k кандидатов из Chroma и реранжирует их с помощью FlagReranker.\n",
    "    Возвращает top_n наиболее релевантных фрагментов.\n",
    "    \n",
    "    :param question: Вопрос пользователя\n",
    "    :param vectordb: Объект Chroma\n",
    "    :param top_k: Сколько фрагментов извлекать из Chroma\n",
    "    :param top_n: Сколько лучших возвращать после rerank\n",
    "    :return: Список кортежей (Document, score)\n",
    "    \"\"\"\n",
    "    retriever = vectordb.as_retriever(search_kwargs={\"k\": top_k, \"filter\": {\"arxiv_id\": arxiv_id}})\n",
    "    candidates = retriever.get_relevant_documents(question)\n",
    "\n",
    "    pairs = [[question, doc.page_content] for doc in candidates]\n",
    "    scores = reranker.compute_score(pairs, normalize=True)\n",
    "\n",
    "    reranked = sorted(zip(candidates, scores), key=lambda x: -x[1])\n",
    "    \n",
    "    # print(\"🔍 Rerank результаты:\")\n",
    "    # for i, (doc, score) in enumerate(reranked):\n",
    "    #     print(f\"#Чанк{i+1} — {doc.page_content}...\")\n",
    "\n",
    "    return reranked[:top_n]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadd9f3d-4803-4ce4-98de-76e2c1ae06ad",
   "metadata": {},
   "source": [
    "### Tbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f102e470-38f5-4cb8-8e8d-ed076b6e2085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea68bc076f3d43aea69ea4c3c1d0fcdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_21172\\295889804.py:12: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceBgeEmbeddings(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_21172\\295889804.py:19: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(persist_directory=\"test_chroma_db\", embedding_function=embedding_model)\n"
     ]
    }
   ],
   "source": [
    "model_name = \"t-bank-ai/T-lite-instruct-0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "quant_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=quant_config, device_map=\"auto\")\n",
    "\n",
    "llm = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, return_full_text=False)\n",
    "terminators = list({\n",
    "        tokenizer.eos_token_id,\n",
    "        tokenizer.convert_tokens_to_ids(\"<|eot_id|>\") or tokenizer.eos_token_id,\n",
    "    })\n",
    "\n",
    "embedding_model = HuggingFaceBgeEmbeddings(\n",
    "        model_name=\"BAAI/bge-m3\",\n",
    "        model_kwargs={\"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"}\n",
    "    )\n",
    "\n",
    "reranker = FlagReranker(\"BAAI/bge-reranker-v2-m3\", use_fp16=True)\n",
    "\n",
    "vectorstore = Chroma(persist_directory=\"test_chroma_db\", embedding_function=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b002630c-ff00-4c22-bd9d-dbf92f84cece",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_MSG = (\n",
    "    \"Ты — помощник по научным статьям. \"\n",
    "    \"Твоя задача — дать короткий, точный и однозначный ответ на вопрос, \"\n",
    "    \"используя только приведённый контекст. \"\n",
    "    \"Нельзя продолжать диалог, задавать встречные вопросы или повторяться. Отвечай строго на русском языке\"\n",
    ")\n",
    "\n",
    "\n",
    "def build_messages(question: str, context: str) -> List[dict]:\n",
    "    \"\"\"Формирует сообщения в нужном для chat_template формате.\"\"\"\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_MSG},\n",
    "        {\"role\": \"user\", \"content\": f\"Вопрос:\\n{question}\"},\n",
    "        {\"role\": \"system\", \"content\": f\"Контекст:\\n{context}\"},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a35ec4-0631-48cb-b77b-bc6f3a4ac809",
   "metadata": {},
   "source": [
    "#### Attention is all you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd13284d-9f92-406c-aef1-c8b2cdda88c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['Какой оптимайзер и гиперпараметры использовались в модели?',\n",
    "            'Какие архитектурные компоненты заменяет Transformer в традиционных sequence-to-sequence моделях?',\n",
    "             'Что такое Scaled Dot-Product Attention и зачем в нем используется деление на √dk?',\n",
    "             'Как устроена структура encoder и decoder в Transformer?',\n",
    "             'Почему Multi-Head Attention улучшает производительность по сравнению с одной головой внимания?',\n",
    "             'Какие функции выполняют позиционные кодировки и почему были выбраны синусоиды?',\n",
    "             'В чем преимущества self-attention по сравнению с рекуррентными и сверточными слоями в плане вычислительной сложности и длины пути зависимостей?',\n",
    "             'Какие техники регуляризации использовались при обучении Transformer?',\n",
    "             'Какие результаты Transformer показал на задачах перевода EN→DE и EN→FR по сравнению с предыдущими SOTA?',\n",
    "             'Почему Transformer позволяет более эффективную параллелизацию при обучении?'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8e16ee4-8864-4a53-af96-521d14611239",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_url = \"https://arxiv.org/abs/1706.03762\"\n",
    "arxiv_id = extract_arxiv_id(arxiv_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f9cb30b-ec14-40c4-b1b1-f4892c5dd2cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 1/10 [00:05<00:51,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какой оптимайзер и гиперпараметры использовались в модели?\n",
      "\n",
      "Ответ на вопрос: В данном контексте использовался оптимайзер Adam с параметрами: *β* 1 = 0.9, *β* 2 = 0.98 и *ϵ* = 10^(-9). В процессе обучения применялся динамический подход к изменению скорости обучения.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 2/10 [00:11<00:44,  5.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие архитектурные компоненты заменяет Transformer в традиционных sequence-to-sequence моделях?\n",
      "\n",
      "Ответ на вопрос: В традиционных sequence-to-sequence моделях, таких как те, что используются для машинного перевода, Transformer заменяет рекуррентные слои (RNN) и слои на основе свёрточных сетей (CNN). Вместо них он применяет механизмы многоголового само-внимания (multi-headed self-attention).\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 3/10 [00:18<00:45,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Что такое Scaled Dot-Product Attention и зачем в нем используется деление на √dk?\n",
      "\n",
      "Ответ на вопрос: Деление на √dk в Scaled Dot-Product Attention используется для нормализации результатов скалярного произведения между запросами и ключами. Это помогает стабилизировать значения весов, полученных из softmax, и предотвращает доминирование одного ключа при больших размерностях векторов. Таким образом, нормализация обеспечивает более равномерное распределение внимания между всеми ключами, что важно для точности и устойчивости модели.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:28<00:46,  7.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Как устроена структура encoder и decoder в Transformer?\n",
      "\n",
      "Ответ на вопрос: Структура Transformer состоит из двух основных частей: encoder и decoder. Encoder принимает входную последовательность символов и преобразует её в последовательность непрерывных представлений. Затем decoder, используя эти представления и предыдущие сгенерированные символы, создает выходную последовательность. Обе части включают в себя слои самоприсутствия (self-attention) и линейные соединения (point-wise fully connected layers). Визуально это представлено двумя блоками в архитектуре, изображенной на рисунке 1.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [00:37<00:40,  8.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Почему Multi-Head Attention улучшает производительность по сравнению с одной головой внимания?\n",
      "\n",
      "Ответ на вопрос: Multi-Head Attention улучшает производительность, предоставляя модели возможность одновременно обращаться к информации из различных подпространств признаков. Это достигается за счёт разделения входных данных на несколько подзадач (голов), каждая из которых работает независимо. В отличие от одного внимательного блока, который вынужден усреднять информацию, многоголовое внимание позволяет более гибко и специализированно использовать разные аспекты данных, что повышает эффективность модели.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [00:56<00:47, 11.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие функции выполняют позиционные кодировки и почему были выбраны синусоиды?\n",
      "\n",
      "Ответ на вопрос: Позиционные кодировки (PE) в нейронных сетях, таких как трансформеры, используются для внедрения информации о позициях в тексте. Синусоидальные функции применяются для этого по нескольким причинам:\n",
      "\n",
      "1. **Линейная зависимость от позиции**: Синусоиды позволяют легко выразить смещение позиций, так как *PE* *pos* + *k* можно представить как линейную комбинацию *PE* *pos*.\n",
      "2. **Геометрическая прогрессия частот**: Это помогает модели эффективно различать позиции, поскольку разные частоты (волновые числа) соответствуют разным позициям, что способствует лучшему распознаванию и обработке последовательностей.\n",
      "3. **Обработка относительных позиций**: Такая структура помогает модели понимать относительное расположение слов, что критично для задач, где важно учитывать контекст.\n",
      "\n",
      "Таким образом, выбор синусоидальных функций обусловлен их способностью обеспечивать гибкость и эффективность в работе с позиционной информацией.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [01:13<00:40, 13.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: В чем преимущества self-attention по сравнению с рекуррентными и сверточными слоями в плане вычислительной сложности и длины пути зависимостей?\n",
      "\n",
      "Ответ на вопрос: Преимущества self-attention перед рекуррентными и сверточными слоями заключаются в следующем:\n",
      "1. **Вычислительная эффективность**: В отличие от рекуррентных слоев, которые требуют *O(n)* операций для обработки последовательности длиной *n*, self-attention использует *O(d)* операций, где *d* — размерность представления. Это особенно выгодно для длинных последовательностей.\n",
      "2. **Параллельная обработка**: Self-attention позволяет обрабатывать все элементы одновременно, что ускоряет обучение и предсказание, особенно на больших данных.\n",
      "3. **Глобальные связи**: Возможность взаимодействия между всеми элементами в одном слое, что обеспечивает более широкий контекст и улучшает моделирование зависимостей.\n",
      "\n",
      "Таким образом, self-attention обеспечивает более быстрое и масштабируемое решение для задач, где важны обширные взаимодействия и эффективность.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [01:24<00:25, 12.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие техники регуляризации использовались при обучении Transformer?\n",
      "\n",
      "Ответ на вопрос: Для обучения Transformer использовались следующие техники регуляризации:\n",
      "\n",
      "1. **Dropout**: Применяется на всех слоях, кроме последнего, с вероятностью 0.1.\n",
      "2. **Weight Decay**: Регуляризация L2, которая применяется к весам модели, чтобы предотвратить переобучение.\n",
      "3. **Label Smoothing**: Введение небольшой ошибки в метки целевых данных, что помогает модели лучше обобщать и уменьшает её уверенность в неправильных ответах.\n",
      "\n",
      "Эти методы помогают улучшить устойчивость и обобщающую способность модели, что особенно важно для больших моделей, таких как Transformer.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [01:33<00:11, 11.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие результаты Transformer показал на задачах перевода EN→DE и EN→FR по сравнению с предыдущими SOTA?\n",
      "\n",
      "Ответ на вопрос: На задачах перевода с английского на французский и немецкий языки, модель Transformer показала значительное улучшение по сравнению с предыдущими лидерами. Она достигла высокого BLEU-оценки (41.0) и при этом потребовала меньших ресурсов для обучения, чем предыдущие лучшие модели. Важным фактором стало использование более высокой вероятности dropout (0.1 вместо 0.3), что способствовало лучшей производительности.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:42<00:00, 10.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Почему Transformer позволяет более эффективную параллелизацию при обучении?\n",
      "\n",
      "Ответ на вопрос: Параллелизация в Transformer возможна из-за отсутствия рекуррентных слоев, которые требуют последовательного выполнения и ограничивают возможности распараллеливания. Вместо этого Transformer использует механизм внимания, который может обрабатывать данные параллельно, так как он не требует последовательного обхода входных данных. Это позволяет эффективнее использовать многоядерные и многопроцессорные системы, что ускоряет процесс обучения и улучшает производительность модели.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "times = []\n",
    "\n",
    "for question in tqdm(questions):\n",
    "    reranked = retrieve_and_rerank(question, vectorstore, reranker, arxiv_id, top_k=10, top_n=2)\n",
    "    top_chunks = [doc.page_content for doc, score in reranked]\n",
    "    context = \"\\n\\n\".join(top_chunks)\n",
    "\n",
    "    messages = build_messages(question, context)\n",
    "    start = time.time()\n",
    "\n",
    "    answer = llm(messages, max_new_tokens=256, do_sample=False, eos_token_id=terminators)[0]['generated_text']\n",
    "\n",
    "    end = time.time()\n",
    "    inf_time = end - start\n",
    "    \n",
    "    times.append(inf_time)\n",
    "    print(f'Вопрос: {question}\\n')\n",
    "    print(f'Ответ на вопрос: {answer}\\n\\n')\n",
    "    outputs.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62123aaf-13b2-4e42-87cb-f6d9fb518e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_1 = times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2cfeb3b-abe3-4db8-a9a5-ebe2f2e2591c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(10.112690758705138)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(times_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1df412a0-51f1-449c-8070-2f1eba85632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test_results/article_1_questions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74a42f5c-3275-4cc6-9703-0008b0af26ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tbank'] = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed39fd3b-cbdf-4b7f-8423-3ac3e7807acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_results/article_1_questions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f39f9e-b0a3-4400-9525-eb8e4488d7b7",
   "metadata": {},
   "source": [
    "#### Статья TTRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a135b99c-f2a9-475c-96e7-4a830fbd7c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['В чем заключается основная идея метода Test-Time Reinforcement Learning (TTRL)?',\n",
    "             'Каким бразом осуществляется оценка вознаграждения в TTRL без доступа к истинным меткам?',\n",
    "             'Какую роль играет метод большинства голосов (majority voting) в архитектуре TTRL?',\n",
    "             'Какие улучшения производительности были достигнуты с помощью TTRL на бенчмарке AIME 2024?',\n",
    "             'Как TTRL сравнивается с RL на размеченных тестовых данных по эффективности?',\n",
    "             'Почему TTRL способен работать даже при неточных оценках меток?',\n",
    "             'Какие модели и бенчмарки использовались для оценки эффективности TTRL?',\n",
    "             'Какие факторы могут привести к сбою или неэффективности TTRL?',\n",
    "             'Как TTRL масштабируется при увеличении размера модели?',\n",
    "             'С какими алгоритмами обучения с подкреплением совместим TTRL и какие из них использовались в экспериментах?'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eb2ca42e-8b64-4613-8bf6-2d3fe1564f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_url = \"https://arxiv.org/pdf/2504.16084\"\n",
    "arxiv_id = extract_arxiv_id(arxiv_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b2c4c07-b3be-423a-871a-17ac6cc8e87c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 1/10 [00:09<01:29,  9.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: В чем заключается основная идея метода Test-Time Reinforcement Learning (TTRL)?\n",
      "\n",
      "Ответ на вопрос: Основная идея метода Test-Time Reinforcement Learning (TTRL) заключается в применении обучения с подкреплением (RL) для улучшения больших языковых моделей (LLMs) на основе неотмеченных данных. В отличие от традиционных подходов, TTRL использует информацию из самого процесса инференса и предобученных моделей для оценки и оптимизации производительности модели в режиме реального времени, что позволяет модели самостоятельно адаптироваться и улучшаться без необходимости вручную заданных меток.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 2/10 [00:17<01:08,  8.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Каким бразом осуществляется оценка вознаграждения в TTRL без доступа к истинным меткам?\n",
      "\n",
      "Ответ на вопрос: Оценка вознаграждения в TTRL (Test-Time Reinforcement Learning) происходит через использование методов, которые не требуют точных меток. В частности, применяется Test-Time Scaling (TTS), где для получения полезных оценок применяется, например, метод большинства голосов. Это позволяет создать функцию вознаграждения, которая помогает обучению модели на основе обратной связи, полученной из неотмеченных данных.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 3/10 [00:23<00:51,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какую роль играет метод большинства голосов (majority voting) в архитектуре TTRL?\n",
      "\n",
      "Ответ на вопрос: Метод большинства голосов в архитектуре TTRL используется для создания наградной функции, которая основывается на согласованности предсказаний модели. Это позволяет обучать модели на тестовых данных без меток, что является важным шагом в развитии самообучающихся систем и RL с самоподтвержденными наградами.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:33<00:49,  8.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие улучшения производительности были достигнуты с помощью TTRL на бенчмарке AIME 2024?\n",
      "\n",
      "Ответ на вопрос: На бенчмарке AIME 2024 применение TTRL (техники обучения без учителя) к модели Qwen2.5-Math-7B привело к улучшению производительности на 159% (с 13.3 до 43.3). Это достигается за счёт самообучения и не требует меток для тренировки, что обеспечивает обобщение на другие задачи. Техника также положительно влияет на другие метрики и может быть интегрирована с разными алгоритмами, демонстрируя высокий потолок производительности.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [00:39<00:38,  7.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Как TTRL сравнивается с RL на размеченных тестовых данных по эффективности?\n",
      "\n",
      "Ответ на вопрос: На размеченных тестовых данных, **TTRL** (Transferable Reinforcement Learning) демонстрирует эффективность, сравнимую с **RL** (Reinforcement Learning), что подтверждается близостью их кривых производительности (см. Рис. 7). Это указывает на высокую эффективность **TTRL** в улучшении результатов, превосходящую традиционные методы обучения и оценки.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [00:47<00:31,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Почему TTRL способен работать даже при неточных оценках меток?\n",
      "\n",
      "Ответ на вопрос: TTRL (Temporal Reward-Driven Learning) остаётся эффективным, несмотря на неточные оценки меток, потому что система использует правило, согласно которому награды вычисляются на основе соответствия предсказанного ответа и \"метки\". Даже если оценка метки не точна, но отличается от неверного предсказания, она всё равно помогает корректировать поведение модели, обеспечивая отрицательную награду за ошибки.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [00:55<00:23,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие модели и бенчмарки использовались для оценки эффективности TTRL?\n",
      "\n",
      "Ответ на вопрос: Для оценки эффективности TTRL (Test-Time Reinforcement Learning) использовались различные модели и бенчмарки. В частности, применялись базовые модели Qwen2.5-Math-1.5B и Qwen2.5-Math-7B, а также инструкционная модель LLaMA-3.1-8B-Instruct. Эти модели проверялись на различных задачах, чтобы показать универсальность подхода и его масштабируемость.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [01:05<00:17,  8.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие факторы могут привести к сбою или неэффективности TTRL?\n",
      "\n",
      "Ответ на вопрос: Основные причины неэффективности или сбоя в TTRL (Transfer and Training with Reinforcement Learning) связаны с недостатком предварительных знаний о целевой задаче. Это особенно критично, когда тестовые данные сложнее и включают новые элементы, а модель не имеет подходящих механизмов для адаптации и обучения на основе сложного материала. В случае с Qwen2.5-Math-1.5B и LLaMA-3.1-8B-Instruct, отсутствие значительного улучшения может быть следствием недостаточной подготовленности моделей к таким сложным задачам.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [01:15<00:08,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Как TTRL масштабируется при увеличении размера модели?\n",
      "\n",
      "Ответ на вопрос: TTRL (Test-Time Reinforcement Learning) демонстрирует улучшение производительности при увеличении размера модели. В данном контексте, большие модели (например, 7B параметров) показывают значительные улучшения в задачах, таких как AIME 2024 и AMC, за счет более точного прогнозирования и лучшего обучения на новых данных. Модели меньшего размера (1.5B) не дают столь заметных результатов, что связано с их ограниченными возможностями.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:21<00:00,  8.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: С какими алгоритмами обучения с подкреплением совместим TTRL и какие из них использовались в экспериментах?\n",
      "\n",
      "Ответ на вопрос: Техника TTRL (Temporal Training with Reinforcement Learning) совместима с алгоритмами, такими как PPO (Proximal Policy Optimization) и GRPO (Generalized Reinforcement Policy Optimization). В экспериментах, представленных в контексте, использовался PPO, который показал стабильные результаты и сопоставимую эффективность с GRPO.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "times = []\n",
    "\n",
    "for question in tqdm(questions):\n",
    "    reranked = retrieve_and_rerank(question, vectorstore, reranker, arxiv_id, top_k=10, top_n=2)\n",
    "    top_chunks = [doc.page_content for doc, score in reranked]\n",
    "    context = \"\\n\\n\".join(top_chunks)\n",
    "\n",
    "    messages = build_messages(question, context)\n",
    "    start = time.time()\n",
    "\n",
    "    answer = llm(messages, max_new_tokens=256, do_sample=False, eos_token_id=terminators)[0]['generated_text']\n",
    "\n",
    "    end = time.time()\n",
    "    inf_time = end - start\n",
    "    \n",
    "    times.append(inf_time)\n",
    "    print(f'Вопрос: {question}\\n')\n",
    "    print(f'Ответ на вопрос: {answer}\\n\\n')\n",
    "    outputs.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a728498-afc5-4432-9e9b-a795206b78df",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_2 = times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f8630d3-740e-4884-bb5c-01ac47aad4ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(7.986197686195373)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(times_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5831273f-b6b4-41b5-b540-5596b9dd6d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test_results/article_2_questions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "367bf663-a51e-47b1-9129-ef8b911d0598",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tbank'] = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2e5e8b5d-ae53-4a74-b7e4-f8e8e74a1c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_results/article_2_questions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56678d2-63fc-4988-b23d-bde731d1b3d3",
   "metadata": {},
   "source": [
    "#### Статья Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "26176f4e-dc8d-4733-88b4-e1545e787af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['Какая модель используется в качестве генератора в RAG?',\n",
    "             'Какая модель используется в качестве ретривера в RAG и как она инициализируется?',\n",
    "             'Чем отличаются архитектуры RAG-Token и RAG-Sequence?',\n",
    "             'Какой объем документов используется в векторном индексе Wikipedia?',\n",
    "             'Какие задачи были использованы для оценки RAG-моделей?',\n",
    "             'Почему авторы считают генерацию предпочтительной по сравнению с извлечением при ответе на вопросы?',\n",
    "             'Какую производительность показал RAG на задаче Jeopardy Question Generation по сравнению с BART?',\n",
    "             'Как осуществляется совместное обучение генератора и ретривера в RAG?',\n",
    "             'Какой эффект даёт \"hot-swapping\" индекса документов в RAG?',\n",
    "             'Какие аппроксимации используются при декодировании в RAG-Sequence и RAG-Token?'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9e8a5468-36b6-4c76-857b-12d31d9e9b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_url = \"https://arxiv.org/pdf/2005.11401\"\n",
    "arxiv_id = extract_arxiv_id(arxiv_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8a8072ed-97a1-480d-bf47-f9f179d56ac7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 1/10 [00:09<01:28,  9.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какая модель используется в качестве генератора в RAG?\n",
      "\n",
      "Ответ на вопрос: В RAG (Retrieval-Augmented Generation) используется модель, состоящая из двух компонентов: (i) \"retriever\" (получатель), который на основе входного запроса *x* выбирает и возвращает наиболее релевантные текстовые фрагменты *z*; и (ii) \"generator\" (генератор), который, используя эти фрагменты и исходный запрос, генерирует целевой текст *y*. Важно отметить, что оба компонента имеют свои параметры и функции вероятности, которые определяют их работу.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 2/10 [00:15<00:59,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какая модель используется в качестве ретривера в RAG и как она инициализируется?\n",
      "\n",
      "Ответ на вопрос: В качестве ретривера в RAG используется модель, инициализированная на основе DPR (Dense Passage Retrieval). Для этого применяется обучение на основе Natural Questions и TriviaQA, что позволяет эффективно извлекать и ранжировать релевантные документы.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 3/10 [00:25<01:00,  8.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Чем отличаются архитектуры RAG-Token и RAG-Sequence?\n",
      "\n",
      "Ответ на вопрос: **RAG-Token** использует автокодирование, где вероятность перехода *p* ( *y|x* ) определяется через вероятность *z* ( *·|x* ) и вероятность *y* ( *|x, z* ). Это позволяет применять стандартные методы декодирования, такие как beam search. В отличие от этого, **RAG-Sequence** требует иного подхода, так как его архитектура не является автокодировочной и требует специфических методов для оценки вероятностей и последующего декодирования.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:27<00:36,  6.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какой объем документов используется в векторном индексе Wikipedia?\n",
      "\n",
      "Ответ на вопрос: В векторном индексе Wikipedia используется 21 миллион документов, каждый из которых состоит из 100 слов.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [00:36<00:34,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие задачи были использованы для оценки RAG-моделей?\n",
      "\n",
      "Ответ на вопрос: Для оценки RAG-моделей использовались задачи, требующие глубокого понимания и использования знаний из различных источников, такие как открытые вопросы и ответы (open domain QA), а также другие задачи, связанные с обработкой естественного языка, где важны контекст и доступ к большим объемам информации. В частности, модели показали высокие результаты на таких тестах, как SQuAD, Natural Questions и TriviaQA.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [00:42<00:27,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Почему авторы считают генерацию предпочтительной по сравнению с извлечением при ответе на вопросы?\n",
      "\n",
      "Ответ на вопрос: Авторы считают генерацию предпочтительной, потому что она позволяет создавать ответы на основе информации, которая не представлена в исходном тексте напрямую, но может быть выведена из контекста. Это особенно полезно для задач, где ответы не всегда явно сформулированы в документах, что невозможно для методов извлечения.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [00:49<00:20,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какую производительность показал RAG на задаче Jeopardy Question Generation по сравнению с BART?\n",
      "\n",
      "Ответ на вопрос: RAG (Reinforced Attention Generative Adversarial Networks) показывает лучшие результаты на задаче генерации вопросов для игры Jeopardy по сравнению с BART (Bidirectional and AutoRegressive Transformers). В частности, RAG выигрывает по метрике Q-BLEU-1 и получает более высокие оценки за фактологическую точность и специфичность в человеческой оценке.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [00:58<00:14,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Как осуществляется совместное обучение генератора и ретривера в RAG?\n",
      "\n",
      "Ответ на вопрос: В RAG (Retrieval-Augmented Generation) обучение генератора и ретривера происходит совместно. Генератор (например, модель на основе T5 или BART) и система поиска (ретривер) работают вместе, чтобы улучшить качество генерации текста. Оба компонента проходят обучение на одном и том же наборе данных, что позволяет им адаптироваться и взаимодействовать для создания более точных и релевантных ответов.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [01:04<00:06,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какой эффект даёт \"hot-swapping\" индекса документов в RAG?\n",
      "\n",
      "Ответ на вопрос: \"Hot-swapping\" индекса в RAG (Retrieval-Augmented Generation) позволяет обновлять и заменять базу данных для поиска без необходимости повторного обучения всей модели. Это обеспечивает гибкость и возможность быстрого обновления информации, что важно для поддержания актуальности и точности ответов на запросы.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:14<00:00,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие аппроксимации используются при декодировании в RAG-Sequence и RAG-Token?\n",
      "\n",
      "Ответ на вопрос: Для декодирования в RAG-Sequence и RAG-Token используются различные методы аппроксимации. В RAG-Token применяется стандартный автокодировочный подход, где вероятность перехода *p* ( *y|x* ) аппроксимируется через выборку из верхних *k* вероятностей *p* ( *·|x* ) и последующее использование этих значений в рамках стандартного бим декодера. В RAG-Sequence, вероятно, применяется другой метод, но конкретные детали не указаны в данном контексте.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "times = []\n",
    "\n",
    "for question in tqdm(questions):\n",
    "    reranked = retrieve_and_rerank(question, vectorstore, reranker, arxiv_id, top_k=10, top_n=2)\n",
    "    top_chunks = [doc.page_content for doc, score in reranked]\n",
    "    context = \"\\n\\n\".join(top_chunks)\n",
    "\n",
    "    messages = build_messages(question, context)\n",
    "    start = time.time()\n",
    "\n",
    "    answer = llm(messages, max_new_tokens=256, do_sample=False, eos_token_id=terminators)[0]['generated_text']\n",
    "\n",
    "    end = time.time()\n",
    "    inf_time = end - start\n",
    "    \n",
    "    times.append(inf_time)\n",
    "    print(f'Вопрос: {question}\\n')\n",
    "    print(f'Ответ на вопрос: {answer}\\n\\n')\n",
    "    outputs.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "302347e5-1728-4577-b1e8-fbe4650da74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_3 = times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cc2b5210-7c27-4643-8b65-e2bda5258d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(7.293178129196167)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(times_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ee029518-949b-4c53-b21d-d3e97f8218b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test_results/article_3_questions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "789197db-7f4c-4552-931b-e300545cb0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tbank'] = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d81fad22-7e68-4c14-8e0f-82858f2e2078",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_results/article_3_questions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc5aeb4-30d7-4913-9160-a79a6c2b2c8c",
   "metadata": {},
   "source": [
    "#### Статья Efficient Estimation of Word Representations in Vector Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f01db91f-c8e1-4dc5-93a1-482ecb4edc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['Какие две модели архитектур были предложены авторами для обучения векторных представлений слов?',\n",
    "             'В чём основное различие между архитектурами CBOW и Skip-gram?',\n",
    "             'Какие типы отношений включены в Semantic-Syntactic Word Relationship test set?',\n",
    "             'Какие значения точности показала модель Skip-gram на семантических и синтаксических подзадачах?',\n",
    "             'Какой подход используется в Skip-gram модели для выбора контекстных слов?',\n",
    "             'Какова формула вычислительной сложности модели CBOW?',\n",
    "             'Почему авторы отказались от использования скрытого слоя в новых архитектурах?',\n",
    "             'Как масштабировалась тренировка моделей в распределённой системе DistBelief?',\n",
    "             'Как были сгенерированы вопросы в тестовом наборе для оценки word vectors?',\n",
    "             'Какой метод используется для ответа на аналогии вроде “king - man + woman = ?”?'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "311a5124-23b0-41c2-a14f-6289563a2bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_url = \"https://arxiv.org/pdf/1301.3781\"\n",
    "arxiv_id = extract_arxiv_id(arxiv_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "14d85b75-a944-4bbb-b0af-281c07b75834",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 1/10 [00:10<01:34, 10.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие две модели архитектур были предложены авторами для обучения векторных представлений слов?\n",
      "\n",
      "Ответ на вопрос: Авторы предложили две модели для обучения векторных представлений слов: \n",
      "1. **Модель на основе нейронной сети с линейным слоем и нелинейным скрытым слоем** (feedforward neural network with a linear projection layer and a non-linear hidden layer). \n",
      "2. **Модель, использующая архитектуру нейронной сети для языковых моделей (NNLM)**, которая также применялась в предыдущих исследованиях, но была усовершенствована и адаптирована для более эффективного обучения векторных представлений.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 2/10 [00:24<01:38, 12.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: В чём основное различие между архитектурами CBOW и Skip-gram?\n",
      "\n",
      "Ответ на вопрос: Основное различие между архитектурами CBOW (Continuous Bag of Words) и Skip-gram заключается в их подходе к обучению. CBOW предсказывает текущее слово, используя контекст (окружение) из нескольких слов, тогда как Skip-gram делает обратное: предсказывает ближайшие слова вокруг заданного слова. Это приводит к разным результатам на задачах, требующих анализа семантики и синтаксиса текста. Skip-gram лучше справляется с выявлением семантических связей, а CBOW сильнее в синтаксических задачах.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 3/10 [00:33<01:17, 11.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие типы отношений включены в Semantic-Syntactic Word Relationship test set?\n",
      "\n",
      "Ответ на вопрос: В Semantic-Syntactic Word Relationship test set включены пять типов семантических вопросов и девять типов синтаксических вопросов. Семантические вопросы касаются, например, связей между словами, как \"страна-город\" (например, Франция и Париж), а синтаксические вопросы могут проверять грамматические связи и отношения, такие как \"кто\" и \"что\" в предложении. Вопросы создаются на основе пар слов, которые выбираются из различных категорий, таких как города и их штаты, и затем соединяются для формирования вопросов.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:36<00:47,  7.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие значения точности показала модель Skip-gram на семантических и синтаксических подзадачах?\n",
      "\n",
      "Ответ на вопрос: Модель Skip-gram показала точность 24% на семантических задачах и 30.1% на синтаксических задачах в приведённом контексте.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [00:46<00:42,  8.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какой подход используется в Skip-gram модели для выбора контекстных слов?\n",
      "\n",
      "Ответ на вопрос: В модели Skip-gram для выбора контекстных слов используется метод, называемый \"skip-gram\", который предполагает, что каждое слово в предложении рассматривается как контекст для всех остальных слов. В процессе обучения модель учится предсказывать ближайшие слова вокруг текущего слова, что помогает создать векторные представления слов, отражающие их семантическую близость. Важно, что при этом учитываются как слова, непосредственно окружающие текущее слово, так и слова на более удалённых позициях, но с уменьшением веса для более отдалённых.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [00:56<00:35,  8.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какова формула вычислительной сложности модели CBOW?\n",
      "\n",
      "Ответ на вопрос: Формула вычислительной сложности для модели CBOW (Continuous Bag of Words) выглядит следующим образом:\n",
      "\n",
      "*Q* = *C ×* ( *D* + *D × log* 2 ( *V* )) (5)\n",
      "\n",
      "Здесь:\n",
      "- *C* — максимальное расстояние между словами (context window size).\n",
      "- *D* — размерность векторов слов.\n",
      "- *V* — размер словаря.\n",
      "\n",
      "Эта формула описывает количество операций, необходимых для обучения модели, и учитывает как размерность векторов, так и количество слов в словаре.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [01:04<00:26,  8.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Почему авторы отказались от использования скрытого слоя в новых архитектурах?\n",
      "\n",
      "Ответ на вопрос: Авторы отказались от использования скрытого слоя в новых архитектурах, чтобы уменьшить вычислительную сложность моделей. Это позволило им исследовать более простые модели, которые могут быть обучены на больших объемах данных, что потенциально улучшает эффективность обучения и обработки информации. Вместо этого они применяют методы, такие как \"bag-of-words\" и использование нескольких слов из истории и будущего для классификации текущего слова, что также снижает требования к ресурсам.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [01:14<00:18,  9.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Как масштабировалась тренировка моделей в распределённой системе DistBelief?\n",
      "\n",
      "Ответ на вопрос: Масштабирование тренировки моделей в системе DistBelief происходило за счет распределения вычислительных задач между множеством реплик (копий) модели. В частности, использовалась асинхронная градиентная схема с мини-пакетами и адаптивным методом обучения Adagrad. Каждая реплика работала на множестве CPU-ядер, что позволяло эффективно использовать ресурсы кластера. В среднем, применялось от 50 до 100 реплик, что обеспечивало параллельное обучение на больших объемах данных.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [01:24<00:09,  9.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Как были сгенерированы вопросы в тестовом наборе для оценки word vectors?\n",
      "\n",
      "Ответ на вопрос: Вопросы для тестирования word vectors были сгенерированы в два этапа. Сначала вручную составлялись списки похожих пар слов. Затем, на основе этих списков, создавались вопросы, соединяя случайные пары слов. Например, для создания вопросов о городах и штатах США, использовались списки городов и их соответствующих штатов. В итоге, тестовый набор включает вопросы, которые проверяют как семантические, так и синтаксические связи слов, и охватывает только однословные термины.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:34<00:00,  9.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какой метод используется для ответа на аналогии вроде “king - man + woman = ?”?\n",
      "\n",
      "Ответ на вопрос: Для решения аналогий, таких как \"king - man + woman =?\", используется метод, основанный на векторных представлениях слов. В этом методе из векторного представления слова \"King\" вычитается вектор слова \"Man\", а затем прибавляется вектор слова \"Woman\". Полученный вектор сравнивается с векторами других слов, и ближайший по смыслу считается ответом. В данном случае, это может быть слово \"Queen\". \n",
      "\n",
      "Таким образом, алгебраические операции над векторами слов позволяют выявить семантическую связь и найти наиболее подходящее слово для завершения аналогии.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "times = []\n",
    "\n",
    "for question in tqdm(questions):\n",
    "    reranked = retrieve_and_rerank(question, vectorstore, reranker, arxiv_id, top_k=10, top_n=2)\n",
    "    top_chunks = [doc.page_content for doc, score in reranked]\n",
    "    context = \"\\n\\n\".join(top_chunks)\n",
    "\n",
    "    messages = build_messages(question, context)\n",
    "    start = time.time()\n",
    "\n",
    "    answer = llm(messages, max_new_tokens=256, do_sample=False, eos_token_id=terminators)[0]['generated_text']\n",
    "\n",
    "    end = time.time()\n",
    "    inf_time = end - start\n",
    "    \n",
    "    times.append(inf_time)\n",
    "    print(f'Вопрос: {question}\\n')\n",
    "    print(f'Ответ на вопрос: {answer}\\n\\n')\n",
    "    outputs.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f23ecb3a-893e-4b3e-a9db-b40f6b19c67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_4 = times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2ab52e5c-a563-48a5-bedc-1771b5302908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(9.327714204788208)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(times_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ff61c8d9-e7b7-45b4-a1a5-ab9e8d6ca569",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test_results/article_4_questions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cc459199-cc5c-46b3-b271-4d036ebebc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tbank'] = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5a62ca25-138b-4cbe-a92d-1bf00c2e6a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_results/article_4_questions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb7853e-3e08-4ff6-b798-abc2b596ccfa",
   "metadata": {},
   "source": [
    "#### Статья LADDER: SELF-IMPROVING LLMS THROUGH RECURSIVE PROBLEM DECOMPOSITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "42509498-78f7-4860-b04a-8122bf188a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['В чём заключается ключевая идея фреймворка LADDER?',\n",
    "             'Какой метод используется для верификации правильности решений интегралов в LADDER?',\n",
    "             'Как осуществляется генерация вариантов задач в LADDER?',\n",
    "             'Что такое TTRL и чем он отличается от LADDER?',\n",
    "             'Какие результаты достигнуты моделью Qwen2.5 7B на экзамене MIT Integration Bee после применения LADDER и TTRL?',\n",
    "             'Какая функция вознаграждения используется в GRPO в рамках обучения в LADDER?',\n",
    "             'Почему RL без использования вариантов задач показывает плохие результаты на задачах интегрирования?',\n",
    "             'Какие техники использовались для увеличения разнообразия генерируемых вариантов задач?',\n",
    "             'Как LADDER масштабирует обучение без увеличения размера модели?',\n",
    "             'Какие ограничения или сложности были замечены при генерации вариантов задач?'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d85f9565-b63d-4dfa-949f-a2fe1b0c845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_url = \"https://arxiv.org/pdf/2503.00735\"\n",
    "arxiv_id = extract_arxiv_id(arxiv_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ae72d3a4-27f5-4a45-8585-32a6d3a5d0cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 1/10 [00:07<01:05,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: В чём заключается ключевая идея фреймворка LADDER?\n",
      "\n",
      "Ответ на вопрос: Ключевая идея фреймворка LADDER заключается в использовании рекурсивного подхода к обучению, где модель сама генерирует и решает упрощенные версии сложных задач. Это позволяет создать постепенный градиент сложности, что способствует более эффективному и самостоятельному процессу обучения, не требующему значительных вычислительных ресурсов или внешнего контроля.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 2/10 [00:11<00:46,  5.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какой метод используется для верификации правильности решений интегралов в LADDER?\n",
      "\n",
      "Ответ на вопрос: Для верификации решений интегралов в LADDER используется численный метод проверки, который сочетает точность с эффективностью вычислений. Этот процесс обеспечивает надежную проверку на различных типах интегралов, учитывая особенности и возможные численные проблемы.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 3/10 [00:21<00:51,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Как осуществляется генерация вариантов задач в LADDER?\n",
      "\n",
      "Ответ на вопрос: В LADDER генерация вариантов задач происходит в два этапа. На первом этапе для каждого интеграла из обучающей выборки создаётся дерево вариантов (см. раздел 3.1.2). На втором этапе применяется протокол обучения с подкреплением (см. раздел 3.1.4), где используется сгенерированный набор вариантов как обучающий материал. Это позволяет улучшить и обобщить способности модели к интеграции. В итоге, модель может решать новые задачи.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:30<00:49,  8.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Что такое TTRL и чем он отличается от LADDER?\n",
      "\n",
      "Ответ на вопрос: TTRL (Test-Time Recursive Learning) — это метод, который улучшает производительность модели на тестовых данных, применяя рекурсивное разложение задач. В отличие от LADDER, который использует структурированный подход для генерации и решения задач, TTRL непосредственно применяет этот метод к самим тестовым вопросам, что позволяет модели лучше справляться с трудными случаями. В результате, TTRL помогает модели, обученной в рамках LADDER, показывать лучшие результаты, чем более крупные модели, такие как o1 от OpenAI, на сложных задачах.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [00:35<00:34,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие результаты достигнуты моделью Qwen2.5 7B на экзамене MIT Integration Bee после применения LADDER и TTRL?\n",
      "\n",
      "Ответ на вопрос: На экзамене MIT Integration Bee модель Qwen2.5 7B, после применения LADDER и TTRL, достигла 90% точности, что значительно превысило стандартный порог в 73% и установило новый рекорд для моделей такого размера.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [00:41<00:26,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какая функция вознаграждения используется в GRPO в рамках обучения в LADDER?\n",
      "\n",
      "Ответ на вопрос: В рамках LADDER используется функция вознаграждения, которая основана на сравнении текущих и предыдущих результатов модели. В частности, в GRPO применяется оценка, зависящая от разницы между новыми и старыми ответами группы, что позволяет модели оценивать свою эффективность и корректировать себя на основе этой обратной связи.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [00:49<00:21,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Почему RL без использования вариантов задач показывает плохие результаты на задачах интегрирования?\n",
      "\n",
      "Ответ на вопрос: Использование RL без специальных методов и подходов к задачам интегрирования, таким как LADDER, приводит к низким результатам из-за сложности и специфичности этих задач. Важно, что успех достигается именно благодаря тщательно разработанной структуре задач, а не только алгоритму RL. Это указывает на перспективы применения подобных методов в других сложных задачах, где прямое обучение оказывается неэффективным.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [01:04<00:19,  9.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие техники использовались для увеличения разнообразия генерируемых вариантов задач?\n",
      "\n",
      "Ответ на вопрос: Для увеличения разнообразия генерируемых задач использовались две ключевые техники:\n",
      "\n",
      "1. **Температурное изменение (Temperature Cycling):** В процессе генерации вариантов применялся динамический диапазон температур от 0.8 до 1.4. Это позволило управлять балансом между новизной и математической корректностью.\n",
      "\n",
      "2. **Персонифицированные запросы (Persona-based Prompting):** Модель получала инструкции, которые требовали от неё рассматривать задачи с разных точек зрения, например, \"подходи как Эйлер\" или \"анализируй как Гаусс\". Это способствовало более широкому спектру решений и подходов.\n",
      "\n",
      "Таким образом, комбинация этих методов и гибкость в управлении количеством генерируемых вариантов (N) обеспечили эффективное разнообразие и качество задач.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [01:12<00:09,  9.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Как LADDER масштабирует обучение без увеличения размера модели?\n",
      "\n",
      "Ответ на вопрос: LADDER масштабирует обучение, используя методы рекурсивного разложения задач и обучения на основе подкрепления. Модель разбивает сложные проблемы на более простые части, что позволяет ей адаптироваться и совершенствоваться в процессе выполнения задач, не требуя увеличения размера самой модели или дополнительных данных. Это способствует динамическому развитию навыков и повышению эффективности без необходимости в значительном росте ресурсов.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:20<00:00,  8.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие ограничения или сложности были замечены при генерации вариантов задач?\n",
      "\n",
      "Ответ на вопрос: Основные сложности при генерации задач связаны с тем, что небольшие изменения в коэффициентах или структуре функций могут значительно повысить сложность интегралов. Например, изменение коэффициента в рациональной функции может привести к появлению корней, которые усложняют вычисления. Это показывает, что даже незначительные модификации могут сильно влиять на уровень трудности задачи.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "times = []\n",
    "\n",
    "for question in tqdm(questions):\n",
    "    reranked = retrieve_and_rerank(question, vectorstore, reranker, arxiv_id, top_k=10, top_n=2)\n",
    "    top_chunks = [doc.page_content for doc, score in reranked]\n",
    "    context = \"\\n\\n\".join(top_chunks)\n",
    "\n",
    "    messages = build_messages(question, context)\n",
    "    start = time.time()\n",
    "\n",
    "    answer = llm(messages, max_new_tokens=256, do_sample=False, eos_token_id=terminators)[0]['generated_text']\n",
    "\n",
    "    end = time.time()\n",
    "    inf_time = end - start\n",
    "    \n",
    "    times.append(inf_time)\n",
    "    print(f'Вопрос: {question}\\n')\n",
    "    print(f'Ответ на вопрос: {answer}\\n\\n')\n",
    "    outputs.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6d382048-bc22-4eb7-aa0b-3f65ddec1343",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_5 = times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9bc4a18b-b4f6-476d-99a1-71278aaac674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(7.925498390197754)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(times_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "69d584a6-7ae8-4fcc-b000-7bba9f97ec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test_results/article_5_questions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8e959c86-eb0d-483c-8f8d-28cb3094c830",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tbank'] = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7822e6af-26ad-4799-a005-8c20d4364054",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_results/article_5_questions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7be6cac2-042b-424f-97a9-632402db2913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее время генерации ответа Tbank: 8.5 сек\n"
     ]
    }
   ],
   "source": [
    "print(f'Среднее время генерации ответа Tbank: 8.5 сек')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da127717-84af-40d4-9b11-90f7275de834",
   "metadata": {},
   "source": [
    "### YandexGPT 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "637cb0c0-48e0-4de8-9959-ea7ad6617bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "664922c661674fbdb06f5c841e806135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_8864\\1072813799.py:8: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceBgeEmbeddings(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_8864\\1072813799.py:15: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(persist_directory=\"test_chroma_db\", embedding_function=embedding_model)\n"
     ]
    }
   ],
   "source": [
    "model_name = \"yandex/YandexGPT-5-Lite-8B-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "quant_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=quant_config, device_map=\"auto\")\n",
    "\n",
    "llm = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, return_full_text=False)\n",
    "\n",
    "embedding_model = HuggingFaceBgeEmbeddings(\n",
    "        model_name=\"BAAI/bge-m3\",\n",
    "        model_kwargs={\"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"}\n",
    "    )\n",
    "\n",
    "reranker = FlagReranker(\"BAAI/bge-reranker-v2-m3\", use_fp16=True)\n",
    "\n",
    "vectorstore = Chroma(persist_directory=\"test_chroma_db\", embedding_function=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "458dd2b9-36e8-40a5-889c-fca966ae0016",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_MSG = (\n",
    "    \"Ты — помощник по научным статьям. \"\n",
    "    \"Твоя задача — дать короткий, точный и однозначный ответ на вопрос, \"\n",
    "    \"используя только приведённый контекст. \"\n",
    "    \"Нельзя продолжать диалог, задавать встречные вопросы или повторяться. Отвечай строго на русском языке\"\n",
    ")\n",
    "\n",
    "\n",
    "def build_messages(question: str, context: str) -> List[dict]:\n",
    "    \"\"\"Формирует сообщения в нужном для chat_template формате.\"\"\"\n",
    "    return [\n",
    "        {\"role\": \"user\", \"content\": SYSTEM_MSG},\n",
    "        {\"role\": \"user\", \"content\": f\"Вопрос:\\n{question}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Контекст:\\n{context}\"},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60126971-0c96-4448-9b1e-6236c7f948f5",
   "metadata": {},
   "source": [
    "#### Attention is all you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70491b33-468b-4df2-a586-c5604c90a03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['Какой оптимайзер и гиперпараметры использовались в модели?',\n",
    "            'Какие архитектурные компоненты заменяет Transformer в традиционных sequence-to-sequence моделях?',\n",
    "             'Что такое Scaled Dot-Product Attention и зачем в нем используется деление на √dk?',\n",
    "             'Как устроена структура encoder и decoder в Transformer?',\n",
    "             'Почему Multi-Head Attention улучшает производительность по сравнению с одной головой внимания?',\n",
    "             'Какие функции выполняют позиционные кодировки и почему были выбраны синусоиды?',\n",
    "             'В чем преимущества self-attention по сравнению с рекуррентными и сверточными слоями в плане вычислительной сложности и длины пути зависимостей?',\n",
    "             'Какие техники регуляризации использовались при обучении Transformer?',\n",
    "             'Какие результаты Transformer показал на задачах перевода EN→DE и EN→FR по сравнению с предыдущими SOTA?',\n",
    "             'Почему Transformer позволяет более эффективную параллелизацию при обучении?'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e86c834a-f590-42e5-8717-f76f88630563",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_url = \"https://arxiv.org/abs/1706.03762\"\n",
    "arxiv_id = extract_arxiv_id(arxiv_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d711db2-1726-4f6e-9870-73c54753e184",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                             | 0/10 [00:00<?, ?it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                     | 1/10 [00:03<00:32,  3.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какой оптимайзер и гиперпараметры использовались в модели?\n",
      "\n",
      "Ответ на вопрос:  Мы использовали оптимизатор Adam с параметрами β1 = 0,9, β2 = 0,98 и ϵ = 10^[-9]^.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                     | 2/10 [00:06<00:24,  3.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие архитектурные компоненты заменяет Transformer в традиционных sequence-to-sequence моделях?\n",
      "\n",
      "Ответ на вопрос:  Transformer заменяет рекуррентные слои, наиболее часто используемые в архитектурах encoder-decoder, на механизм multi-headed self-attention.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                     | 3/10 [00:15<00:40,  5.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Что такое Scaled Dot-Product Attention и зачем в нем используется деление на √dk?\n",
      "\n",
      "Ответ на вопрос:  Scaled Dot-Product Attention — это метод внимания, при котором входные данные состоят из запросов и ключей размерности \\(d_k\\), и значений размерности \\(d_v\\). Сначала вычисляются скалярные произведения запроса со всеми ключами, затем каждое произведение делится на \\(\\sqrt{d_k}\\), после чего применяется функция softmax для получения весов значений. Деление на \\(\\sqrt{d_k}\\) используется для нормализации и стабилизации обучения.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                     | 4/10 [00:21<00:36,  6.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Как устроена структура encoder и decoder в Transformer?\n",
      "\n",
      "Ответ на вопрос:  Структура encoder и decoder в Transformer состоит из stacked self-attention и point-wise, fully connected layers. Encoder преобразует входную последовательность символьных представлений в последовательность непрерывных представлений. Decoder генерирует выходную последовательность символов, используя полученные от encoder данные и потребляя ранее сгенерированные символы как дополнительный вход для генерации следующего элемента.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                     | 5/10 [00:24<00:24,  4.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Почему Multi-Head Attention улучшает производительность по сравнению с одной головой внимания?\n",
      "\n",
      "Ответ на вопрос:  Multi-head attention позволяет модели совместно учитывать информацию из разных подпространств представлений в разных позициях. С одной головой внимания усреднение это ингибирует.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                     | 6/10 [00:31<00:22,  5.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие функции выполняют позиционные кодировки и почему были выбраны синусоиды?\n",
      "\n",
      "Ответ на вопрос:  Позиционные кодировки выполняют функцию представления позиции в виде синусоид. Они позволяют модели легко научиться учитывать относительные позиции, поскольку для любого фиксированного смещения k, PE(pos + k) можно представить как линейную функцию от PE(pos). Синусоиды были выбраны из-за гипотезы, что они помогут модели эффективно работать с относительными позициями.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                     | 7/10 [00:37<00:17,  5.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: В чем преимущества self-attention по сравнению с рекуррентными и сверточными слоями в плане вычислительной сложности и длины пути зависимостей?\n",
      "\n",
      "Ответ на вопрос:  В плане вычислительной сложности слой self-attention быстрее рекуррентных слоёв, когда длина последовательности $n$ меньше размерности представления $d$. Самовнимание соединяет все позиции с постоянным числом последовательно выполняемых операций, в то время как рекуррентный слой требует $O(n)$ последовательных операций.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.████▍                | 8/10 [00:38<00:08,  4.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие техники регуляризации использовались при обучении Transformer?\n",
      "\n",
      "Ответ на вопрос:  При обучении Transformer использовались три типа регуляризации.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.████████████▋        | 9/10 [00:43<00:04,  4.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие результаты Transformer показал на задачах перевода EN→DE и EN→FR по сравнению с предыдущими SOTA?\n",
      "\n",
      "Ответ на вопрос:  На задаче перевода EN→FR по WMT 2014 модель Transformer (big) достигла показателя BLEU 41,0, превзойдя все ранее опубликованные одиночные модели при меньшей в четыре раза стоимости обучения по сравнению с предыдущей передовой моделью.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:47<00:00,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Почему Transformer позволяет более эффективную параллелизацию при обучении?\n",
      "\n",
      "Ответ на вопрос:  Transformer позволяет значительно больше параллелизации, поскольку полностью полагается на механизм внимания для выявления глобальных зависимостей между входными и выходными данными, избегая при этом рекуррентных связей.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "times = []\n",
    "\n",
    "for question in tqdm(questions):\n",
    "    reranked = retrieve_and_rerank(question, vectorstore, reranker, arxiv_id, top_k=10, top_n=2)\n",
    "    top_chunks = [doc.page_content for doc, score in reranked]\n",
    "    context = \"\\n\\n\".join(top_chunks)\n",
    "\n",
    "    messages = build_messages(question, context)\n",
    "    start = time.time()\n",
    "\n",
    "    answer = llm(messages, max_new_tokens=256, do_sample=False, top_p=None, temperature=None)[0]['generated_text']\n",
    "\n",
    "    end = time.time()\n",
    "    inf_time = end - start\n",
    "    \n",
    "    times.append(inf_time)\n",
    "    print(f'Вопрос: {question}\\n')\n",
    "    print(f'Ответ на вопрос: {answer}\\n\\n')\n",
    "    outputs.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bf0e410-74d7-4530-9c99-c1a8d68e311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_1 = times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5eaf4d6f-b5c6-415a-b2d0-cc88ad83fc03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(4.636782193183899)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(times_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfad216d-5e1c-4ff5-9959-5aaa8c0f4c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test_results/article_1_questions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1af20de-2dd3-4a9b-b1af-c35dbfb69c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['YandexGPT'] = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73d8fe46-7e5f-4d2c-a7e9-cbdc85264370",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_results/article_1_questions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5164c79-29a5-478f-9755-3279995c5770",
   "metadata": {},
   "source": [
    "#### Статья TTRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06008292-8ff9-48ba-bac4-ff837c47d93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['В чем заключается основная идея метода Test-Time Reinforcement Learning (TTRL)?',\n",
    "             'Каким бразом осуществляется оценка вознаграждения в TTRL без доступа к истинным меткам?',\n",
    "             'Какую роль играет метод большинства голосов (majority voting) в архитектуре TTRL?',\n",
    "             'Какие улучшения производительности были достигнуты с помощью TTRL на бенчмарке AIME 2024?',\n",
    "             'Как TTRL сравнивается с RL на размеченных тестовых данных по эффективности?',\n",
    "             'Почему TTRL способен работать даже при неточных оценках меток?',\n",
    "             'Какие модели и бенчмарки использовались для оценки эффективности TTRL?',\n",
    "             'Какие факторы могут привести к сбою или неэффективности TTRL?',\n",
    "             'Как TTRL масштабируется при увеличении размера модели?',\n",
    "             'С какими алгоритмами обучения с подкреплением совместим TTRL и какие из них использовались в экспериментах?'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "305a4af8-f754-443b-b653-b23996072c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_url = \"https://arxiv.org/pdf/2504.16084\"\n",
    "arxiv_id = extract_arxiv_id(arxiv_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6fec39b4-10c2-4abc-80aa-cf74ea765b39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                             | 0/10 [00:00<?, ?it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                     | 1/10 [00:06<00:55,  6.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: В чем заключается основная идея метода Test-Time Reinforcement Learning (TTRL)?\n",
      "\n",
      "Ответ на вопрос:  Основная идея метода Test-Time Reinforcement Learning (TTRL) заключается в тренировке больших языковых моделей (LLMs) с помощью RL на немаркированных данных. TTRL позволяет моделям «самоэволюционировать», используя предварительные знания, заложенные в предварительно обученных моделях.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                     | 2/10 [00:10<00:39,  4.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Каким бразом осуществляется оценка вознаграждения в TTRL без доступа к истинным меткам?\n",
      "\n",
      "Ответ на вопрос:  Оценка вознаграждения в TTRL без доступа к истинным меткам осуществляется с помощью распространённых практик в Test-Time Scaling (TTS), таких как majority voting (мажоритарное голосование).\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                     | 3/10 [00:13<00:30,  4.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какую роль играет метод большинства голосов (majority voting) в архитектуре TTRL?\n",
      "\n",
      "Ответ на вопрос:  Метод большинства голосов (majority voting) в архитектуре TTRL играет ключевую роль, поскольку генерирует основанные на правилах вознаграждения на основе консенсуса среди предсказаний модели.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                     | 4/10 [00:20<00:31,  5.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие улучшения производительности были достигнуты с помощью TTRL на бенчмарке AIME 2024?\n",
      "\n",
      "Ответ на вопрос:  Применение TTRL к Qwen2.5-Math-7B привело к улучшению производительности на AIME 2024 на 159% (с 13,3 до 43,3), со средним приростом в 84% по AMC, AIME и MATH-500.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                     | 5/10 [00:23<00:21,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Как TTRL сравнивается с RL на размеченных тестовых данных по эффективности?\n",
      "\n",
      "Ответ на вопрос:  По результатам оценки на размеченных тестовых данных, кривая производительности TTRL близко приближается к кривой RL (leakage).\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                     | 6/10 [00:28<00:18,  4.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Почему TTRL способен работать даже при неточных оценках меток?\n",
      "\n",
      "Ответ на вопрос:  TTRL остаётся эффективным даже при неточных оценках меток, потому что награды в RL назначаются на основе соответствия предсказанного ответа «метке». Система может назначить корректное «отрицательное» вознаграждение, если предполагаемая метка отличается от неправильно предсказанного ответа.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                     | 7/10 [00:32<00:13,  4.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие модели и бенчмарки использовались для оценки эффективности TTRL?\n",
      "\n",
      "Ответ на вопрос:  Для оценки эффективности TTRL использовались модели Qwen2.5-Math-1.5B, Qwen2.5-Math-7B и LLaMA-3.1-8B-Instruct.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.████▍                | 8/10 [00:36<00:08,  4.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие факторы могут привести к сбою или неэффективности TTRL?\n",
      "\n",
      "Ответ на вопрос:  Фактором, который может привести к сбою или неэффективности TTRL, является недостаток предварительных знаний модели для выполнения целевой задачи из-за сложности данных.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.████████████▋        | 9/10 [00:42<00:04,  4.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Как TTRL масштабируется при увеличении размера модели?\n",
      "\n",
      "Ответ на вопрос:  TTRL естественно масштабируется: с увеличением размера модели (от 1,5B до 7B) наблюдается прирост производительности на AIME 2024 и AMC. Большие модели могут производить более точные вознаграждения за большинство голосов во время самосовершенствования, что приводит к более эффективному обучению на новых данных.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:45<00:00,  4.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: С какими алгоритмами обучения с подкреплением совместим TTRL и какие из них использовались в экспериментах?\n",
      "\n",
      "Ответ на вопрос:  TTRL совместим с разными алгоритмами обучения с подкреплением. В экспериментах использовался алгоритм PPO (Schulman et al., 2017).\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "times = []\n",
    "\n",
    "for question in tqdm(questions):\n",
    "    reranked = retrieve_and_rerank(question, vectorstore, reranker, arxiv_id, top_k=10, top_n=2)\n",
    "    top_chunks = [doc.page_content for doc, score in reranked]\n",
    "    context = \"\\n\\n\".join(top_chunks)\n",
    "\n",
    "    messages = build_messages(question, context)\n",
    "    start = time.time()\n",
    "\n",
    "    answer = llm(messages, max_new_tokens=256, do_sample=False, top_p=None, temperature=None)[0]['generated_text']\n",
    "\n",
    "    end = time.time()\n",
    "    inf_time = end - start\n",
    "    \n",
    "    times.append(inf_time)\n",
    "    print(f'Вопрос: {question}\\n')\n",
    "    print(f'Ответ на вопрос: {answer}\\n\\n')\n",
    "    outputs.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "017a3a51-845c-4ab5-95d7-7c3d31808fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_2 = times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3cd9823d-08a0-44d4-81e9-9798ad8cd00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(4.416370105743408)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(times_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61fee2ea-47f6-4d7b-bf22-0e6d036ae973",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test_results/article_2_questions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd9c0c92-0762-4687-a18d-63684117510c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['YandexGPT'] = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3ab16b3-fbb0-48ba-9322-28708fd41b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_results/article_2_questions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3066d1c-e6ab-48af-a970-f2441dd01926",
   "metadata": {},
   "source": [
    "#### Статья Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2165b788-0610-47bd-b583-332306072f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['Какая модель используется в качестве генератора в RAG?',\n",
    "             'Какая модель используется в качестве ретривера в RAG и как она инициализируется?',\n",
    "             'Чем отличаются архитектуры RAG-Token и RAG-Sequence?',\n",
    "             'Какой объем документов используется в векторном индексе Wikipedia?',\n",
    "             'Какие задачи были использованы для оценки RAG-моделей?',\n",
    "             'Почему авторы считают генерацию предпочтительной по сравнению с извлечением при ответе на вопросы?',\n",
    "             'Какую производительность показал RAG на задаче Jeopardy Question Generation по сравнению с BART?',\n",
    "             'Как осуществляется совместное обучение генератора и ретривера в RAG?',\n",
    "             'Какой эффект даёт \"hot-swapping\" индекса документов в RAG?',\n",
    "             'Какие аппроксимации используются при декодировании в RAG-Sequence и RAG-Token?'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa24508d-2b31-405b-9b2e-26512620825e",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_url = \"https://arxiv.org/pdf/2005.11401\"\n",
    "arxiv_id = extract_arxiv_id(arxiv_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b7b384e-f6af-473c-93af-52f1433a5101",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                             | 0/10 [00:00<?, ?it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                     | 1/10 [00:03<00:29,  3.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какая модель используется в качестве генератора в RAG?\n",
      "\n",
      "Ответ на вопрос:  В RAG используется генератор $p_{\\theta} (y_i|x, z, y_{1:i−1})$.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                     | 2/10 [00:06<00:25,  3.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какая модель используется в качестве ретривера в RAG и как она инициализируется?\n",
      "\n",
      "Ответ на вопрос:  В RAG в качестве ретривера используется ретривер из DPR, который инициализируется с помощью контроля извлечения на Natural Questions и TriviaQA.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                     | 3/10 [00:13<00:35,  5.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Чем отличаются архитектуры RAG-Token и RAG-Sequence?\n",
      "\n",
      "Ответ на вопрос:  RAG-Token можно рассматривать как стандартный авторегрессионный seq2seq генератор. В то время как для RAG-Sequence и RAG-Token требуются разные способы аппроксимации arg max y p(y|x), при декодировании используются различные подходы. RAG-Token использует переходную вероятность с учётом top-k (p(·|x)) и стандартного лучевого декодера.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                     | 4/10 [00:14<00:20,  3.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какой объем документов используется в векторном индексе Wikipedia?\n",
      "\n",
      "Ответ на вопрос:  21 млн документов.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                     | 5/10 [00:17<00:15,  3.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие задачи были использованы для оценки RAG-моделей?\n",
      "\n",
      "Ответ на вопрос:  Модели оценивались на широком спектре задач, требующих глубоких знаний в области NLP, и установили новый стандарт в трёх задачах открытого домена QA.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                     | 6/10 [00:21<00:13,  3.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Почему авторы считают генерацию предпочтительной по сравнению с извлечением при ответе на вопросы?\n",
      "\n",
      "Ответ на вопрос:  Авторы считают генерацию предпочтительной по сравнению с извлечением, потому что документы, содержащие подсказки об ответе, но не содержащие его дословно, всё равно могут способствовать формированию правильного ответа. Это невозможно при использовании стандартных экстрактивных подходов.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                     | 7/10 [00:27<00:12,  4.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какую производительность показал RAG на задаче Jeopardy Question Generation по сравнению с BART?\n",
      "\n",
      "Ответ на вопрос:  RAG-Token показал лучшие результаты, чем RAG-Sequence, и обе модели превзошли BART по Q-BLEU-1. Также оценщики отметили, что генерации RAG более фактурны в 42,7% случаев по сравнению с 7,1% у BART.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.████▍                | 8/10 [00:29<00:07,  3.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Как осуществляется совместное обучение генератора и ретривера в RAG?\n",
      "\n",
      "Ответ на вопрос:  Оба генератора и ретривера в RAG обучаются совместно путём тонкой настройки на любой seq2seq задаче.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.████████████▋        | 9/10 [00:31<00:03,  3.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какой эффект даёт \"hot-swapping\" индекса документов в RAG?\n",
      "\n",
      "Ответ на вопрос:  «Hot-swapping» индекса документов в RAG позволяет обновлять модель без необходимости переобучения.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:37<00:00,  3.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие аппроксимации используются при декодировании в RAG-Sequence и RAG-Token?\n",
      "\n",
      "Ответ на вопрос:  При декодировании в RAG-Sequence и RAG-Token используются различные способы аппроксимации arg max $y$ $p$ ($y|x$). В частности, для RAG-Token применяется подход с использованием стандартного beam decoder и переходных вероятностей с учётом top-$k$ ($p$ ($·|x$)).\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "times = []\n",
    "\n",
    "for question in tqdm(questions):\n",
    "    reranked = retrieve_and_rerank(question, vectorstore, reranker, arxiv_id, top_k=10, top_n=2)\n",
    "    top_chunks = [doc.page_content for doc, score in reranked]\n",
    "    context = \"\\n\\n\".join(top_chunks)\n",
    "\n",
    "    messages = build_messages(question, context)\n",
    "    start = time.time()\n",
    "\n",
    "    answer = llm(messages, max_new_tokens=256, do_sample=False, top_p=None, temperature=None)[0]['generated_text']\n",
    "\n",
    "    end = time.time()\n",
    "    inf_time = end - start\n",
    "    \n",
    "    times.append(inf_time)\n",
    "    print(f'Вопрос: {question}\\n')\n",
    "    print(f'Ответ на вопрос: {answer}\\n\\n')\n",
    "    outputs.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed48b19e-9ae2-410e-9ea3-dfd5a601d7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_3 = times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7171bd51-be99-403e-adc8-e74c42fab897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.6867867946624755)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(times_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e89224c0-1bfa-4ee4-91c4-9f56eec11162",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test_results/article_3_questions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f3bdd79e-993c-4237-88cc-83c300c3853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['YandexGPT'] = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ab879f76-ce08-4792-98bd-1b24d91daf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_results/article_3_questions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c3325e-5977-4570-83a3-d2d5c7ad4745",
   "metadata": {},
   "source": [
    "#### Статья Efficient Estimation of Word Representations in Vector Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1dbd275f-d14f-4cf1-b556-d5579c74881f",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['Какие две модели архитектур были предложены авторами для обучения векторных представлений слов?',\n",
    "             'В чём основное различие между архитектурами CBOW и Skip-gram?',\n",
    "             'Какие типы отношений включены в Semantic-Syntactic Word Relationship test set?',\n",
    "             'Какие значения точности показала модель Skip-gram на семантических и синтаксических подзадачах?',\n",
    "             'Какой подход используется в Skip-gram модели для выбора контекстных слов?',\n",
    "             'Какова формула вычислительной сложности модели CBOW?',\n",
    "             'Почему авторы отказались от использования скрытого слоя в новых архитектурах?',\n",
    "             'Как масштабировалась тренировка моделей в распределённой системе DistBelief?',\n",
    "             'Как были сгенерированы вопросы в тестовом наборе для оценки word vectors?',\n",
    "             'Какой метод используется для ответа на аналогии вроде “king - man + woman = ?”?'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8ed1d905-bfd9-436c-a50f-ff959dffb9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_url = \"https://arxiv.org/pdf/1301.3781\"\n",
    "arxiv_id = extract_arxiv_id(arxiv_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8dbe0e8d-14a5-490a-bdb1-d1a2485dbc13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                             | 0/10 [00:00<?, ?it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                     | 1/10 [00:04<00:42,  4.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие две модели архитектур были предложены авторами для обучения векторных представлений слов?\n",
      "\n",
      "Ответ на вопрос:  Авторы предложили две модели архитектур: \n",
      "1. Модель на основе полносвязной нейронной сети с линейным проекционным слоем и нелинейным скрытым слоем.\n",
      "2. Другая модельная архитектура для вычисления непрерывных векторных представлений слов.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                     | 2/10 [00:07<00:26,  3.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: В чём основное различие между архитектурами CBOW и Skip-gram?\n",
      "\n",
      "Ответ на вопрос:  CBOW предсказывает текущее слово на основе контекста, а Skip-gram предсказывает окружающие слова по заданному текущему слову.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                     | 3/10 [00:11<00:25,  3.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие типы отношений включены в Semantic-Syntactic Word Relationship test set?\n",
      "\n",
      "Ответ на вопрос:  В Semantic-Syntactic Word Relationship test set включены пять типов семантических отношений, например, отношение между страной и городом, который ей принадлежит (как Франция относится к Парижу, так Германия относится к Берлину).\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                     | 4/10 [00:13<00:19,  3.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие значения точности показала модель Skip-gram на семантических и синтаксических подзадачах?\n",
      "\n",
      "Ответ на вопрос:  Модель Skip-gram показала точность 55% на семантических подзадачах и 59% на синтаксических подзадачах.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                     | 5/10 [00:19<00:20,  4.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какой подход используется в Skip-gram модели для выбора контекстных слов?\n",
      "\n",
      "Ответ на вопрос:  В Skip-gram модели используется подход, при котором каждое текущее слово используется как вход для логистического классификатора с непрерывным проекционным слоем, и предсказываются слова в определённом диапазоне до и после текущего слова. При этом более отдалённым словам даётся меньше веса за счёт уменьшения их выборки в обучающих примерах.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                     | 6/10 [00:21<00:13,  3.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какова формула вычислительной сложности модели CBOW?\n",
      "\n",
      "Ответ на вопрос:  $Q = C × (D + D × log_2(V))$\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                     | 7/10 [00:27<00:12,  4.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Почему авторы отказались от использования скрытого слоя в новых архитектурах?\n",
      "\n",
      "Ответ на вопрос:  Авторы отказались от использования скрытого слоя в новых архитектурах, потому что посчитали, что нелинейный скрытый слой является источником большей части сложности вычислений. Они решили исследовать более простые модели, которые могут быть обучены на гораздо большем объёме данных более эффективно, даже если они не смогут представлять данные так же точно, как нейронные сети.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.████▍                | 8/10 [00:32<00:09,  4.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Как масштабировалась тренировка моделей в распределённой системе DistBelief?\n",
      "\n",
      "Ответ на вопрос:  В системе DistBelief тренировка моделей масштабировалась за счёт запуска множества реплик одной и той же модели параллельно. Использовалось от 50 до 100 реплик модели во время тренировки. Каждая реплика синхронизирует свои обновления градиента через централизованный сервер, который хранит все параметры.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.████████████▋        | 9/10 [00:36<00:04,  4.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Как были сгенерированы вопросы в тестовом наборе для оценки word vectors?\n",
      "\n",
      "Ответ на вопрос:  Вопросы в тестовом наборе для оценки word vectors были созданы в два этапа: сначала вручную был составлен список похожих пар слов, затем на их основе был сформирован большой список вопросов путём соединения двух пар слов.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:38<00:00,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какой метод используется для ответа на аналогии вроде “king - man + woman = ?”?\n",
      "\n",
      "Ответ на вопрос:  Метод word offset, где выполняются простые алгебраические операции над векторами слов.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "times = []\n",
    "\n",
    "for question in tqdm(questions):\n",
    "    reranked = retrieve_and_rerank(question, vectorstore, reranker, arxiv_id, top_k=10, top_n=2)\n",
    "    top_chunks = [doc.page_content for doc, score in reranked]\n",
    "    context = \"\\n\\n\".join(top_chunks)\n",
    "\n",
    "    messages = build_messages(question, context)\n",
    "    start = time.time()\n",
    "\n",
    "    answer = llm(messages, max_new_tokens=256, do_sample=False, top_p=None, temperature=None)[0]['generated_text']\n",
    "\n",
    "    end = time.time()\n",
    "    inf_time = end - start\n",
    "    \n",
    "    times.append(inf_time)\n",
    "    print(f'Вопрос: {question}\\n')\n",
    "    print(f'Ответ на вопрос: {answer}\\n\\n')\n",
    "    outputs.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cde3c09f-e385-4628-b1c5-f87656695f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_4 = times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a346d12-ab1b-4f30-8e0a-ac5f3813d9ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.7225289344787598)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(times_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0463ac07-242f-4f9c-9109-f67840f26855",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test_results/article_4_questions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da306ea2-bcbd-48ca-aa96-80c978d166f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['YandexGPT'] = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b62a3e57-aa45-4be9-b8d1-13f7d9d5ed98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_results/article_4_questions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a4bc3a-fc1b-4bee-9dcc-9b0922068913",
   "metadata": {},
   "source": [
    "#### Статья LADDER: SELF-IMPROVING LLMS THROUGH RECURSIVE PROBLEM DECOMPOSITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d3cc690f-5fc0-410f-8203-393e27cf255f",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['В чём заключается ключевая идея фреймворка LADDER?',\n",
    "             'Какой метод используется для верификации правильности решений интегралов в LADDER?',\n",
    "             'Как осуществляется генерация вариантов задач в LADDER?',\n",
    "             'Что такое TTRL и чем он отличается от LADDER?',\n",
    "             'Какие результаты достигнуты моделью Qwen2.5 7B на экзамене MIT Integration Bee после применения LADDER и TTRL?',\n",
    "             'Какая функция вознаграждения используется в GRPO в рамках обучения в LADDER?',\n",
    "             'Почему RL без использования вариантов задач показывает плохие результаты на задачах интегрирования?',\n",
    "             'Какие техники использовались для увеличения разнообразия генерируемых вариантов задач?',\n",
    "             'Как LADDER масштабирует обучение без увеличения размера модели?',\n",
    "             'Какие ограничения или сложности были замечены при генерации вариантов задач?'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c9a38d1b-062b-4b00-a4ae-960d86e79a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_url = \"https://arxiv.org/pdf/2503.00735\"\n",
    "arxiv_id = extract_arxiv_id(arxiv_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d729bbad-2047-4cb8-a2c5-22c775480c68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                             | 0/10 [00:00<?, ?it/s]\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                     | 1/10 [00:04<00:37,  4.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: В чём заключается ключевая идея фреймворка LADDER?\n",
      "\n",
      "Ответ на вопрос:  Ключевая идея фреймворка LADDER заключается в том, что модели могут самостоятельно улучшать свои способности к решению задач путём рекурсивного генерирования и решения постепенно упрощающихся вариантов сложных задач.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                     | 2/10 [00:05<00:21,  2.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какой метод используется для верификации правильности решений интегралов в LADDER?\n",
      "\n",
      "Ответ на вопрос:  Для верификации правильности решений интегралов в LADDER используется численный метод интеграции.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                     | 3/10 [00:10<00:23,  3.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Как осуществляется генерация вариантов задач в LADDER?\n",
      "\n",
      "Ответ на вопрос:  Генерация вариантов задач в LADDER осуществляется в два этапа: сначала собирается тренировочный набор интегралов, затем для каждого интеграла генерируется дерево вариантов. Этот процесс описан в разделе 3.1.2.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                     | 4/10 [00:20<00:36,  6.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Что такое TTRL и чем он отличается от LADDER?\n",
      "\n",
      "Ответ на вопрос:  TTRL — это более эффективный метод масштабирования во время тестирования, чем многократные попытки решить тестовый вопрос. В отличие от LADDER, TTRL применяет рекурсивное разложение задачи непосредственно к тестовым вопросам, что позволяет исходной модели LADDER корректно решать некоторые из самых сложных вопросов. LADDER включает в себя генерацию вариантов, проверку решений и обучение с подкреплением, в то время как TTRL демонстрирует улучшение показателей за счёт рекурсивного подхода к разложению задач во время тестирования.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                     | 5/10 [00:23<00:24,  4.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие результаты достигнуты моделью Qwen2.5 7B на экзамене MIT Integration Bee после применения LADDER и TTRL?\n",
      "\n",
      "Ответ на вопрос:  После применения LADDER и TTRL модель Qwen2.5 7B достигла результата в 90% на экзамене MIT Integration Bee.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                     | 6/10 [00:25<00:16,  4.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какая функция вознаграждения используется в GRPO в рамках обучения в LADDER?\n",
      "\n",
      "Ответ на вопрос:  В GRPO в рамках обучения в LADDER используется функция вознаграждения, основанная на групповых оценках (baseline from group scores).\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.                     | 7/10 [00:29<00:12,  4.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Почему RL без использования вариантов задач показывает плохие результаты на задачах интегрирования?\n",
      "\n",
      "Ответ на вопрос:  Успех RL с вариантами задач обусловлен тщательно сконструированным градиентом сложности, а не самим алгоритмом RL. RL без использования вариантов задач показывает плохие результаты на задачах интегрирования из-за неэффективности прямого обучения в таких задачах.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.████▍                | 8/10 [00:38<00:11,  5.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие техники использовались для увеличения разнообразия генерируемых вариантов задач?\n",
      "\n",
      "Ответ на вопрос:  Для увеличения разнообразия генерируемых вариантов задач использовались следующие техники:\n",
      "1. Температурный цикл (Temperature cycling) — динамическое изменение температуры выборки между 0,8 и 1,4 для разных запросов.\n",
      "2. Персонифицированные подсказки (Persona-based prompting) — модель получала задание принять разные математические перспективы (например, «думай как Эйлер, фокусируясь на рядах», «подходи как Гаусс, ища закономерности»).\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.████████████▋        | 9/10 [00:42<00:04,  4.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Как LADDER масштабирует обучение без увеличения размера модели?\n",
      "\n",
      "Ответ на вопрос:  LADDER масштабирует обучение без увеличения размера модели за счёт рекурсивного разложения задач на более простые подзадачи и использования обучения с подкреплением с проверяемыми вознаграждениями.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:46<00:00,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие ограничения или сложности были замечены при генерации вариантов задач?\n",
      "\n",
      "Ответ на вопрос:  При генерации вариантов задач были замечены сложности с контролем качества. Модель генерировала интегралы, сложность которых существенно отличалась от заданного уровня. Небольшие изменения в коэффициентах или составе функций могли превратить кажущиеся простыми интегралы в гораздо более сложные.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "times = []\n",
    "\n",
    "for question in tqdm(questions):\n",
    "    reranked = retrieve_and_rerank(question, vectorstore, reranker, arxiv_id, top_k=10, top_n=2)\n",
    "    top_chunks = [doc.page_content for doc, score in reranked]\n",
    "    context = \"\\n\\n\".join(top_chunks)\n",
    "\n",
    "    messages = build_messages(question, context)\n",
    "    start = time.time()\n",
    "\n",
    "    answer = llm(messages, max_new_tokens=256, do_sample=False, top_p=None, temperature=None)[0]['generated_text']\n",
    "\n",
    "    end = time.time()\n",
    "    inf_time = end - start\n",
    "    \n",
    "    times.append(inf_time)\n",
    "    print(f'Вопрос: {question}\\n')\n",
    "    print(f'Ответ на вопрос: {answer}\\n\\n')\n",
    "    outputs.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "13cd4e77-a182-4dc8-b879-92b8e57a8030",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_5 = times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1fe7a6f0-5cdb-4d3a-bdf4-2f8056dfaa28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(4.579136824607849)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(times_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "785759ac-ee74-4ea0-af10-48ce17ff38ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test_results/article_5_questions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e9123554-125c-4b32-ac1e-f530040e4e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['YandexGPT'] = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "98a89be4-7d0f-4d6e-972c-39b2e9f7d7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_results/article_5_questions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a4ec9181-123d-4569-8345-944d7b6bd210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее время генерации ответа Yandex: 4.2 сек\n"
     ]
    }
   ],
   "source": [
    "print(f'Среднее время генерации ответа Yandex: {np.mean(times_1 + times_2 + times_3 + times_4 + times_5):.1f} сек')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9783355-663d-4421-a523-faf849b83504",
   "metadata": {},
   "source": [
    "### QWEN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d3384fe-37a6-44e7-a5bc-9bdef11190bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb929e12259c47de82f10cc81ec227a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_4284\\1997649636.py:16: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceBgeEmbeddings(\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_4284\\1997649636.py:23: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(persist_directory=\"test_chroma_db\", embedding_function=embedding_model)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"Qwen/Qwen3-8B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "quant_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    #quantization_config=quant_config,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"cuda\"\n",
    ")\n",
    "\n",
    "llm = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, return_full_text=False)\n",
    "\n",
    "embedding_model = HuggingFaceBgeEmbeddings(\n",
    "        model_name=\"BAAI/bge-m3\",\n",
    "        model_kwargs={\"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"}\n",
    "    )\n",
    "\n",
    "reranker = FlagReranker(\"BAAI/bge-reranker-v2-m3\", use_fp16=True)\n",
    "\n",
    "vectorstore = Chroma(persist_directory=\"test_chroma_db\", embedding_function=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a349b84a-e149-4d72-9fcb-6e73612c6e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_MSG = (\n",
    "    \"Ты — помощник по научным статьям. \"\n",
    "    \"Твоя задача — дать короткий, точный и однозначный ответ на вопрос, используя только приведённый контекст. \"\n",
    "    \"Нельзя продолжать диалог, задавать встречные вопросы или повторяться. Отвечай строго на русском языке\"\n",
    ")\n",
    "\n",
    "\n",
    "def build_messages(question: str, context: str) -> List[dict]:\n",
    "    \"\"\"Формирует сообщения в нужном для chat_template формате.\"\"\"\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_MSG},\n",
    "        {\"role\": \"user\", \"content\": f\"Вопрос:\\n{question}\"},\n",
    "        {\"role\": \"assistant\", \"content\": f\"Контекст:\\n{context}\"}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979462cc-4e9a-48a9-adc0-6b4db2be54bc",
   "metadata": {},
   "source": [
    "#### Attention is all you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "427ed5f6-f0d9-43e2-bbc1-9e12d85e60f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['Какой оптимайзер и гиперпараметры использовались в модели?',\n",
    "            'Какие архитектурные компоненты заменяет Transformer в традиционных sequence-to-sequence моделях?',\n",
    "             'Что такое Scaled Dot-Product Attention и зачем в нем используется деление на √dk?',\n",
    "             'Как устроена структура encoder и decoder в Transformer?',\n",
    "             'Почему Multi-Head Attention улучшает производительность по сравнению с одной головой внимания?',\n",
    "             'Какие функции выполняют позиционные кодировки и почему были выбраны синусоиды?',\n",
    "             'В чем преимущества self-attention по сравнению с рекуррентными и сверточными слоями в плане вычислительной сложности и длины пути зависимостей?',\n",
    "             'Какие техники регуляризации использовались при обучении Transformer?',\n",
    "             'Какие результаты Transformer показал на задачах перевода EN→DE и EN→FR по сравнению с предыдущими SOTA?',\n",
    "             'Почему Transformer позволяет более эффективную параллелизацию при обучении?'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1f9399d-e912-4f1d-8f7b-fe0dbc3b188e",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_url = \"https://arxiv.org/abs/1706.03762\"\n",
    "arxiv_id = extract_arxiv_id(arxiv_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce3e54df-e77f-46fc-b978-0d68b5caed60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_4284\\2189633747.py:13: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  candidates = retriever.get_relevant_documents(question)\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      " 10%|████████▎                                                                          | 1/10 [00:11<01:40, 11.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какой оптимайзер и гиперпараметры использовались в модели?\n",
      "\n",
      "Ответ на вопрос: Оптимайзер — Adam, гиперпараметры: β₁ = 0.9, β₂ = 0.98, ε = 10⁻⁹.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 2/10 [00:16<01:00,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие архитектурные компоненты заменяет Transformer в традиционных sequence-to-sequence моделях?\n",
      "\n",
      "Ответ на вопрос: Рекуррентные слои.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 3/10 [00:29<01:10, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Что такое Scaled Dot-Product Attention и зачем в нем используется деление на √dk?\n",
      "\n",
      "Ответ на вопрос: Scaled Dot-Product Attention — это механизм внимания, в котором вычисляется скалярное произведение между векторами запросов и ключей, затем результат делится на √dk, чтобы стабилизировать значения перед применением softmax. Деление на √dk используется для предотвращения больших значений скалярного произведения, что может привести к нестабильности при обучении.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:44<01:13, 12.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Как устроена структура encoder и decoder в Transformer?\n",
      "\n",
      "Ответ на вопрос: Encoder состоит из стека из 6 идентичных слоев, каждый из которых включает два подслоя: самопроизвольное внимание и полностью связанный слой. Decoder также состоит из стека из 6 идентичных слоев, каждый из которых включает три подслоя: самопроизвольное внимание, полностью связанный слой и внимание к encoder'у. В decoder'е используется маскировка, чтобы предотвратить зависимость от последующих позиций.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [00:56<00:59, 11.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Почему Multi-Head Attention улучшает производительность по сравнению с одной головой внимания?\n",
      "\n",
      "Ответ на вопрос: Multi-Head Attention улучшает производительность, так как позволяет модели одновременно обращать внимание к информации из разных подпространств представлений, что повышает способность к захвату различных аспектов данных. Одна голова внимания ограничивает эту способность, так как её выходы усредняются.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [01:08<00:47, 11.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие функции выполняют позиционные кодировки и почему были выбраны синусоиды?\n",
      "\n",
      "Ответ на вопрос: Позиционные кодировки позволяют модели учитывать относительные позиции слов в последовательности. Синусоиды были выбраны, потому что они позволяют модели легко вычислять относительные позиции и экстраполировать на более длинные последовательности.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [01:25<00:41, 13.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: В чем преимущества self-attention по сравнению с рекуррентными и сверточными слоями в плане вычислительной сложности и длины пути зависимостей?\n",
      "\n",
      "Ответ на вопрос: Self-attention имеет постоянное число операций независимо от длины последовательности, в то время как рекуррентные слои требуют *O(n)* последовательных операций. Это делает self-attention более эффективным по вычислительной сложности при длине последовательности *n*, меньшей, чем размерность представления *d*. Self-attention также позволяет модели учитывать зависимости между всеми позициями последовательности, в отличие от рекуррентных и сверточных слоев, которые ограничены локальными зависимостями.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [01:33<00:23, 11.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие техники регуляризации использовались при обучении Transformer?\n",
      "\n",
      "Ответ на вопрос: В обучении Transformer использовались три типа регуляризации.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [01:40<00:10, 10.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие результаты Transformer показал на задачах перевода EN→DE и EN→FR по сравнению с предыдущими SOTA?\n",
      "\n",
      "Ответ на вопрос: Transformer показал BLEU-счет 41.8 на задаче EN→FR, что превзошло предыдущие SOTA модели.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:53<00:00, 11.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Почему Transformer позволяет более эффективную параллелизацию при обучении?\n",
      "\n",
      "Ответ на вопрос: Потому что Transformer использует механизм внимания, который позволяет моделировать зависимости между любыми позициями входа и выхода за постоянное число операций, в отличие от моделей с рекуррентными или свёрточными сетями, где число операций растёт с расстоянием между позициями. Это позволяет более эффективно использовать параллельные вычисления.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "times = []\n",
    "\n",
    "for question in tqdm(questions):\n",
    "    reranked = retrieve_and_rerank(question, vectorstore, reranker, arxiv_id, top_k=10, top_n=2)\n",
    "    top_chunks = [doc.page_content for doc, score in reranked]\n",
    "    context = \"\\n\\n\".join(top_chunks)\n",
    "\n",
    "    messages = build_messages(question, context)\n",
    "    messages = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True, enable_thinking=False)\n",
    "    start = time.time()\n",
    "    \n",
    "    answer = llm(messages, max_new_tokens=256, do_sample=False, temperature=None, top_p=None, top_k=None)[0]['generated_text']\n",
    "    \n",
    "    end = time.time()\n",
    "    inf_time = end - start\n",
    "    \n",
    "    times.append(inf_time)\n",
    "    print(f'Вопрос: {question}\\n')\n",
    "    print(f'Ответ на вопрос: {answer}\\n\\n')\n",
    "    outputs.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f88bb006-9896-414c-8ebc-aadeb93ee990",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_1 = times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "498c3e23-bbed-436c-85f7-ddd363793b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(8.321885013580323)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(times_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90bc6696-18cd-47b1-a045-0c307829619e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test_results/article_1_questions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2dc52b2-0806-4f45-a5e2-a1e8afeee7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Qwen3'] = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba7eaa0f-7bda-4059-a5ec-d90acef1abcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_results/article_1_questions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5864a8a6-c64d-4ae8-a9d3-3a02c10d96bf",
   "metadata": {},
   "source": [
    "#### Статья TTRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c08e7db-41d0-4abb-8990-b0802abb267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['В чем заключается основная идея метода Test-Time Reinforcement Learning (TTRL)?',\n",
    "             'Каким бразом осуществляется оценка вознаграждения в TTRL без доступа к истинным меткам?',\n",
    "             'Какую роль играет метод большинства голосов (majority voting) в архитектуре TTRL?',\n",
    "             'Какие улучшения производительности были достигнуты с помощью TTRL на бенчмарке AIME 2024?',\n",
    "             'Как TTRL сравнивается с RL на размеченных тестовых данных по эффективности?',\n",
    "             'Почему TTRL способен работать даже при неточных оценках меток?',\n",
    "             'Какие модели и бенчмарки использовались для оценки эффективности TTRL?',\n",
    "             'Какие факторы могут привести к сбою или неэффективности TTRL?',\n",
    "             'Как TTRL масштабируется при увеличении размера модели?',\n",
    "             'С какими алгоритмами обучения с подкреплением совместим TTRL и какие из них использовались в экспериментах?'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4fabd77-9fff-4cbc-9fb8-5d364d35caee",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_url = \"https://arxiv.org/pdf/2504.16084\"\n",
    "arxiv_id = extract_arxiv_id(arxiv_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e594b17-c3d3-4607-bf6d-782c0e3641b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 1/10 [00:12<01:51, 12.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: В чем заключается основная идея метода Test-Time Reinforcement Learning (TTRL)?\n",
      "\n",
      "Ответ на вопрос: Основная идея метода Test-Time Reinforcement Learning (TTRL) заключается в обучении больших языковых моделей с использованием усилительного обучения (RL) на тестовых данных без доступа к меткам, где награды оцениваются на основе согласованности предсказаний модели (метод большинства).\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 2/10 [00:22<01:27, 10.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Каким бразом осуществляется оценка вознаграждения в TTRL без доступа к истинным меткам?\n",
      "\n",
      "Ответ на вопрос: Оценка вознаграждения в TTRL осуществляется с использованием методов, таких как большинство голосов, для оценки меток и вычисления рулеточных вознаграждений на основе правил, без доступа к истинным меткам.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 3/10 [00:31<01:11, 10.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какую роль играет метод большинства голосов (majority voting) в архитектуре TTRL?\n",
      "\n",
      "Ответ на вопрос: Метод большинства голосов (majority voting) в архитектуре TTRL используется для генерации правил на основе согласия среди предсказаний модели, что позволяет формировать награды в условиях отсутствия меток.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:39<00:55,  9.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие улучшения производительности были достигнуты с помощью TTRL на бенчмарке AIME 2024?\n",
      "\n",
      "Ответ на вопрос: Улучшения производительности с помощью TTRL на бенчмарке AIME 2024 составили 159.3%.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [00:46<00:41,  8.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Как TTRL сравнивается с RL на размеченных тестовых данных по эффективности?\n",
      "\n",
      "Ответ на вопрос: TTRL показывает эффективность, сравнимую с RL на размеченных тестовых данных, и в некоторых случаях превосходит их.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [00:53<00:31,  7.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Почему TTRL способен работать даже при неточных оценках меток?\n",
      "\n",
      "Ответ на вопрос: Потому что награды более плотные, чем метки, что позволяет получать полезные сигналы обучения даже при неточных оценках меток.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [01:03<00:25,  8.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие модели и бенчмарки использовались для оценки эффективности TTRL?\n",
      "\n",
      "Ответ на вопрос: Модели: Qwen2.5-Math-7B, DeepSeek-R1. Бенчмарки: AIME 2024, AMC, MATH-500.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [01:17<00:20, 10.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие факторы могут привести к сбою или неэффективности TTRL?\n",
      "\n",
      "Ответ на вопрос: Недостаток предварительных знаний о целевой задаче, сложность тестовых данных, зависимость от приоров, риски коллапса, ограниченность метода оценки меток через голосование и редкость и неизвестность тестовых данных.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [01:28<00:10, 10.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Как TTRL масштабируется при увеличении размера модели?\n",
      "\n",
      "Ответ на вопрос: TTRL естественно масштабируется с увеличением размера модели, так как более крупные модели способны генерировать более точные награды при голосовании большинством, что приводит к более эффективному обучению на новых данных.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:35<00:00,  9.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: С какими алгоритмами обучения с подкреплением совместим TTRL и какие из них использовались в экспериментах?\n",
      "\n",
      "Ответ на вопрос: TTRL совместим с алгоритмами PPO и GRPO, и в экспериментах использовался PPO.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "times = []\n",
    "\n",
    "for question in tqdm(questions):\n",
    "    reranked = retrieve_and_rerank(question, vectorstore, reranker, arxiv_id, top_k=10, top_n=2)\n",
    "    top_chunks = [doc.page_content for doc, score in reranked]\n",
    "    context = \"\\n\\n\".join(top_chunks)\n",
    "\n",
    "    messages = build_messages(question, context)\n",
    "    messages = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True, enable_thinking=False)\n",
    "    start = time.time()\n",
    "\n",
    "    answer = llm(messages, max_new_tokens=256, do_sample=False, top_p=None, temperature=None, top_k=None)[0]['generated_text']\n",
    "\n",
    "    end = time.time()\n",
    "    inf_time = end - start\n",
    "    \n",
    "    times.append(inf_time)\n",
    "    print(f'Вопрос: {question}\\n')\n",
    "    print(f'Ответ на вопрос: {answer}\\n\\n')\n",
    "    outputs.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c953d4f5-55f9-4612-827a-c1e75cb8e99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_2 = times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb49efae-070c-4b90-8d1b-fe63b28b8a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(6.568811774253845)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(times_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2a833af-e973-4fe6-8aae-09df68e29b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test_results/article_2_questions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "881c994d-034c-48a2-9663-e9dd153c0bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Qwen3'] = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a52ab972-6d98-4b05-9c9d-4b4d12e265af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_results/article_2_questions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133536e2-360e-476f-bfa5-e64bfef3762e",
   "metadata": {},
   "source": [
    "#### Статья Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "761ed1d5-7dc6-4de5-af41-b15fa6892e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['Какая модель используется в качестве генератора в RAG?',\n",
    "             'Какая модель используется в качестве ретривера в RAG и как она инициализируется?',\n",
    "             'Чем отличаются архитектуры RAG-Token и RAG-Sequence?',\n",
    "             'Какой объем документов используется в векторном индексе Wikipedia?',\n",
    "             'Какие задачи были использованы для оценки RAG-моделей?',\n",
    "             'Почему авторы считают генерацию предпочтительной по сравнению с извлечением при ответе на вопросы?',\n",
    "             'Какую производительность показал RAG на задаче Jeopardy Question Generation по сравнению с BART?',\n",
    "             'Как осуществляется совместное обучение генератора и ретривера в RAG?',\n",
    "             'Какой эффект даёт \"hot-swapping\" индекса документов в RAG?',\n",
    "             'Какие аппроксимации используются при декодировании в RAG-Sequence и RAG-Token?'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab624c89-ff7b-476d-88b4-a2e39cd9054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_url = \"https://arxiv.org/pdf/2005.11401\"\n",
    "arxiv_id = extract_arxiv_id(arxiv_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3182353-901f-46a4-9e02-fe4011f9067b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 1/10 [00:05<00:51,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какая модель используется в качестве генератора в RAG?\n",
      "\n",
      "Ответ на вопрос: RAG-Sequence модель.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 2/10 [00:15<01:05,  8.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какая модель используется в качестве ретривера в RAG и как она инициализируется?\n",
      "\n",
      "Ответ на вопрос: В RAG в качестве ретривера используется Dense Passage Retriever (DPR), инициализированный с использованием предобучения на данных Natural Questions и TriviaQA.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 3/10 [00:27<01:08,  9.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Чем отличаются архитектуры RAG-Token и RAG-Sequence?\n",
      "\n",
      "Ответ на вопрос: Архитектура RAG-Token использует токенизацию для генерации ответа, а RAG-Sequence — последовательную генерацию, где каждый шаг зависит от предыдущих.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:34<00:52,  8.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какой объем документов используется в векторном индексе Wikipedia?\n",
      "\n",
      "Ответ на вопрос: Объем документов в векторном индексе Wikipedia составляет 21 миллион.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [00:44<00:46,  9.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие задачи были использованы для оценки RAG-моделей?\n",
      "\n",
      "Ответ на вопрос: Для оценки RAG-моделей использовались задачи, связанные с открытым доменом, включая QA (question answering) на задачах, таких как TQA, Natural Questions и TriviaQA.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [00:57<00:42, 10.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Почему авторы считают генерацию предпочтительной по сравнению с извлечением при ответе на вопросы?\n",
      "\n",
      "Ответ на вопрос: Авторы считают генерацию предпочтительной по сравнению с извлечением, потому что генерация позволяет получать более точные и конкретные ответы, даже если документы содержат подсказки, но не содержат ответа напрямую, что невозможно с помощью стандартных извлекающих методов.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [01:05<00:28,  9.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какую производительность показал RAG на задаче Jeopardy Question Generation по сравнению с BART?\n",
      "\n",
      "Ответ на вопрос: RAG показал лучшую производительность, чем BART, на задаче Jeopardy Question Generation по метрике Q-BLEU-1.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [01:21<00:23, 11.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Как осуществляется совместное обучение генератора и ретривера в RAG?\n",
      "\n",
      "Ответ на вопрос: Совместное обучение генератора и ретривера в RAG осуществляется через минимизацию отрицательного маргинального логарифмического правдоподобия целевых выходов с использованием стохастического градиентного спуска, при этом документовый энкодер фиксируется, а только query энкодер и генератор подвергаются тонкой настройке.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [01:31<00:11, 11.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какой эффект даёт \"hot-swapping\" индекса документов в RAG?\n",
      "\n",
      "Ответ на вопрос: \"Hot-swapping\" индекса документов в RAG позволяет обновлять знания модели в режиме реального времени без необходимости переобучения, что обеспечивает актуальность информации при сохранении структуры и параметров модели.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:44<00:00, 10.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие аппроксимации используются при декодировании в RAG-Sequence и RAG-Token?\n",
      "\n",
      "Ответ на вопрос: В RAG-Sequence используется аппроксимация top-K для маргинализации вероятности, а в RAG-Token — аппроксимация с использованием top-K и последовательного декодирования с учетом ретривированных документов.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "times = []\n",
    "\n",
    "for question in tqdm(questions):\n",
    "    reranked = retrieve_and_rerank(question, vectorstore, reranker, arxiv_id, top_k=10, top_n=2)\n",
    "    top_chunks = [doc.page_content for doc, score in reranked]\n",
    "    context = \"\\n\\n\".join(top_chunks)\n",
    "\n",
    "    messages = build_messages(question, context)\n",
    "    messages = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True, enable_thinking=False)\n",
    "    start = time.time()\n",
    "\n",
    "    answer = llm(messages, max_new_tokens=256, do_sample=False, top_p=None, temperature=None, top_k=None)[0]['generated_text']\n",
    "\n",
    "    end = time.time()\n",
    "    inf_time = end - start\n",
    "    \n",
    "    times.append(inf_time)\n",
    "    print(f'Вопрос: {question}\\n')\n",
    "    print(f'Ответ на вопрос: {answer}\\n\\n')\n",
    "    outputs.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5106a9f-4e74-4070-a3d1-0588d9458e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_3 = times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "530563ee-e018-45cc-8539-089d36b31616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(7.817001175880432)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(times_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58adca76-ac7b-4958-8204-d787070795e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test_results/article_3_questions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fbdd1d45-23e8-4278-9fb9-d1b8e04897b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Qwen3'] = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ed73320-741c-46ea-84f8-07505a1fbed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_results/article_3_questions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771dc43e-6817-4532-97fd-3a9902b4fcb9",
   "metadata": {},
   "source": [
    "#### Статья Efficient Estimation of Word Representations in Vector Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15e185f5-b757-4253-b238-7168b7bc982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['Какие две модели архитектур были предложены авторами для обучения векторных представлений слов?',\n",
    "             'В чём основное различие между архитектурами CBOW и Skip-gram?',\n",
    "             'Какие типы отношений включены в Semantic-Syntactic Word Relationship test set?',\n",
    "             'Какие значения точности показала модель Skip-gram на семантических и синтаксических подзадачах?',\n",
    "             'Какой подход используется в Skip-gram модели для выбора контекстных слов?',\n",
    "             'Какова формула вычислительной сложности модели CBOW?',\n",
    "             'Почему авторы отказались от использования скрытого слоя в новых архитектурах?',\n",
    "             'Как масштабировалась тренировка моделей в распределённой системе DistBelief?',\n",
    "             'Как были сгенерированы вопросы в тестовом наборе для оценки word vectors?',\n",
    "             'Какой метод используется для ответа на аналогии вроде “king - man + woman = ?”?'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "655aad71-46c7-4a40-a0ef-e95a84921807",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_url = \"https://arxiv.org/pdf/1301.3781\"\n",
    "arxiv_id = extract_arxiv_id(arxiv_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b78ca5a2-523c-4bcc-9c44-ea425c4fb24e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 1/10 [00:10<01:30, 10.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие две модели архитектур были предложены авторами для обучения векторных представлений слов?\n",
      "\n",
      "Ответ на вопрос: Две модели архитектур, предложенные авторами, — это модель с линейным проекционным слоем и нелинейным скрытым слоем, а также модель, основанная на других типах нейронных сетей.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 2/10 [00:28<01:57, 14.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: В чём основное различие между архитектурами CBOW и Skip-gram?\n",
      "\n",
      "Ответ на вопрос: Основное различие между архитектурами CBOW и Skip-gram заключается в том, что CBOW предсказывает текущее слово на основе контекста, а Skip-gram предсказывает окружающие слова на основе текущего слова.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 3/10 [00:38<01:29, 12.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие типы отношений включены в Semantic-Syntactic Word Relationship test set?\n",
      "\n",
      "Ответ на вопрос: В Semantic-Syntactic Word Relationship test set включены пять типов семантических и девять типов синтаксических отношений.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:50<01:14, 12.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие значения точности показала модель Skip-gram на семантических и синтаксических подзадачах?\n",
      "\n",
      "Ответ на вопрос: Модель Skip-gram показала точность 50.0% на семантической подзадаче и 55.9% на синтаксической подзадаче.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [00:56<00:51, 10.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какой подход используется в Skip-gram модели для выбора контекстных слов?\n",
      "\n",
      "Ответ на вопрос: Сэмплирование с весами, где более близкие слова имеют больший вес.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [01:05<00:38,  9.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какова формула вычислительной сложности модели CBOW?\n",
      "\n",
      "Ответ на вопрос: Формула вычислительной сложности модели CBOW: $ Q = C \\times (D + D \\times \\log_2(V)) $.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [01:12<00:26,  8.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Почему авторы отказались от использования скрытого слоя в новых архитектурах?\n",
      "\n",
      "Ответ на вопрос: Авторы отказались от использования скрытого слоя, чтобы уменьшить вычислительную сложность модели и повысить эффективность обучения на больших объемах данных.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [01:23<00:18,  9.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Как масштабировалась тренировка моделей в распределённой системе DistBelief?\n",
      "\n",
      "Ответ на вопрос: Модели масштабировались с использованием 50 до 100 реплик модели, каждая из которых использовала несколько CPU-ядер на разных машинах в центре данных.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [01:34<00:10, 10.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Как были сгенерированы вопросы в тестовом наборе для оценки word vectors?\n",
      "\n",
      "Ответ на вопрос: Вопросы в тестовом наборе были сгенерированы в два этапа: сначала создавалась ручная список пар схожих слов, а затем формировался большой список вопросов путём случайного соединения двух пар слов.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:45<00:00, 10.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какой метод используется для ответа на аналогии вроде “king - man + woman = ?”?\n",
      "\n",
      "Ответ на вопрос: Метод, используемый для ответа на аналогии вроде “king - man + woman =?”, — это метод векторных операций, основанный на алгебраических действиях с векторами слов.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "times = []\n",
    "\n",
    "for question in tqdm(questions):\n",
    "    reranked = retrieve_and_rerank(question, vectorstore, reranker, arxiv_id, top_k=10, top_n=2)\n",
    "    top_chunks = [doc.page_content for doc, score in reranked]\n",
    "    context = \"\\n\\n\".join(top_chunks)\n",
    "\n",
    "    messages = build_messages(question, context)\n",
    "    messages = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True, enable_thinking=False)\n",
    "    start = time.time()\n",
    "\n",
    "    answer = llm(messages, max_new_tokens=256, do_sample=False, top_p=None, temperature=None, top_k=None)[0]['generated_text']\n",
    "\n",
    "    end = time.time()\n",
    "    inf_time = end - start\n",
    "    \n",
    "    times.append(inf_time)\n",
    "    print(f'Вопрос: {question}\\n')\n",
    "    print(f'Ответ на вопрос: {answer}\\n\\n')\n",
    "    outputs.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2749ba3f-db5b-45d2-84d5-4a4f41f0707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_4 = times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a58314a2-0bf0-4ac9-8b6c-5142cbb7a926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(7.517814183235169)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(times_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c8fbe37e-79cc-4c30-ba76-7afeb0e66d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test_results/article_4_questions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d303f682-6ea5-44a6-b58a-c84c31ccfef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Qwen3'] = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2eef40e3-0997-4c37-af32-1f43d8037450",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_results/article_4_questions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bc47fd-9302-4227-bcaf-9a439114bc9f",
   "metadata": {},
   "source": [
    "#### Статья LADDER: SELF-IMPROVING LLMS THROUGH RECURSIVE PROBLEM DECOMPOSITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f08878ca-0cdc-413d-a87d-1af179184eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['В чём заключается ключевая идея фреймворка LADDER?',\n",
    "             'Какой метод используется для верификации правильности решений интегралов в LADDER?',\n",
    "             'Как осуществляется генерация вариантов задач в LADDER?',\n",
    "             'Что такое TTRL и чем он отличается от LADDER?',\n",
    "             'Какие результаты достигнуты моделью Qwen2.5 7B на экзамене MIT Integration Bee после применения LADDER и TTRL?',\n",
    "             'Какая функция вознаграждения используется в GRPO в рамках обучения в LADDER?',\n",
    "             'Почему RL без использования вариантов задач показывает плохие результаты на задачах интегрирования?',\n",
    "             'Какие техники использовались для увеличения разнообразия генерируемых вариантов задач?',\n",
    "             'Как LADDER масштабирует обучение без увеличения размера модели?',\n",
    "             'Какие ограничения или сложности были замечены при генерации вариантов задач?'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9969290c-5faa-42f1-86d4-abf5e6f77d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_url = \"https://arxiv.org/pdf/2503.00735\"\n",
    "arxiv_id = extract_arxiv_id(arxiv_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "545aa75e-67aa-44f9-8ed2-ff8991856ada",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 1/10 [00:09<01:25,  9.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: В чём заключается ключевая идея фреймворка LADDER?\n",
      "\n",
      "Ответ на вопрос: Ключевая идея фреймворка LADDER заключается в автономном улучшении способности моделей решать задачи через рекурсивное разложение сложных задач на более простые варианты и обучение на их решениях.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 2/10 [00:16<01:05,  8.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какой метод используется для верификации правильности решений интегралов в LADDER?\n",
      "\n",
      "Ответ на вопрос: Метод численной интеграции используется для верификации правильности решений интегралов в LADDER.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 3/10 [00:26<01:01,  8.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Как осуществляется генерация вариантов задач в LADDER?\n",
      "\n",
      "Ответ на вопрос: Варианты задач в LADDER генерируются с использованием трёхэтапного метода, описанного в разделе 3.1.2, где для каждого интеграла из обучающего набора создаётся дерево вариантов.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:43<01:13, 12.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Что такое TTRL и чем он отличается от LADDER?\n",
      "\n",
      "Ответ на вопрос: TTRL — это метод тестового времени, который использует рекурсивное разложение задач для улучшения способности модели решать сложные задачи. LADDER — это структурированный фреймворк, основанный на рекурсивном разложении задач и усилении обучения, включающий генерацию вариантов, проверку решений и обучение с усилением. TTRL улучшает LADDER, применяя разложение задач непосредственно на тестовых вопросах, что позволяет модели решать более сложные задачи.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [00:53<00:56, 11.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие результаты достигнуты моделью Qwen2.5 7B на экзамене MIT Integration Bee после применения LADDER и TTRL?\n",
      "\n",
      "Ответ на вопрос: Модель Qwen2.5 7B достигла результата 90% на экзамене MIT Integration Bee после применения LADDER и TTRL.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [01:01<00:41, 10.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какая функция вознаграждения используется в GRPO в рамках обучения в LADDER?\n",
      "\n",
      "Ответ на вопрос: Функция вознаграждения, используемая в GRPO в рамках обучения в LADDER, — это функция, основанная на оценке верификации решений, которая проверяет правильность ответов модели.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [01:12<00:31, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Почему RL без использования вариантов задач показывает плохие результаты на задачах интегрирования?\n",
      "\n",
      "Ответ на вопрос: Потому что RL без использования вариантов задач не способен эффективно обучаться сложным математическим навыкам, таким как интегрирование, из-за отсутствия структурированного градиента сложности, что приводит к плохим результатам.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [01:22<00:20, 10.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие техники использовались для увеличения разнообразия генерируемых вариантов задач?\n",
      "\n",
      "Ответ на вопрос: Использовались следующие техники: случайное выборка преобразований, циклическое изменение температуры при генерации и персонализированные промпты с разными математическими перспективами.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [01:32<00:10, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Как LADDER масштабирует обучение без увеличения размера модели?\n",
      "\n",
      "Ответ на вопрос: LADDER масштабирует обучение, позволяя моделям динамически разбивать сложные задачи на более простые и обучаться на них во время инференса, что позволяет значительно улучшать производительность без увеличения размера модели или предобучения.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:42<00:00, 10.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Какие ограничения или сложности были замечены при генерации вариантов задач?\n",
      "\n",
      "Ответ на вопрос: При генерации вариантов задач наблюдались сложности с контролем уровня сложности, так как небольшие изменения в коэффициентах или функциональной составляющей могли значительно увеличивать сложность интегралов.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "times = []\n",
    "\n",
    "for question in tqdm(questions):\n",
    "    reranked = retrieve_and_rerank(question, vectorstore, reranker, arxiv_id, top_k=10, top_n=2)\n",
    "    top_chunks = [doc.page_content for doc, score in reranked]\n",
    "    context = \"\\n\\n\".join(top_chunks)\n",
    "\n",
    "    messages = build_messages(question, context)\n",
    "    messages = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True, enable_thinking=False)\n",
    "    start = time.time()\n",
    "\n",
    "    answer = llm(messages, max_new_tokens=256, do_sample=False, top_p=None, temperature=None, top_k=None)[0]['generated_text']\n",
    "\n",
    "    end = time.time()\n",
    "    inf_time = end - start\n",
    "    \n",
    "    times.append(inf_time)\n",
    "    print(f'Вопрос: {question}\\n')\n",
    "    print(f'Ответ на вопрос: {answer}\\n\\n')\n",
    "    outputs.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "02d6c21e-ad3a-4677-93f6-cf8e04c1720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_5 = times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "94b7c39d-1510-42b6-9bfe-a4171ed8c151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(8.391678547859192)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(times_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "970d1b8e-a102-463e-8474-5b8d950f37f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test_results/article_5_questions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "704a9ecc-c4f5-41f6-aa4b-eb9d966736b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Qwen3'] = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9336934d-e0bc-4099-97bb-1fe0dbfaa555",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_results/article_5_questions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6a089cf7-27cf-4176-9749-eb2cb7a6afa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее время генерации ответа Qwen3: 7.7 сек\n"
     ]
    }
   ],
   "source": [
    "print(f'Среднее время генерации ответа Qwen3: {np.mean(times_1 + times_2 + times_3 + times_4 + times_5):.1f} сек')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f7446f-dc57-4066-b550-b6aa478aff64",
   "metadata": {},
   "source": [
    "# Среднее время генерации ответов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ad9b55d-c1b0-48c5-bf5f-6af1188343cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее время генерации ответов Tbank: 8.5 сек\n",
      "Среднее время генерации ответов Yandex: 4.2 сек\n",
      "Среднее время генерации ответов Qwen3: 7.7 сек\n"
     ]
    }
   ],
   "source": [
    "print(f'Среднее время генерации ответов Tbank: 8.5 сек')\n",
    "print(f'Среднее время генерации ответов Yandex: 4.2 сек')\n",
    "print(f'Среднее время генерации ответов Qwen3: 7.7 сек')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c659a2c5-e53e-44fe-94b8-ba91c914a06d",
   "metadata": {},
   "source": [
    "## Собираем все ответы в один датафрейм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "be5a1860-34f0-4fe9-9365-16516ea96a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('test_results/article_1_questions.csv')\n",
    "df2 = pd.read_csv('test_results/article_2_questions.csv')\n",
    "df3 = pd.read_csv('test_results/article_3_questions.csv')\n",
    "df4 = pd.read_csv('test_results/article_4_questions.csv')\n",
    "df5 = pd.read_csv('test_results/article_5_questions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c1e7187b-6579-4e11-a8e8-fcd2500a3505",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2, df3, df4, df5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3c5f4153-810a-4ced-aec2-a63f87676b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_results/article_questions_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80037f9b-2267-4cb6-814e-9f525145aa83",
   "metadata": {},
   "source": [
    "## LLM as a judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca1825bf-9cb9-4ece-af5e-1f071de2d23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('article_questions_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7e57610-f965-464f-8098-325e18c9a753",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>gt</th>\n",
       "      <th>Tbank</th>\n",
       "      <th>YandexGPT</th>\n",
       "      <th>Qwen3</th>\n",
       "      <th>gen_tbank_rank</th>\n",
       "      <th>gen_yandex_rank</th>\n",
       "      <th>gen_qwen_rank</th>\n",
       "      <th>sim_scores_tbank</th>\n",
       "      <th>sim_scores_yandex</th>\n",
       "      <th>sim_scores_qwen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Какой оптимайзер и гиперпараметры использовали...</td>\n",
       "      <td>В оригинальной статье использовался Adam с пар...</td>\n",
       "      <td>В данном контексте использовался оптимайзер Ad...</td>\n",
       "      <td>Мы использовали оптимизатор Adam с параметрам...</td>\n",
       "      <td>Оптимайзер — Adam, гиперпараметры: β₁ = 0.9, β...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.669123</td>\n",
       "      <td>0.570089</td>\n",
       "      <td>0.500410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Какие архитектурные компоненты заменяет Transf...</td>\n",
       "      <td>Transformer заменяет RNN или LSTM/GRU, использ...</td>\n",
       "      <td>В традиционных sequence-to-sequence моделях, т...</td>\n",
       "      <td>Transformer заменяет рекуррентные слои, наибо...</td>\n",
       "      <td>Рекуррентные слои.</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.695416</td>\n",
       "      <td>0.769922</td>\n",
       "      <td>0.370163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Что такое Scaled Dot-Product Attention и зачем...</td>\n",
       "      <td>Это механизм внимания, который вычисляет:\\nAtt...</td>\n",
       "      <td>Деление на √dk в Scaled Dot-Product Attention ...</td>\n",
       "      <td>Scaled Dot-Product Attention — это метод вним...</td>\n",
       "      <td>Scaled Dot-Product Attention — это механизм вн...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.503097</td>\n",
       "      <td>0.558233</td>\n",
       "      <td>0.644848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Как устроена структура encoder и decoder в Tra...</td>\n",
       "      <td>Encoder: N одинаковых блоков (обычно N=6), каж...</td>\n",
       "      <td>Структура Transformer состоит из двух основных...</td>\n",
       "      <td>Структура encoder и decoder в Transformer сос...</td>\n",
       "      <td>Encoder состоит из стека из 6 идентичных слоев...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.355634</td>\n",
       "      <td>0.415566</td>\n",
       "      <td>0.558227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Почему Multi-Head Attention улучшает производи...</td>\n",
       "      <td>Потому что каждая \"голова\" обучается фокусиров...</td>\n",
       "      <td>Multi-Head Attention улучшает производительнос...</td>\n",
       "      <td>Multi-head attention позволяет модели совмест...</td>\n",
       "      <td>Multi-Head Attention улучшает производительнос...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.405849</td>\n",
       "      <td>0.377725</td>\n",
       "      <td>0.400534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Какие функции выполняют позиционные кодировки ...</td>\n",
       "      <td>Позиционные кодировки добавляют информацию о п...</td>\n",
       "      <td>Позиционные кодировки (PE) в нейронных сетях, ...</td>\n",
       "      <td>Позиционные кодировки выполняют функцию предс...</td>\n",
       "      <td>Позиционные кодировки позволяют модели учитыва...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.602244</td>\n",
       "      <td>0.709361</td>\n",
       "      <td>0.736253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>В чем преимущества self-attention по сравнению...</td>\n",
       "      <td>Self-attention: O(n²) по длине последовательно...</td>\n",
       "      <td>Преимущества self-attention перед рекуррентным...</td>\n",
       "      <td>В плане вычислительной сложности слой self-at...</td>\n",
       "      <td>Self-attention имеет постоянное число операций...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.619954</td>\n",
       "      <td>0.577273</td>\n",
       "      <td>0.644929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Какие техники регуляризации использовались при...</td>\n",
       "      <td>Dropout (в attention, feed-forward, embeddings...</td>\n",
       "      <td>Для обучения Transformer использовались следую...</td>\n",
       "      <td>При обучении Transformer использовались три т...</td>\n",
       "      <td>В обучении Transformer использовались три типа...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.342940</td>\n",
       "      <td>0.224844</td>\n",
       "      <td>0.229979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Какие результаты Transformer показал на задача...</td>\n",
       "      <td>EN→DE: BLEU 28.4 (vs. предыдущие ~26.4)\\nEN→FR...</td>\n",
       "      <td>На задачах перевода с английского на французск...</td>\n",
       "      <td>На задаче перевода EN→FR по WMT 2014 модель T...</td>\n",
       "      <td>Transformer показал BLEU-счет 41.8 на задаче E...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.672282</td>\n",
       "      <td>0.662603</td>\n",
       "      <td>0.662860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Почему Transformer позволяет более эффективную...</td>\n",
       "      <td>Потому что self-attention не требует последова...</td>\n",
       "      <td>Параллелизация в Transformer возможна из-за от...</td>\n",
       "      <td>Transformer позволяет значительно больше пара...</td>\n",
       "      <td>Потому что Transformer использует механизм вни...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.395121</td>\n",
       "      <td>0.322822</td>\n",
       "      <td>0.407397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>В чем заключается основная идея метода Test-Ti...</td>\n",
       "      <td>TTRL — это метод обучения с подкреплением без ...</td>\n",
       "      <td>Основная идея метода Test-Time Reinforcement L...</td>\n",
       "      <td>Основная идея метода Test-Time Reinforcement ...</td>\n",
       "      <td>Основная идея метода Test-Time Reinforcement L...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.817064</td>\n",
       "      <td>0.753922</td>\n",
       "      <td>0.767716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Каким бразом осуществляется оценка вознагражде...</td>\n",
       "      <td>Модель многократно генерирует ответы на один и...</td>\n",
       "      <td>Оценка вознаграждения в TTRL (Test-Time Reinfo...</td>\n",
       "      <td>Оценка вознаграждения в TTRL без доступа к ис...</td>\n",
       "      <td>Оценка вознаграждения в TTRL осуществляется с ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.320177</td>\n",
       "      <td>0.344438</td>\n",
       "      <td>0.360994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Какую роль играет метод большинства голосов (m...</td>\n",
       "      <td>Majority voting используется для оценки метки ...</td>\n",
       "      <td>Метод большинства голосов в архитектуре TTRL и...</td>\n",
       "      <td>Метод большинства голосов (majority voting) в...</td>\n",
       "      <td>Метод большинства голосов (majority voting) в ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.466848</td>\n",
       "      <td>0.449711</td>\n",
       "      <td>0.518320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Какие улучшения производительности были достиг...</td>\n",
       "      <td>На AIME 2024 модель Qwen2.5-Math-7B улучшилась...</td>\n",
       "      <td>На бенчмарке AIME 2024 применение TTRL (техник...</td>\n",
       "      <td>Применение TTRL к Qwen2.5-Math-7B привело к у...</td>\n",
       "      <td>Улучшения производительности с помощью TTRL на...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.513037</td>\n",
       "      <td>0.678006</td>\n",
       "      <td>0.539866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Как TTRL сравнивается с RL на размеченных тест...</td>\n",
       "      <td>TTRL почти достигает производительности RL с д...</td>\n",
       "      <td>На размеченных тестовых данных, **TTRL** (Tran...</td>\n",
       "      <td>По результатам оценки на размеченных тестовых...</td>\n",
       "      <td>TTRL показывает эффективность, сравнимую с RL ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.527506</td>\n",
       "      <td>0.617846</td>\n",
       "      <td>0.555313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Почему TTRL способен работать даже при неточны...</td>\n",
       "      <td>Потому что:\\nRL устойчив к шуму в наградах.\\nД...</td>\n",
       "      <td>TTRL (Temporal Reward-Driven Learning) остаётс...</td>\n",
       "      <td>TTRL остаётся эффективным даже при неточных о...</td>\n",
       "      <td>Потому что награды более плотные, чем метки, ч...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558490</td>\n",
       "      <td>0.654931</td>\n",
       "      <td>0.525280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Какие модели и бенчмарки использовались для оц...</td>\n",
       "      <td>Модели: Qwen2.5-Math-1.5B, Qwen2.5-Math-7B, LL...</td>\n",
       "      <td>Для оценки эффективности TTRL (Test-Time Reinf...</td>\n",
       "      <td>Для оценки эффективности TTRL использовались ...</td>\n",
       "      <td>Модели: Qwen2.5-Math-7B, DeepSeek-R1. Бенчмарк...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.636273</td>\n",
       "      <td>0.663828</td>\n",
       "      <td>0.845781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Какие факторы могут привести к сбою или неэффе...</td>\n",
       "      <td>Недостаток предварительных знаний у модели (на...</td>\n",
       "      <td>Основные причины неэффективности или сбоя в TT...</td>\n",
       "      <td>Фактором, который может привести к сбою или н...</td>\n",
       "      <td>Недостаток предварительных знаний о целевой за...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531387</td>\n",
       "      <td>0.446694</td>\n",
       "      <td>0.452113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Как TTRL масштабируется при увеличении размера...</td>\n",
       "      <td>TTRL масштабируется положительно — более крупн...</td>\n",
       "      <td>TTRL (Test-Time Reinforcement Learning) демонс...</td>\n",
       "      <td>TTRL естественно масштабируется: с увеличение...</td>\n",
       "      <td>TTRL естественно масштабируется с увеличением ...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.725395</td>\n",
       "      <td>0.752094</td>\n",
       "      <td>0.725277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>С какими алгоритмами обучения с подкреплением ...</td>\n",
       "      <td>Совместим с PPO и GRPO. В экспериментах исполь...</td>\n",
       "      <td>Техника TTRL (Temporal Training with Reinforce...</td>\n",
       "      <td>TTRL совместим с разными алгоритмами обучения...</td>\n",
       "      <td>TTRL совместим с алгоритмами PPO и GRPO, и в э...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.555093</td>\n",
       "      <td>0.563449</td>\n",
       "      <td>0.651296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Какая модель используется в качестве генератор...</td>\n",
       "      <td>BART-large (400M параметров) используется как ...</td>\n",
       "      <td>В RAG (Retrieval-Augmented Generation) использ...</td>\n",
       "      <td>В RAG используется генератор $p_{\\theta} (y_i...</td>\n",
       "      <td>RAG-Sequence модель.</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.188245</td>\n",
       "      <td>0.261742</td>\n",
       "      <td>0.079123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Какая модель используется в качестве ретривера...</td>\n",
       "      <td>DPR (Dense Passage Retriever) — bi-encoder на ...</td>\n",
       "      <td>В качестве ретривера в RAG используется модель...</td>\n",
       "      <td>В RAG в качестве ретривера используется ретри...</td>\n",
       "      <td>В RAG в качестве ретривера используется Dense ...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.515640</td>\n",
       "      <td>0.382114</td>\n",
       "      <td>0.499232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Чем отличаются архитектуры RAG-Token и RAG-Seq...</td>\n",
       "      <td>RAG-Sequence использует один и тот же документ...</td>\n",
       "      <td>**RAG-Token** использует автокодирование, где ...</td>\n",
       "      <td>RAG-Token можно рассматривать как стандартный...</td>\n",
       "      <td>Архитектура RAG-Token использует токенизацию д...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.609349</td>\n",
       "      <td>0.604506</td>\n",
       "      <td>0.739484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Какой объем документов используется в векторно...</td>\n",
       "      <td>21 миллион документов, каждая статья разбита н...</td>\n",
       "      <td>В векторном индексе Wikipedia используется 21 ...</td>\n",
       "      <td>21 млн документов.</td>\n",
       "      <td>Объем документов в векторном индексе Wikipedia...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.675305</td>\n",
       "      <td>0.617678</td>\n",
       "      <td>0.616513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Какие задачи были использованы для оценки RAG-...</td>\n",
       "      <td>Open-domain QA: Natural Questions, TriviaQA, W...</td>\n",
       "      <td>Для оценки RAG-моделей использовались задачи, ...</td>\n",
       "      <td>Модели оценивались на широком спектре задач, ...</td>\n",
       "      <td>Для оценки RAG-моделей использовались задачи, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.355814</td>\n",
       "      <td>0.326911</td>\n",
       "      <td>0.429089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Почему авторы считают генерацию предпочтительн...</td>\n",
       "      <td>Потому что:\\nМожно обобщать и генерировать отв...</td>\n",
       "      <td>Авторы считают генерацию предпочтительной, пот...</td>\n",
       "      <td>Авторы считают генерацию предпочтительной по ...</td>\n",
       "      <td>Авторы считают генерацию предпочтительной по с...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.639885</td>\n",
       "      <td>0.553435</td>\n",
       "      <td>0.556720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Какую производительность показал RAG на задаче...</td>\n",
       "      <td>RAG-Token превзошёл BART по метрике Q-BLEU-1 (...</td>\n",
       "      <td>RAG (Reinforced Attention Generative Adversari...</td>\n",
       "      <td>RAG-Token показал лучшие результаты, чем RAG-...</td>\n",
       "      <td>RAG показал лучшую производительность, чем BAR...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.625540</td>\n",
       "      <td>0.829998</td>\n",
       "      <td>0.612993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Как осуществляется совместное обучение генерат...</td>\n",
       "      <td>Модель обучается end-to-end, минимизируя отриц...</td>\n",
       "      <td>В RAG (Retrieval-Augmented Generation) обучени...</td>\n",
       "      <td>Оба генератора и ретривера в RAG обучаются со...</td>\n",
       "      <td>Совместное обучение генератора и ретривера в R...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.346530</td>\n",
       "      <td>0.325784</td>\n",
       "      <td>0.460076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Какой эффект даёт \"hot-swapping\" индекса докум...</td>\n",
       "      <td>Можно обновлять знания модели без переобучения...</td>\n",
       "      <td>\"Hot-swapping\" индекса в RAG (Retrieval-Augmen...</td>\n",
       "      <td>«Hot-swapping» индекса документов в RAG позво...</td>\n",
       "      <td>\"Hot-swapping\" индекса документов в RAG позвол...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.308062</td>\n",
       "      <td>0.381191</td>\n",
       "      <td>0.383768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Какие аппроксимации используются при декодиров...</td>\n",
       "      <td>RAG-Token: стандартный beam search с суммой по...</td>\n",
       "      <td>Для декодирования в RAG-Sequence и RAG-Token и...</td>\n",
       "      <td>При декодировании в RAG-Sequence и RAG-Token ...</td>\n",
       "      <td>В RAG-Sequence используется аппроксимация top-...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.569197</td>\n",
       "      <td>0.570432</td>\n",
       "      <td>0.620428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Какие две модели архитектур были предложены ав...</td>\n",
       "      <td>CBOW (Continuous Bag-of-Words)\\nSkip-gram\\nОбе...</td>\n",
       "      <td>Авторы предложили две модели для обучения вект...</td>\n",
       "      <td>Авторы предложили две модели архитектур: \\n1....</td>\n",
       "      <td>Две модели архитектур, предложенные авторами, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.307397</td>\n",
       "      <td>0.297944</td>\n",
       "      <td>0.291936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>В чём основное различие между архитектурами CB...</td>\n",
       "      <td>CBOW предсказывает текущие слово по контексту ...</td>\n",
       "      <td>Основное различие между архитектурами CBOW (Co...</td>\n",
       "      <td>CBOW предсказывает текущее слово на основе ко...</td>\n",
       "      <td>Основное различие между архитектурами CBOW и S...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.728077</td>\n",
       "      <td>0.870906</td>\n",
       "      <td>0.725184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Какие типы отношений включены в Semantic-Synta...</td>\n",
       "      <td>Семантические (5 типов): столицы, валюты, отно...</td>\n",
       "      <td>В Semantic-Syntactic Word Relationship test se...</td>\n",
       "      <td>В Semantic-Syntactic Word Relationship test s...</td>\n",
       "      <td>В Semantic-Syntactic Word Relationship test se...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.557402</td>\n",
       "      <td>0.551080</td>\n",
       "      <td>0.622326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Какие значения точности показала модель Skip-g...</td>\n",
       "      <td>Для Skip-gram с размерностью 300 и обучением н...</td>\n",
       "      <td>Модель Skip-gram показала точность 24% на сема...</td>\n",
       "      <td>Модель Skip-gram показала точность 55% на сем...</td>\n",
       "      <td>Модель Skip-gram показала точность 50.0% на се...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.704451</td>\n",
       "      <td>0.686502</td>\n",
       "      <td>0.709938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Какой подход используется в Skip-gram модели д...</td>\n",
       "      <td>Слово предсказывает контекст в окне размера C....</td>\n",
       "      <td>В модели Skip-gram для выбора контекстных слов...</td>\n",
       "      <td>В Skip-gram модели используется подход, при к...</td>\n",
       "      <td>Сэмплирование с весами, где более близкие слов...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.497566</td>\n",
       "      <td>0.333870</td>\n",
       "      <td>0.301729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Какова формула вычислительной сложности модели...</td>\n",
       "      <td>Q=N⋅D+D⋅log 2​(V)\\nГде:\\nN — количество слов в...</td>\n",
       "      <td>Формула вычислительной сложности для модели CB...</td>\n",
       "      <td>$Q = C × (D + D × log_2(V))$</td>\n",
       "      <td>Формула вычислительной сложности модели CBOW: ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.590970</td>\n",
       "      <td>0.631210</td>\n",
       "      <td>0.539666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Почему авторы отказались от использования скры...</td>\n",
       "      <td>Потому что основная вычислительная нагрузка пр...</td>\n",
       "      <td>Авторы отказались от использования скрытого сл...</td>\n",
       "      <td>Авторы отказались от использования скрытого с...</td>\n",
       "      <td>Авторы отказались от использования скрытого сл...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.551878</td>\n",
       "      <td>0.591255</td>\n",
       "      <td>0.668123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Как масштабировалась тренировка моделей в расп...</td>\n",
       "      <td>Использовалась асинхронная mini-batch SGD + Ad...</td>\n",
       "      <td>Масштабирование тренировки моделей в системе D...</td>\n",
       "      <td>В системе DistBelief тренировка моделей масшт...</td>\n",
       "      <td>Модели масштабировались с использованием 50 до...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.492811</td>\n",
       "      <td>0.333205</td>\n",
       "      <td>0.441351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Как были сгенерированы вопросы в тестовом набо...</td>\n",
       "      <td>Сначала вручную созданы списки пар слов.\\nЗате...</td>\n",
       "      <td>Вопросы для тестирования word vectors были сге...</td>\n",
       "      <td>Вопросы в тестовом наборе для оценки word vec...</td>\n",
       "      <td>Вопросы в тестовом наборе были сгенерированы в...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.579154</td>\n",
       "      <td>0.513489</td>\n",
       "      <td>0.621097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Какой метод используется для ответа на аналоги...</td>\n",
       "      <td>Применяется векторная арифметика:\\nvec(\"king\")...</td>\n",
       "      <td>Для решения аналогий, таких как \"king - man + ...</td>\n",
       "      <td>Метод word offset, где выполняются простые ал...</td>\n",
       "      <td>Метод, используемый для ответа на аналогии вро...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.628457</td>\n",
       "      <td>0.303511</td>\n",
       "      <td>0.465351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>В чём заключается ключевая идея фреймворка LAD...</td>\n",
       "      <td>Модель самостоятельно улучшает свои способност...</td>\n",
       "      <td>Ключевая идея фреймворка LADDER заключается в ...</td>\n",
       "      <td>Ключевая идея фреймворка LADDER заключается в...</td>\n",
       "      <td>Ключевая идея фреймворка LADDER заключается в ...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.372673</td>\n",
       "      <td>0.421113</td>\n",
       "      <td>0.362873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Какой метод используется для верификации прави...</td>\n",
       "      <td>Применяется численная верификация: сравнение о...</td>\n",
       "      <td>Для верификации решений интегралов в LADDER ис...</td>\n",
       "      <td>Для верификации правильности решений интеграл...</td>\n",
       "      <td>Метод численной интеграции используется для ве...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.558852</td>\n",
       "      <td>0.491127</td>\n",
       "      <td>0.533643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Как осуществляется генерация вариантов задач в...</td>\n",
       "      <td>Варианты создаются по дереву:\\nПрименяются 3–5...</td>\n",
       "      <td>В LADDER генерация вариантов задач происходит ...</td>\n",
       "      <td>Генерация вариантов задач в LADDER осуществля...</td>\n",
       "      <td>Варианты задач в LADDER генерируются с использ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.459679</td>\n",
       "      <td>0.483903</td>\n",
       "      <td>0.510993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Что такое TTRL и чем он отличается от LADDER?</td>\n",
       "      <td>TTRL (Test-Time RL) — это тестовое применение ...</td>\n",
       "      <td>TTRL (Test-Time Recursive Learning) — это мето...</td>\n",
       "      <td>TTRL — это более эффективный метод масштабиро...</td>\n",
       "      <td>TTRL — это метод тестового времени, который ис...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.836282</td>\n",
       "      <td>0.771014</td>\n",
       "      <td>0.782000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Какие результаты достигнуты моделью Qwen2.5 7B...</td>\n",
       "      <td>LADDER: 73% (вышел на уровень квалификации)\\nL...</td>\n",
       "      <td>На экзамене MIT Integration Bee модель Qwen2.5...</td>\n",
       "      <td>После применения LADDER и TTRL модель Qwen2.5...</td>\n",
       "      <td>Модель Qwen2.5 7B достигла результата 90% на э...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.531311</td>\n",
       "      <td>0.572808</td>\n",
       "      <td>0.539494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Какая функция вознаграждения используется в GR...</td>\n",
       "      <td>GRPO использует два компонента:\\nAccuracy rewa...</td>\n",
       "      <td>В рамках LADDER используется функция вознаграж...</td>\n",
       "      <td>В GRPO в рамках обучения в LADDER используетс...</td>\n",
       "      <td>Функция вознаграждения, используемая в GRPO в ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.524843</td>\n",
       "      <td>0.485310</td>\n",
       "      <td>0.511644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Почему RL без использования вариантов задач по...</td>\n",
       "      <td>Без градиента сложности RL быстро проваливаетс...</td>\n",
       "      <td>Использование RL без специальных методов и под...</td>\n",
       "      <td>Успех RL с вариантами задач обусловлен тщател...</td>\n",
       "      <td>Потому что RL без использования вариантов зада...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.514872</td>\n",
       "      <td>0.545307</td>\n",
       "      <td>0.594181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Какие техники использовались для увеличения ра...</td>\n",
       "      <td>Batch prompting (по 10 за раз)\\nTemperature cy...</td>\n",
       "      <td>Для увеличения разнообразия генерируемых задач...</td>\n",
       "      <td>Для увеличения разнообразия генерируемых вари...</td>\n",
       "      <td>Использовались следующие техники: случайное вы...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.553947</td>\n",
       "      <td>0.558200</td>\n",
       "      <td>0.411620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Как LADDER масштабирует обучение без увеличени...</td>\n",
       "      <td>Путём генерации тысяч вариантов и обучения на ...</td>\n",
       "      <td>LADDER масштабирует обучение, используя методы...</td>\n",
       "      <td>LADDER масштабирует обучение без увеличения р...</td>\n",
       "      <td>LADDER масштабирует обучение, позволяя моделям...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.378422</td>\n",
       "      <td>0.352350</td>\n",
       "      <td>0.383792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Какие ограничения или сложности были замечены ...</td>\n",
       "      <td>Примерно 8% вариантов оказались нерешаемыми\\nН...</td>\n",
       "      <td>Основные сложности при генерации задач связаны...</td>\n",
       "      <td>При генерации вариантов задач были замечены с...</td>\n",
       "      <td>При генерации вариантов задач наблюдались слож...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.471513</td>\n",
       "      <td>0.548490</td>\n",
       "      <td>0.566462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Questions  \\\n",
       "0   Какой оптимайзер и гиперпараметры использовали...   \n",
       "1   Какие архитектурные компоненты заменяет Transf...   \n",
       "2   Что такое Scaled Dot-Product Attention и зачем...   \n",
       "3   Как устроена структура encoder и decoder в Tra...   \n",
       "4   Почему Multi-Head Attention улучшает производи...   \n",
       "5   Какие функции выполняют позиционные кодировки ...   \n",
       "6   В чем преимущества self-attention по сравнению...   \n",
       "7   Какие техники регуляризации использовались при...   \n",
       "8   Какие результаты Transformer показал на задача...   \n",
       "9   Почему Transformer позволяет более эффективную...   \n",
       "10  В чем заключается основная идея метода Test-Ti...   \n",
       "11  Каким бразом осуществляется оценка вознагражде...   \n",
       "12  Какую роль играет метод большинства голосов (m...   \n",
       "13  Какие улучшения производительности были достиг...   \n",
       "14  Как TTRL сравнивается с RL на размеченных тест...   \n",
       "15  Почему TTRL способен работать даже при неточны...   \n",
       "16  Какие модели и бенчмарки использовались для оц...   \n",
       "17  Какие факторы могут привести к сбою или неэффе...   \n",
       "18  Как TTRL масштабируется при увеличении размера...   \n",
       "19  С какими алгоритмами обучения с подкреплением ...   \n",
       "20  Какая модель используется в качестве генератор...   \n",
       "21  Какая модель используется в качестве ретривера...   \n",
       "22  Чем отличаются архитектуры RAG-Token и RAG-Seq...   \n",
       "23  Какой объем документов используется в векторно...   \n",
       "24  Какие задачи были использованы для оценки RAG-...   \n",
       "25  Почему авторы считают генерацию предпочтительн...   \n",
       "26  Какую производительность показал RAG на задаче...   \n",
       "27  Как осуществляется совместное обучение генерат...   \n",
       "28  Какой эффект даёт \"hot-swapping\" индекса докум...   \n",
       "29  Какие аппроксимации используются при декодиров...   \n",
       "30  Какие две модели архитектур были предложены ав...   \n",
       "31  В чём основное различие между архитектурами CB...   \n",
       "32  Какие типы отношений включены в Semantic-Synta...   \n",
       "33  Какие значения точности показала модель Skip-g...   \n",
       "34  Какой подход используется в Skip-gram модели д...   \n",
       "35  Какова формула вычислительной сложности модели...   \n",
       "36  Почему авторы отказались от использования скры...   \n",
       "37  Как масштабировалась тренировка моделей в расп...   \n",
       "38  Как были сгенерированы вопросы в тестовом набо...   \n",
       "39  Какой метод используется для ответа на аналоги...   \n",
       "40  В чём заключается ключевая идея фреймворка LAD...   \n",
       "41  Какой метод используется для верификации прави...   \n",
       "42  Как осуществляется генерация вариантов задач в...   \n",
       "43      Что такое TTRL и чем он отличается от LADDER?   \n",
       "44  Какие результаты достигнуты моделью Qwen2.5 7B...   \n",
       "45  Какая функция вознаграждения используется в GR...   \n",
       "46  Почему RL без использования вариантов задач по...   \n",
       "47  Какие техники использовались для увеличения ра...   \n",
       "48  Как LADDER масштабирует обучение без увеличени...   \n",
       "49  Какие ограничения или сложности были замечены ...   \n",
       "\n",
       "                                                   gt  \\\n",
       "0   В оригинальной статье использовался Adam с пар...   \n",
       "1   Transformer заменяет RNN или LSTM/GRU, использ...   \n",
       "2   Это механизм внимания, который вычисляет:\\nAtt...   \n",
       "3   Encoder: N одинаковых блоков (обычно N=6), каж...   \n",
       "4   Потому что каждая \"голова\" обучается фокусиров...   \n",
       "5   Позиционные кодировки добавляют информацию о п...   \n",
       "6   Self-attention: O(n²) по длине последовательно...   \n",
       "7   Dropout (в attention, feed-forward, embeddings...   \n",
       "8   EN→DE: BLEU 28.4 (vs. предыдущие ~26.4)\\nEN→FR...   \n",
       "9   Потому что self-attention не требует последова...   \n",
       "10  TTRL — это метод обучения с подкреплением без ...   \n",
       "11  Модель многократно генерирует ответы на один и...   \n",
       "12  Majority voting используется для оценки метки ...   \n",
       "13  На AIME 2024 модель Qwen2.5-Math-7B улучшилась...   \n",
       "14  TTRL почти достигает производительности RL с д...   \n",
       "15  Потому что:\\nRL устойчив к шуму в наградах.\\nД...   \n",
       "16  Модели: Qwen2.5-Math-1.5B, Qwen2.5-Math-7B, LL...   \n",
       "17  Недостаток предварительных знаний у модели (на...   \n",
       "18  TTRL масштабируется положительно — более крупн...   \n",
       "19  Совместим с PPO и GRPO. В экспериментах исполь...   \n",
       "20  BART-large (400M параметров) используется как ...   \n",
       "21  DPR (Dense Passage Retriever) — bi-encoder на ...   \n",
       "22  RAG-Sequence использует один и тот же документ...   \n",
       "23  21 миллион документов, каждая статья разбита н...   \n",
       "24  Open-domain QA: Natural Questions, TriviaQA, W...   \n",
       "25  Потому что:\\nМожно обобщать и генерировать отв...   \n",
       "26  RAG-Token превзошёл BART по метрике Q-BLEU-1 (...   \n",
       "27  Модель обучается end-to-end, минимизируя отриц...   \n",
       "28  Можно обновлять знания модели без переобучения...   \n",
       "29  RAG-Token: стандартный beam search с суммой по...   \n",
       "30  CBOW (Continuous Bag-of-Words)\\nSkip-gram\\nОбе...   \n",
       "31  CBOW предсказывает текущие слово по контексту ...   \n",
       "32  Семантические (5 типов): столицы, валюты, отно...   \n",
       "33  Для Skip-gram с размерностью 300 и обучением н...   \n",
       "34  Слово предсказывает контекст в окне размера C....   \n",
       "35  Q=N⋅D+D⋅log 2​(V)\\nГде:\\nN — количество слов в...   \n",
       "36  Потому что основная вычислительная нагрузка пр...   \n",
       "37  Использовалась асинхронная mini-batch SGD + Ad...   \n",
       "38  Сначала вручную созданы списки пар слов.\\nЗате...   \n",
       "39  Применяется векторная арифметика:\\nvec(\"king\")...   \n",
       "40  Модель самостоятельно улучшает свои способност...   \n",
       "41  Применяется численная верификация: сравнение о...   \n",
       "42  Варианты создаются по дереву:\\nПрименяются 3–5...   \n",
       "43  TTRL (Test-Time RL) — это тестовое применение ...   \n",
       "44  LADDER: 73% (вышел на уровень квалификации)\\nL...   \n",
       "45  GRPO использует два компонента:\\nAccuracy rewa...   \n",
       "46  Без градиента сложности RL быстро проваливаетс...   \n",
       "47  Batch prompting (по 10 за раз)\\nTemperature cy...   \n",
       "48  Путём генерации тысяч вариантов и обучения на ...   \n",
       "49  Примерно 8% вариантов оказались нерешаемыми\\nН...   \n",
       "\n",
       "                                                Tbank  \\\n",
       "0   В данном контексте использовался оптимайзер Ad...   \n",
       "1   В традиционных sequence-to-sequence моделях, т...   \n",
       "2   Деление на √dk в Scaled Dot-Product Attention ...   \n",
       "3   Структура Transformer состоит из двух основных...   \n",
       "4   Multi-Head Attention улучшает производительнос...   \n",
       "5   Позиционные кодировки (PE) в нейронных сетях, ...   \n",
       "6   Преимущества self-attention перед рекуррентным...   \n",
       "7   Для обучения Transformer использовались следую...   \n",
       "8   На задачах перевода с английского на французск...   \n",
       "9   Параллелизация в Transformer возможна из-за от...   \n",
       "10  Основная идея метода Test-Time Reinforcement L...   \n",
       "11  Оценка вознаграждения в TTRL (Test-Time Reinfo...   \n",
       "12  Метод большинства голосов в архитектуре TTRL и...   \n",
       "13  На бенчмарке AIME 2024 применение TTRL (техник...   \n",
       "14  На размеченных тестовых данных, **TTRL** (Tran...   \n",
       "15  TTRL (Temporal Reward-Driven Learning) остаётс...   \n",
       "16  Для оценки эффективности TTRL (Test-Time Reinf...   \n",
       "17  Основные причины неэффективности или сбоя в TT...   \n",
       "18  TTRL (Test-Time Reinforcement Learning) демонс...   \n",
       "19  Техника TTRL (Temporal Training with Reinforce...   \n",
       "20  В RAG (Retrieval-Augmented Generation) использ...   \n",
       "21  В качестве ретривера в RAG используется модель...   \n",
       "22  **RAG-Token** использует автокодирование, где ...   \n",
       "23  В векторном индексе Wikipedia используется 21 ...   \n",
       "24  Для оценки RAG-моделей использовались задачи, ...   \n",
       "25  Авторы считают генерацию предпочтительной, пот...   \n",
       "26  RAG (Reinforced Attention Generative Adversari...   \n",
       "27  В RAG (Retrieval-Augmented Generation) обучени...   \n",
       "28  \"Hot-swapping\" индекса в RAG (Retrieval-Augmen...   \n",
       "29  Для декодирования в RAG-Sequence и RAG-Token и...   \n",
       "30  Авторы предложили две модели для обучения вект...   \n",
       "31  Основное различие между архитектурами CBOW (Co...   \n",
       "32  В Semantic-Syntactic Word Relationship test se...   \n",
       "33  Модель Skip-gram показала точность 24% на сема...   \n",
       "34  В модели Skip-gram для выбора контекстных слов...   \n",
       "35  Формула вычислительной сложности для модели CB...   \n",
       "36  Авторы отказались от использования скрытого сл...   \n",
       "37  Масштабирование тренировки моделей в системе D...   \n",
       "38  Вопросы для тестирования word vectors были сге...   \n",
       "39  Для решения аналогий, таких как \"king - man + ...   \n",
       "40  Ключевая идея фреймворка LADDER заключается в ...   \n",
       "41  Для верификации решений интегралов в LADDER ис...   \n",
       "42  В LADDER генерация вариантов задач происходит ...   \n",
       "43  TTRL (Test-Time Recursive Learning) — это мето...   \n",
       "44  На экзамене MIT Integration Bee модель Qwen2.5...   \n",
       "45  В рамках LADDER используется функция вознаграж...   \n",
       "46  Использование RL без специальных методов и под...   \n",
       "47  Для увеличения разнообразия генерируемых задач...   \n",
       "48  LADDER масштабирует обучение, используя методы...   \n",
       "49  Основные сложности при генерации задач связаны...   \n",
       "\n",
       "                                            YandexGPT  \\\n",
       "0    Мы использовали оптимизатор Adam с параметрам...   \n",
       "1    Transformer заменяет рекуррентные слои, наибо...   \n",
       "2    Scaled Dot-Product Attention — это метод вним...   \n",
       "3    Структура encoder и decoder в Transformer сос...   \n",
       "4    Multi-head attention позволяет модели совмест...   \n",
       "5    Позиционные кодировки выполняют функцию предс...   \n",
       "6    В плане вычислительной сложности слой self-at...   \n",
       "7    При обучении Transformer использовались три т...   \n",
       "8    На задаче перевода EN→FR по WMT 2014 модель T...   \n",
       "9    Transformer позволяет значительно больше пара...   \n",
       "10   Основная идея метода Test-Time Reinforcement ...   \n",
       "11   Оценка вознаграждения в TTRL без доступа к ис...   \n",
       "12   Метод большинства голосов (majority voting) в...   \n",
       "13   Применение TTRL к Qwen2.5-Math-7B привело к у...   \n",
       "14   По результатам оценки на размеченных тестовых...   \n",
       "15   TTRL остаётся эффективным даже при неточных о...   \n",
       "16   Для оценки эффективности TTRL использовались ...   \n",
       "17   Фактором, который может привести к сбою или н...   \n",
       "18   TTRL естественно масштабируется: с увеличение...   \n",
       "19   TTRL совместим с разными алгоритмами обучения...   \n",
       "20   В RAG используется генератор $p_{\\theta} (y_i...   \n",
       "21   В RAG в качестве ретривера используется ретри...   \n",
       "22   RAG-Token можно рассматривать как стандартный...   \n",
       "23                                 21 млн документов.   \n",
       "24   Модели оценивались на широком спектре задач, ...   \n",
       "25   Авторы считают генерацию предпочтительной по ...   \n",
       "26   RAG-Token показал лучшие результаты, чем RAG-...   \n",
       "27   Оба генератора и ретривера в RAG обучаются со...   \n",
       "28   «Hot-swapping» индекса документов в RAG позво...   \n",
       "29   При декодировании в RAG-Sequence и RAG-Token ...   \n",
       "30   Авторы предложили две модели архитектур: \\n1....   \n",
       "31   CBOW предсказывает текущее слово на основе ко...   \n",
       "32   В Semantic-Syntactic Word Relationship test s...   \n",
       "33   Модель Skip-gram показала точность 55% на сем...   \n",
       "34   В Skip-gram модели используется подход, при к...   \n",
       "35                       $Q = C × (D + D × log_2(V))$   \n",
       "36   Авторы отказались от использования скрытого с...   \n",
       "37   В системе DistBelief тренировка моделей масшт...   \n",
       "38   Вопросы в тестовом наборе для оценки word vec...   \n",
       "39   Метод word offset, где выполняются простые ал...   \n",
       "40   Ключевая идея фреймворка LADDER заключается в...   \n",
       "41   Для верификации правильности решений интеграл...   \n",
       "42   Генерация вариантов задач в LADDER осуществля...   \n",
       "43   TTRL — это более эффективный метод масштабиро...   \n",
       "44   После применения LADDER и TTRL модель Qwen2.5...   \n",
       "45   В GRPO в рамках обучения в LADDER используетс...   \n",
       "46   Успех RL с вариантами задач обусловлен тщател...   \n",
       "47   Для увеличения разнообразия генерируемых вари...   \n",
       "48   LADDER масштабирует обучение без увеличения р...   \n",
       "49   При генерации вариантов задач были замечены с...   \n",
       "\n",
       "                                                Qwen3  gen_tbank_rank  \\\n",
       "0   Оптимайзер — Adam, гиперпараметры: β₁ = 0.9, β...               1   \n",
       "1                                  Рекуррентные слои.               1   \n",
       "2   Scaled Dot-Product Attention — это механизм вн...               3   \n",
       "3   Encoder состоит из стека из 6 идентичных слоев...               3   \n",
       "4   Multi-Head Attention улучшает производительнос...               2   \n",
       "5   Позиционные кодировки позволяют модели учитыва...               3   \n",
       "6   Self-attention имеет постоянное число операций...               2   \n",
       "7   В обучении Transformer использовались три типа...               1   \n",
       "8   Transformer показал BLEU-счет 41.8 на задаче E...               3   \n",
       "9   Потому что Transformer использует механизм вни...               1   \n",
       "10  Основная идея метода Test-Time Reinforcement L...               2   \n",
       "11  Оценка вознаграждения в TTRL осуществляется с ...               2   \n",
       "12  Метод большинства голосов (majority voting) в ...               1   \n",
       "13  Улучшения производительности с помощью TTRL на...               3   \n",
       "14  TTRL показывает эффективность, сравнимую с RL ...               2   \n",
       "15  Потому что награды более плотные, чем метки, ч...               3   \n",
       "16  Модели: Qwen2.5-Math-7B, DeepSeek-R1. Бенчмарк...               1   \n",
       "17  Недостаток предварительных знаний о целевой за...               2   \n",
       "18  TTRL естественно масштабируется с увеличением ...               3   \n",
       "19  TTRL совместим с алгоритмами PPO и GRPO, и в э...               1   \n",
       "20                               RAG-Sequence модель.               3   \n",
       "21  В RAG в качестве ретривера используется Dense ...               3   \n",
       "22  Архитектура RAG-Token использует токенизацию д...               1   \n",
       "23  Объем документов в векторном индексе Wikipedia...               1   \n",
       "24  Для оценки RAG-моделей использовались задачи, ...               2   \n",
       "25  Авторы считают генерацию предпочтительной по с...               3   \n",
       "26  RAG показал лучшую производительность, чем BAR...               2   \n",
       "27  Совместное обучение генератора и ретривера в R...               3   \n",
       "28  \"Hot-swapping\" индекса документов в RAG позвол...               2   \n",
       "29  В RAG-Sequence используется аппроксимация top-...               3   \n",
       "30  Две модели архитектур, предложенные авторами, ...               3   \n",
       "31  Основное различие между архитектурами CBOW и S...               2   \n",
       "32  В Semantic-Syntactic Word Relationship test se...               2   \n",
       "33  Модель Skip-gram показала точность 50.0% на се...               3   \n",
       "34  Сэмплирование с весами, где более близкие слов...               3   \n",
       "35  Формула вычислительной сложности модели CBOW: ...               1   \n",
       "36  Авторы отказались от использования скрытого сл...               3   \n",
       "37  Модели масштабировались с использованием 50 до...               1   \n",
       "38  Вопросы в тестовом наборе были сгенерированы в...               1   \n",
       "39  Метод, используемый для ответа на аналогии вро...               1   \n",
       "40  Ключевая идея фреймворка LADDER заключается в ...               3   \n",
       "41  Метод численной интеграции используется для ве...               1   \n",
       "42  Варианты задач в LADDER генерируются с использ...               1   \n",
       "43  TTRL — это метод тестового времени, который ис...               3   \n",
       "44  Модель Qwen2.5 7B достигла результата 90% на э...               1   \n",
       "45  Функция вознаграждения, используемая в GRPO в ...               3   \n",
       "46  Потому что RL без использования вариантов зада...               3   \n",
       "47  Использовались следующие техники: случайное вы...               1   \n",
       "48  LADDER масштабирует обучение, позволяя моделям...               3   \n",
       "49  При генерации вариантов задач наблюдались слож...               3   \n",
       "\n",
       "    gen_yandex_rank  gen_qwen_rank  sim_scores_tbank  sim_scores_yandex  \\\n",
       "0                 2              2          0.669123           0.570089   \n",
       "1                 2              3          0.695416           0.769922   \n",
       "2                 2              1          0.503097           0.558233   \n",
       "3                 2              1          0.355634           0.415566   \n",
       "4                 3              1          0.405849           0.377725   \n",
       "5                 2              1          0.602244           0.709361   \n",
       "6                 3              1          0.619954           0.577273   \n",
       "7                 2              2          0.342940           0.224844   \n",
       "8                 2              1          0.672282           0.662603   \n",
       "9                 3              2          0.395121           0.322822   \n",
       "10                3              1          0.817064           0.753922   \n",
       "11                2              2          0.320177           0.344438   \n",
       "12                3              2          0.466848           0.449711   \n",
       "13                2              1          0.513037           0.678006   \n",
       "14                1              3          0.527506           0.617846   \n",
       "15                2              1          0.558490           0.654931   \n",
       "16                2              3          0.636273           0.663828   \n",
       "17                3              1          0.531387           0.446694   \n",
       "18                2              1          0.725395           0.752094   \n",
       "19                3              2          0.555093           0.563449   \n",
       "20                3              3          0.188245           0.261742   \n",
       "21                2              1          0.515640           0.382114   \n",
       "22                2              3          0.609349           0.604506   \n",
       "23                3              2          0.675305           0.617678   \n",
       "24                3              1          0.355814           0.326911   \n",
       "25                1              2          0.639885           0.553435   \n",
       "26                1              3          0.625540           0.829998   \n",
       "27                2              1          0.346530           0.325784   \n",
       "28                3              1          0.308062           0.381191   \n",
       "29                2              1          0.569197           0.570432   \n",
       "30                3              3          0.307397           0.297944   \n",
       "31                1              1          0.728077           0.870906   \n",
       "32                3              1          0.557402           0.551080   \n",
       "33                2              1          0.704451           0.686502   \n",
       "34                2              1          0.497566           0.333870   \n",
       "35                2              2          0.590970           0.631210   \n",
       "36                2              1          0.551878           0.591255   \n",
       "37                2              3          0.492811           0.333205   \n",
       "38                2              3          0.579154           0.513489   \n",
       "39                3              2          0.628457           0.303511   \n",
       "40                2              1          0.372673           0.421113   \n",
       "41                3              2          0.558852           0.491127   \n",
       "42                2              3          0.459679           0.483903   \n",
       "43                1              2          0.836282           0.771014   \n",
       "44                2              2          0.531311           0.572808   \n",
       "45                1              2          0.524843           0.485310   \n",
       "46                2              1          0.514872           0.545307   \n",
       "47                2              3          0.553947           0.558200   \n",
       "48                2              1          0.378422           0.352350   \n",
       "49                1              2          0.471513           0.548490   \n",
       "\n",
       "    sim_scores_qwen  \n",
       "0          0.500410  \n",
       "1          0.370163  \n",
       "2          0.644848  \n",
       "3          0.558227  \n",
       "4          0.400534  \n",
       "5          0.736253  \n",
       "6          0.644929  \n",
       "7          0.229979  \n",
       "8          0.662860  \n",
       "9          0.407397  \n",
       "10         0.767716  \n",
       "11         0.360994  \n",
       "12         0.518320  \n",
       "13         0.539866  \n",
       "14         0.555313  \n",
       "15         0.525280  \n",
       "16         0.845781  \n",
       "17         0.452113  \n",
       "18         0.725277  \n",
       "19         0.651296  \n",
       "20         0.079123  \n",
       "21         0.499232  \n",
       "22         0.739484  \n",
       "23         0.616513  \n",
       "24         0.429089  \n",
       "25         0.556720  \n",
       "26         0.612993  \n",
       "27         0.460076  \n",
       "28         0.383768  \n",
       "29         0.620428  \n",
       "30         0.291936  \n",
       "31         0.725184  \n",
       "32         0.622326  \n",
       "33         0.709938  \n",
       "34         0.301729  \n",
       "35         0.539666  \n",
       "36         0.668123  \n",
       "37         0.441351  \n",
       "38         0.621097  \n",
       "39         0.465351  \n",
       "40         0.362873  \n",
       "41         0.533643  \n",
       "42         0.510993  \n",
       "43         0.782000  \n",
       "44         0.539494  \n",
       "45         0.511644  \n",
       "46         0.594181  \n",
       "47         0.411620  \n",
       "48         0.383792  \n",
       "49         0.566462  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bff4cf3-a5f8-41de-bb7d-8916fc89a94d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>gt</th>\n",
       "      <th>Tbank</th>\n",
       "      <th>YandexGPT</th>\n",
       "      <th>Qwen3</th>\n",
       "      <th>gen_tbank_rank</th>\n",
       "      <th>gen_yandex_rank</th>\n",
       "      <th>gen_qwen_rank</th>\n",
       "      <th>sim_scores_tbank</th>\n",
       "      <th>sim_scores_yandex</th>\n",
       "      <th>sim_scores_qwen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Какой оптимайзер и гиперпараметры использовали...</td>\n",
       "      <td>В оригинальной статье использовался Adam с пар...</td>\n",
       "      <td>В данном контексте использовался оптимайзер Ad...</td>\n",
       "      <td>Мы использовали оптимизатор Adam с параметрам...</td>\n",
       "      <td>Оптимайзер — Adam, гиперпараметры: β₁ = 0.9, β...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.669123</td>\n",
       "      <td>0.570089</td>\n",
       "      <td>0.500410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Какие архитектурные компоненты заменяет Transf...</td>\n",
       "      <td>Transformer заменяет RNN или LSTM/GRU, использ...</td>\n",
       "      <td>В традиционных sequence-to-sequence моделях, т...</td>\n",
       "      <td>Transformer заменяет рекуррентные слои, наибо...</td>\n",
       "      <td>Рекуррентные слои.</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.695416</td>\n",
       "      <td>0.769922</td>\n",
       "      <td>0.370163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Что такое Scaled Dot-Product Attention и зачем...</td>\n",
       "      <td>Это механизм внимания, который вычисляет:\\nAtt...</td>\n",
       "      <td>Деление на √dk в Scaled Dot-Product Attention ...</td>\n",
       "      <td>Scaled Dot-Product Attention — это метод вним...</td>\n",
       "      <td>Scaled Dot-Product Attention — это механизм вн...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.503097</td>\n",
       "      <td>0.558233</td>\n",
       "      <td>0.644848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Как устроена структура encoder и decoder в Tra...</td>\n",
       "      <td>Encoder: N одинаковых блоков (обычно N=6), каж...</td>\n",
       "      <td>Структура Transformer состоит из двух основных...</td>\n",
       "      <td>Структура encoder и decoder в Transformer сос...</td>\n",
       "      <td>Encoder состоит из стека из 6 идентичных слоев...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.355634</td>\n",
       "      <td>0.415566</td>\n",
       "      <td>0.558227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Почему Multi-Head Attention улучшает производи...</td>\n",
       "      <td>Потому что каждая \"голова\" обучается фокусиров...</td>\n",
       "      <td>Multi-Head Attention улучшает производительнос...</td>\n",
       "      <td>Multi-head attention позволяет модели совмест...</td>\n",
       "      <td>Multi-Head Attention улучшает производительнос...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.405849</td>\n",
       "      <td>0.377725</td>\n",
       "      <td>0.400534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Какие функции выполняют позиционные кодировки ...</td>\n",
       "      <td>Позиционные кодировки добавляют информацию о п...</td>\n",
       "      <td>Позиционные кодировки (PE) в нейронных сетях, ...</td>\n",
       "      <td>Позиционные кодировки выполняют функцию предс...</td>\n",
       "      <td>Позиционные кодировки позволяют модели учитыва...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.602244</td>\n",
       "      <td>0.709361</td>\n",
       "      <td>0.736253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>В чем преимущества self-attention по сравнению...</td>\n",
       "      <td>Self-attention: O(n²) по длине последовательно...</td>\n",
       "      <td>Преимущества self-attention перед рекуррентным...</td>\n",
       "      <td>В плане вычислительной сложности слой self-at...</td>\n",
       "      <td>Self-attention имеет постоянное число операций...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.619954</td>\n",
       "      <td>0.577273</td>\n",
       "      <td>0.644929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Какие техники регуляризации использовались при...</td>\n",
       "      <td>Dropout (в attention, feed-forward, embeddings...</td>\n",
       "      <td>Для обучения Transformer использовались следую...</td>\n",
       "      <td>При обучении Transformer использовались три т...</td>\n",
       "      <td>В обучении Transformer использовались три типа...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.342940</td>\n",
       "      <td>0.224844</td>\n",
       "      <td>0.229979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Какие результаты Transformer показал на задача...</td>\n",
       "      <td>EN→DE: BLEU 28.4 (vs. предыдущие ~26.4)\\nEN→FR...</td>\n",
       "      <td>На задачах перевода с английского на французск...</td>\n",
       "      <td>На задаче перевода EN→FR по WMT 2014 модель T...</td>\n",
       "      <td>Transformer показал BLEU-счет 41.8 на задаче E...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.672282</td>\n",
       "      <td>0.662603</td>\n",
       "      <td>0.662860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Почему Transformer позволяет более эффективную...</td>\n",
       "      <td>Потому что self-attention не требует последова...</td>\n",
       "      <td>Параллелизация в Transformer возможна из-за от...</td>\n",
       "      <td>Transformer позволяет значительно больше пара...</td>\n",
       "      <td>Потому что Transformer использует механизм вни...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.395121</td>\n",
       "      <td>0.322822</td>\n",
       "      <td>0.407397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>В чем заключается основная идея метода Test-Ti...</td>\n",
       "      <td>TTRL — это метод обучения с подкреплением без ...</td>\n",
       "      <td>Основная идея метода Test-Time Reinforcement L...</td>\n",
       "      <td>Основная идея метода Test-Time Reinforcement ...</td>\n",
       "      <td>Основная идея метода Test-Time Reinforcement L...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.817064</td>\n",
       "      <td>0.753922</td>\n",
       "      <td>0.767716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Каким бразом осуществляется оценка вознагражде...</td>\n",
       "      <td>Модель многократно генерирует ответы на один и...</td>\n",
       "      <td>Оценка вознаграждения в TTRL (Test-Time Reinfo...</td>\n",
       "      <td>Оценка вознаграждения в TTRL без доступа к ис...</td>\n",
       "      <td>Оценка вознаграждения в TTRL осуществляется с ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.320177</td>\n",
       "      <td>0.344438</td>\n",
       "      <td>0.360994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Какую роль играет метод большинства голосов (m...</td>\n",
       "      <td>Majority voting используется для оценки метки ...</td>\n",
       "      <td>Метод большинства голосов в архитектуре TTRL и...</td>\n",
       "      <td>Метод большинства голосов (majority voting) в...</td>\n",
       "      <td>Метод большинства голосов (majority voting) в ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.466848</td>\n",
       "      <td>0.449711</td>\n",
       "      <td>0.518320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Какие улучшения производительности были достиг...</td>\n",
       "      <td>На AIME 2024 модель Qwen2.5-Math-7B улучшилась...</td>\n",
       "      <td>На бенчмарке AIME 2024 применение TTRL (техник...</td>\n",
       "      <td>Применение TTRL к Qwen2.5-Math-7B привело к у...</td>\n",
       "      <td>Улучшения производительности с помощью TTRL на...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.513037</td>\n",
       "      <td>0.678006</td>\n",
       "      <td>0.539866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Как TTRL сравнивается с RL на размеченных тест...</td>\n",
       "      <td>TTRL почти достигает производительности RL с д...</td>\n",
       "      <td>На размеченных тестовых данных, **TTRL** (Tran...</td>\n",
       "      <td>По результатам оценки на размеченных тестовых...</td>\n",
       "      <td>TTRL показывает эффективность, сравнимую с RL ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.527506</td>\n",
       "      <td>0.617846</td>\n",
       "      <td>0.555313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Почему TTRL способен работать даже при неточны...</td>\n",
       "      <td>Потому что:\\nRL устойчив к шуму в наградах.\\nД...</td>\n",
       "      <td>TTRL (Temporal Reward-Driven Learning) остаётс...</td>\n",
       "      <td>TTRL остаётся эффективным даже при неточных о...</td>\n",
       "      <td>Потому что награды более плотные, чем метки, ч...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558490</td>\n",
       "      <td>0.654931</td>\n",
       "      <td>0.525280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Какие модели и бенчмарки использовались для оц...</td>\n",
       "      <td>Модели: Qwen2.5-Math-1.5B, Qwen2.5-Math-7B, LL...</td>\n",
       "      <td>Для оценки эффективности TTRL (Test-Time Reinf...</td>\n",
       "      <td>Для оценки эффективности TTRL использовались ...</td>\n",
       "      <td>Модели: Qwen2.5-Math-7B, DeepSeek-R1. Бенчмарк...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.636273</td>\n",
       "      <td>0.663828</td>\n",
       "      <td>0.845781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Какие факторы могут привести к сбою или неэффе...</td>\n",
       "      <td>Недостаток предварительных знаний у модели (на...</td>\n",
       "      <td>Основные причины неэффективности или сбоя в TT...</td>\n",
       "      <td>Фактором, который может привести к сбою или н...</td>\n",
       "      <td>Недостаток предварительных знаний о целевой за...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531387</td>\n",
       "      <td>0.446694</td>\n",
       "      <td>0.452113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Как TTRL масштабируется при увеличении размера...</td>\n",
       "      <td>TTRL масштабируется положительно — более крупн...</td>\n",
       "      <td>TTRL (Test-Time Reinforcement Learning) демонс...</td>\n",
       "      <td>TTRL естественно масштабируется: с увеличение...</td>\n",
       "      <td>TTRL естественно масштабируется с увеличением ...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.725395</td>\n",
       "      <td>0.752094</td>\n",
       "      <td>0.725277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>С какими алгоритмами обучения с подкреплением ...</td>\n",
       "      <td>Совместим с PPO и GRPO. В экспериментах исполь...</td>\n",
       "      <td>Техника TTRL (Temporal Training with Reinforce...</td>\n",
       "      <td>TTRL совместим с разными алгоритмами обучения...</td>\n",
       "      <td>TTRL совместим с алгоритмами PPO и GRPO, и в э...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.555093</td>\n",
       "      <td>0.563449</td>\n",
       "      <td>0.651296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Какая модель используется в качестве генератор...</td>\n",
       "      <td>BART-large (400M параметров) используется как ...</td>\n",
       "      <td>В RAG (Retrieval-Augmented Generation) использ...</td>\n",
       "      <td>В RAG используется генератор $p_{\\theta} (y_i...</td>\n",
       "      <td>RAG-Sequence модель.</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.188245</td>\n",
       "      <td>0.261742</td>\n",
       "      <td>0.079123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Какая модель используется в качестве ретривера...</td>\n",
       "      <td>DPR (Dense Passage Retriever) — bi-encoder на ...</td>\n",
       "      <td>В качестве ретривера в RAG используется модель...</td>\n",
       "      <td>В RAG в качестве ретривера используется ретри...</td>\n",
       "      <td>В RAG в качестве ретривера используется Dense ...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.515640</td>\n",
       "      <td>0.382114</td>\n",
       "      <td>0.499232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Чем отличаются архитектуры RAG-Token и RAG-Seq...</td>\n",
       "      <td>RAG-Sequence использует один и тот же документ...</td>\n",
       "      <td>**RAG-Token** использует автокодирование, где ...</td>\n",
       "      <td>RAG-Token можно рассматривать как стандартный...</td>\n",
       "      <td>Архитектура RAG-Token использует токенизацию д...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.609349</td>\n",
       "      <td>0.604506</td>\n",
       "      <td>0.739484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Какой объем документов используется в векторно...</td>\n",
       "      <td>21 миллион документов, каждая статья разбита н...</td>\n",
       "      <td>В векторном индексе Wikipedia используется 21 ...</td>\n",
       "      <td>21 млн документов.</td>\n",
       "      <td>Объем документов в векторном индексе Wikipedia...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.675305</td>\n",
       "      <td>0.617678</td>\n",
       "      <td>0.616513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Какие задачи были использованы для оценки RAG-...</td>\n",
       "      <td>Open-domain QA: Natural Questions, TriviaQA, W...</td>\n",
       "      <td>Для оценки RAG-моделей использовались задачи, ...</td>\n",
       "      <td>Модели оценивались на широком спектре задач, ...</td>\n",
       "      <td>Для оценки RAG-моделей использовались задачи, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.355814</td>\n",
       "      <td>0.326911</td>\n",
       "      <td>0.429089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Почему авторы считают генерацию предпочтительн...</td>\n",
       "      <td>Потому что:\\nМожно обобщать и генерировать отв...</td>\n",
       "      <td>Авторы считают генерацию предпочтительной, пот...</td>\n",
       "      <td>Авторы считают генерацию предпочтительной по ...</td>\n",
       "      <td>Авторы считают генерацию предпочтительной по с...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.639885</td>\n",
       "      <td>0.553435</td>\n",
       "      <td>0.556720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Какую производительность показал RAG на задаче...</td>\n",
       "      <td>RAG-Token превзошёл BART по метрике Q-BLEU-1 (...</td>\n",
       "      <td>RAG (Reinforced Attention Generative Adversari...</td>\n",
       "      <td>RAG-Token показал лучшие результаты, чем RAG-...</td>\n",
       "      <td>RAG показал лучшую производительность, чем BAR...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.625540</td>\n",
       "      <td>0.829998</td>\n",
       "      <td>0.612993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Как осуществляется совместное обучение генерат...</td>\n",
       "      <td>Модель обучается end-to-end, минимизируя отриц...</td>\n",
       "      <td>В RAG (Retrieval-Augmented Generation) обучени...</td>\n",
       "      <td>Оба генератора и ретривера в RAG обучаются со...</td>\n",
       "      <td>Совместное обучение генератора и ретривера в R...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.346530</td>\n",
       "      <td>0.325784</td>\n",
       "      <td>0.460076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Какой эффект даёт \"hot-swapping\" индекса докум...</td>\n",
       "      <td>Можно обновлять знания модели без переобучения...</td>\n",
       "      <td>\"Hot-swapping\" индекса в RAG (Retrieval-Augmen...</td>\n",
       "      <td>«Hot-swapping» индекса документов в RAG позво...</td>\n",
       "      <td>\"Hot-swapping\" индекса документов в RAG позвол...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.308062</td>\n",
       "      <td>0.381191</td>\n",
       "      <td>0.383768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Какие аппроксимации используются при декодиров...</td>\n",
       "      <td>RAG-Token: стандартный beam search с суммой по...</td>\n",
       "      <td>Для декодирования в RAG-Sequence и RAG-Token и...</td>\n",
       "      <td>При декодировании в RAG-Sequence и RAG-Token ...</td>\n",
       "      <td>В RAG-Sequence используется аппроксимация top-...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.569197</td>\n",
       "      <td>0.570432</td>\n",
       "      <td>0.620428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Какие две модели архитектур были предложены ав...</td>\n",
       "      <td>CBOW (Continuous Bag-of-Words)\\nSkip-gram\\nОбе...</td>\n",
       "      <td>Авторы предложили две модели для обучения вект...</td>\n",
       "      <td>Авторы предложили две модели архитектур: \\n1....</td>\n",
       "      <td>Две модели архитектур, предложенные авторами, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.307397</td>\n",
       "      <td>0.297944</td>\n",
       "      <td>0.291936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>В чём основное различие между архитектурами CB...</td>\n",
       "      <td>CBOW предсказывает текущие слово по контексту ...</td>\n",
       "      <td>Основное различие между архитектурами CBOW (Co...</td>\n",
       "      <td>CBOW предсказывает текущее слово на основе ко...</td>\n",
       "      <td>Основное различие между архитектурами CBOW и S...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.728077</td>\n",
       "      <td>0.870906</td>\n",
       "      <td>0.725184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Какие типы отношений включены в Semantic-Synta...</td>\n",
       "      <td>Семантические (5 типов): столицы, валюты, отно...</td>\n",
       "      <td>В Semantic-Syntactic Word Relationship test se...</td>\n",
       "      <td>В Semantic-Syntactic Word Relationship test s...</td>\n",
       "      <td>В Semantic-Syntactic Word Relationship test se...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.557402</td>\n",
       "      <td>0.551080</td>\n",
       "      <td>0.622326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Какие значения точности показала модель Skip-g...</td>\n",
       "      <td>Для Skip-gram с размерностью 300 и обучением н...</td>\n",
       "      <td>Модель Skip-gram показала точность 24% на сема...</td>\n",
       "      <td>Модель Skip-gram показала точность 55% на сем...</td>\n",
       "      <td>Модель Skip-gram показала точность 50.0% на се...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.704451</td>\n",
       "      <td>0.686502</td>\n",
       "      <td>0.709938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Какой подход используется в Skip-gram модели д...</td>\n",
       "      <td>Слово предсказывает контекст в окне размера C....</td>\n",
       "      <td>В модели Skip-gram для выбора контекстных слов...</td>\n",
       "      <td>В Skip-gram модели используется подход, при к...</td>\n",
       "      <td>Сэмплирование с весами, где более близкие слов...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.497566</td>\n",
       "      <td>0.333870</td>\n",
       "      <td>0.301729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Какова формула вычислительной сложности модели...</td>\n",
       "      <td>Q=N⋅D+D⋅log 2​(V)\\nГде:\\nN — количество слов в...</td>\n",
       "      <td>Формула вычислительной сложности для модели CB...</td>\n",
       "      <td>$Q = C × (D + D × log_2(V))$</td>\n",
       "      <td>Формула вычислительной сложности модели CBOW: ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.590970</td>\n",
       "      <td>0.631210</td>\n",
       "      <td>0.539666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Почему авторы отказались от использования скры...</td>\n",
       "      <td>Потому что основная вычислительная нагрузка пр...</td>\n",
       "      <td>Авторы отказались от использования скрытого сл...</td>\n",
       "      <td>Авторы отказались от использования скрытого с...</td>\n",
       "      <td>Авторы отказались от использования скрытого сл...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.551878</td>\n",
       "      <td>0.591255</td>\n",
       "      <td>0.668123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Как масштабировалась тренировка моделей в расп...</td>\n",
       "      <td>Использовалась асинхронная mini-batch SGD + Ad...</td>\n",
       "      <td>Масштабирование тренировки моделей в системе D...</td>\n",
       "      <td>В системе DistBelief тренировка моделей масшт...</td>\n",
       "      <td>Модели масштабировались с использованием 50 до...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.492811</td>\n",
       "      <td>0.333205</td>\n",
       "      <td>0.441351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Как были сгенерированы вопросы в тестовом набо...</td>\n",
       "      <td>Сначала вручную созданы списки пар слов.\\nЗате...</td>\n",
       "      <td>Вопросы для тестирования word vectors были сге...</td>\n",
       "      <td>Вопросы в тестовом наборе для оценки word vec...</td>\n",
       "      <td>Вопросы в тестовом наборе были сгенерированы в...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.579154</td>\n",
       "      <td>0.513489</td>\n",
       "      <td>0.621097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Какой метод используется для ответа на аналоги...</td>\n",
       "      <td>Применяется векторная арифметика:\\nvec(\"king\")...</td>\n",
       "      <td>Для решения аналогий, таких как \"king - man + ...</td>\n",
       "      <td>Метод word offset, где выполняются простые ал...</td>\n",
       "      <td>Метод, используемый для ответа на аналогии вро...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.628457</td>\n",
       "      <td>0.303511</td>\n",
       "      <td>0.465351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>В чём заключается ключевая идея фреймворка LAD...</td>\n",
       "      <td>Модель самостоятельно улучшает свои способност...</td>\n",
       "      <td>Ключевая идея фреймворка LADDER заключается в ...</td>\n",
       "      <td>Ключевая идея фреймворка LADDER заключается в...</td>\n",
       "      <td>Ключевая идея фреймворка LADDER заключается в ...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.372673</td>\n",
       "      <td>0.421113</td>\n",
       "      <td>0.362873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Какой метод используется для верификации прави...</td>\n",
       "      <td>Применяется численная верификация: сравнение о...</td>\n",
       "      <td>Для верификации решений интегралов в LADDER ис...</td>\n",
       "      <td>Для верификации правильности решений интеграл...</td>\n",
       "      <td>Метод численной интеграции используется для ве...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.558852</td>\n",
       "      <td>0.491127</td>\n",
       "      <td>0.533643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Как осуществляется генерация вариантов задач в...</td>\n",
       "      <td>Варианты создаются по дереву:\\nПрименяются 3–5...</td>\n",
       "      <td>В LADDER генерация вариантов задач происходит ...</td>\n",
       "      <td>Генерация вариантов задач в LADDER осуществля...</td>\n",
       "      <td>Варианты задач в LADDER генерируются с использ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.459679</td>\n",
       "      <td>0.483903</td>\n",
       "      <td>0.510993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Что такое TTRL и чем он отличается от LADDER?</td>\n",
       "      <td>TTRL (Test-Time RL) — это тестовое применение ...</td>\n",
       "      <td>TTRL (Test-Time Recursive Learning) — это мето...</td>\n",
       "      <td>TTRL — это более эффективный метод масштабиро...</td>\n",
       "      <td>TTRL — это метод тестового времени, который ис...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.836282</td>\n",
       "      <td>0.771014</td>\n",
       "      <td>0.782000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Какие результаты достигнуты моделью Qwen2.5 7B...</td>\n",
       "      <td>LADDER: 73% (вышел на уровень квалификации)\\nL...</td>\n",
       "      <td>На экзамене MIT Integration Bee модель Qwen2.5...</td>\n",
       "      <td>После применения LADDER и TTRL модель Qwen2.5...</td>\n",
       "      <td>Модель Qwen2.5 7B достигла результата 90% на э...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.531311</td>\n",
       "      <td>0.572808</td>\n",
       "      <td>0.539494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Какая функция вознаграждения используется в GR...</td>\n",
       "      <td>GRPO использует два компонента:\\nAccuracy rewa...</td>\n",
       "      <td>В рамках LADDER используется функция вознаграж...</td>\n",
       "      <td>В GRPO в рамках обучения в LADDER используетс...</td>\n",
       "      <td>Функция вознаграждения, используемая в GRPO в ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.524843</td>\n",
       "      <td>0.485310</td>\n",
       "      <td>0.511644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Почему RL без использования вариантов задач по...</td>\n",
       "      <td>Без градиента сложности RL быстро проваливаетс...</td>\n",
       "      <td>Использование RL без специальных методов и под...</td>\n",
       "      <td>Успех RL с вариантами задач обусловлен тщател...</td>\n",
       "      <td>Потому что RL без использования вариантов зада...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.514872</td>\n",
       "      <td>0.545307</td>\n",
       "      <td>0.594181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Какие техники использовались для увеличения ра...</td>\n",
       "      <td>Batch prompting (по 10 за раз)\\nTemperature cy...</td>\n",
       "      <td>Для увеличения разнообразия генерируемых задач...</td>\n",
       "      <td>Для увеличения разнообразия генерируемых вари...</td>\n",
       "      <td>Использовались следующие техники: случайное вы...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.553947</td>\n",
       "      <td>0.558200</td>\n",
       "      <td>0.411620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Как LADDER масштабирует обучение без увеличени...</td>\n",
       "      <td>Путём генерации тысяч вариантов и обучения на ...</td>\n",
       "      <td>LADDER масштабирует обучение, используя методы...</td>\n",
       "      <td>LADDER масштабирует обучение без увеличения р...</td>\n",
       "      <td>LADDER масштабирует обучение, позволяя моделям...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.378422</td>\n",
       "      <td>0.352350</td>\n",
       "      <td>0.383792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Какие ограничения или сложности были замечены ...</td>\n",
       "      <td>Примерно 8% вариантов оказались нерешаемыми\\nН...</td>\n",
       "      <td>Основные сложности при генерации задач связаны...</td>\n",
       "      <td>При генерации вариантов задач были замечены с...</td>\n",
       "      <td>При генерации вариантов задач наблюдались слож...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.471513</td>\n",
       "      <td>0.548490</td>\n",
       "      <td>0.566462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Questions  \\\n",
       "0   Какой оптимайзер и гиперпараметры использовали...   \n",
       "1   Какие архитектурные компоненты заменяет Transf...   \n",
       "2   Что такое Scaled Dot-Product Attention и зачем...   \n",
       "3   Как устроена структура encoder и decoder в Tra...   \n",
       "4   Почему Multi-Head Attention улучшает производи...   \n",
       "5   Какие функции выполняют позиционные кодировки ...   \n",
       "6   В чем преимущества self-attention по сравнению...   \n",
       "7   Какие техники регуляризации использовались при...   \n",
       "8   Какие результаты Transformer показал на задача...   \n",
       "9   Почему Transformer позволяет более эффективную...   \n",
       "10  В чем заключается основная идея метода Test-Ti...   \n",
       "11  Каким бразом осуществляется оценка вознагражде...   \n",
       "12  Какую роль играет метод большинства голосов (m...   \n",
       "13  Какие улучшения производительности были достиг...   \n",
       "14  Как TTRL сравнивается с RL на размеченных тест...   \n",
       "15  Почему TTRL способен работать даже при неточны...   \n",
       "16  Какие модели и бенчмарки использовались для оц...   \n",
       "17  Какие факторы могут привести к сбою или неэффе...   \n",
       "18  Как TTRL масштабируется при увеличении размера...   \n",
       "19  С какими алгоритмами обучения с подкреплением ...   \n",
       "20  Какая модель используется в качестве генератор...   \n",
       "21  Какая модель используется в качестве ретривера...   \n",
       "22  Чем отличаются архитектуры RAG-Token и RAG-Seq...   \n",
       "23  Какой объем документов используется в векторно...   \n",
       "24  Какие задачи были использованы для оценки RAG-...   \n",
       "25  Почему авторы считают генерацию предпочтительн...   \n",
       "26  Какую производительность показал RAG на задаче...   \n",
       "27  Как осуществляется совместное обучение генерат...   \n",
       "28  Какой эффект даёт \"hot-swapping\" индекса докум...   \n",
       "29  Какие аппроксимации используются при декодиров...   \n",
       "30  Какие две модели архитектур были предложены ав...   \n",
       "31  В чём основное различие между архитектурами CB...   \n",
       "32  Какие типы отношений включены в Semantic-Synta...   \n",
       "33  Какие значения точности показала модель Skip-g...   \n",
       "34  Какой подход используется в Skip-gram модели д...   \n",
       "35  Какова формула вычислительной сложности модели...   \n",
       "36  Почему авторы отказались от использования скры...   \n",
       "37  Как масштабировалась тренировка моделей в расп...   \n",
       "38  Как были сгенерированы вопросы в тестовом набо...   \n",
       "39  Какой метод используется для ответа на аналоги...   \n",
       "40  В чём заключается ключевая идея фреймворка LAD...   \n",
       "41  Какой метод используется для верификации прави...   \n",
       "42  Как осуществляется генерация вариантов задач в...   \n",
       "43      Что такое TTRL и чем он отличается от LADDER?   \n",
       "44  Какие результаты достигнуты моделью Qwen2.5 7B...   \n",
       "45  Какая функция вознаграждения используется в GR...   \n",
       "46  Почему RL без использования вариантов задач по...   \n",
       "47  Какие техники использовались для увеличения ра...   \n",
       "48  Как LADDER масштабирует обучение без увеличени...   \n",
       "49  Какие ограничения или сложности были замечены ...   \n",
       "\n",
       "                                                   gt  \\\n",
       "0   В оригинальной статье использовался Adam с пар...   \n",
       "1   Transformer заменяет RNN или LSTM/GRU, использ...   \n",
       "2   Это механизм внимания, который вычисляет:\\nAtt...   \n",
       "3   Encoder: N одинаковых блоков (обычно N=6), каж...   \n",
       "4   Потому что каждая \"голова\" обучается фокусиров...   \n",
       "5   Позиционные кодировки добавляют информацию о п...   \n",
       "6   Self-attention: O(n²) по длине последовательно...   \n",
       "7   Dropout (в attention, feed-forward, embeddings...   \n",
       "8   EN→DE: BLEU 28.4 (vs. предыдущие ~26.4)\\nEN→FR...   \n",
       "9   Потому что self-attention не требует последова...   \n",
       "10  TTRL — это метод обучения с подкреплением без ...   \n",
       "11  Модель многократно генерирует ответы на один и...   \n",
       "12  Majority voting используется для оценки метки ...   \n",
       "13  На AIME 2024 модель Qwen2.5-Math-7B улучшилась...   \n",
       "14  TTRL почти достигает производительности RL с д...   \n",
       "15  Потому что:\\nRL устойчив к шуму в наградах.\\nД...   \n",
       "16  Модели: Qwen2.5-Math-1.5B, Qwen2.5-Math-7B, LL...   \n",
       "17  Недостаток предварительных знаний у модели (на...   \n",
       "18  TTRL масштабируется положительно — более крупн...   \n",
       "19  Совместим с PPO и GRPO. В экспериментах исполь...   \n",
       "20  BART-large (400M параметров) используется как ...   \n",
       "21  DPR (Dense Passage Retriever) — bi-encoder на ...   \n",
       "22  RAG-Sequence использует один и тот же документ...   \n",
       "23  21 миллион документов, каждая статья разбита н...   \n",
       "24  Open-domain QA: Natural Questions, TriviaQA, W...   \n",
       "25  Потому что:\\nМожно обобщать и генерировать отв...   \n",
       "26  RAG-Token превзошёл BART по метрике Q-BLEU-1 (...   \n",
       "27  Модель обучается end-to-end, минимизируя отриц...   \n",
       "28  Можно обновлять знания модели без переобучения...   \n",
       "29  RAG-Token: стандартный beam search с суммой по...   \n",
       "30  CBOW (Continuous Bag-of-Words)\\nSkip-gram\\nОбе...   \n",
       "31  CBOW предсказывает текущие слово по контексту ...   \n",
       "32  Семантические (5 типов): столицы, валюты, отно...   \n",
       "33  Для Skip-gram с размерностью 300 и обучением н...   \n",
       "34  Слово предсказывает контекст в окне размера C....   \n",
       "35  Q=N⋅D+D⋅log 2​(V)\\nГде:\\nN — количество слов в...   \n",
       "36  Потому что основная вычислительная нагрузка пр...   \n",
       "37  Использовалась асинхронная mini-batch SGD + Ad...   \n",
       "38  Сначала вручную созданы списки пар слов.\\nЗате...   \n",
       "39  Применяется векторная арифметика:\\nvec(\"king\")...   \n",
       "40  Модель самостоятельно улучшает свои способност...   \n",
       "41  Применяется численная верификация: сравнение о...   \n",
       "42  Варианты создаются по дереву:\\nПрименяются 3–5...   \n",
       "43  TTRL (Test-Time RL) — это тестовое применение ...   \n",
       "44  LADDER: 73% (вышел на уровень квалификации)\\nL...   \n",
       "45  GRPO использует два компонента:\\nAccuracy rewa...   \n",
       "46  Без градиента сложности RL быстро проваливаетс...   \n",
       "47  Batch prompting (по 10 за раз)\\nTemperature cy...   \n",
       "48  Путём генерации тысяч вариантов и обучения на ...   \n",
       "49  Примерно 8% вариантов оказались нерешаемыми\\nН...   \n",
       "\n",
       "                                                Tbank  \\\n",
       "0   В данном контексте использовался оптимайзер Ad...   \n",
       "1   В традиционных sequence-to-sequence моделях, т...   \n",
       "2   Деление на √dk в Scaled Dot-Product Attention ...   \n",
       "3   Структура Transformer состоит из двух основных...   \n",
       "4   Multi-Head Attention улучшает производительнос...   \n",
       "5   Позиционные кодировки (PE) в нейронных сетях, ...   \n",
       "6   Преимущества self-attention перед рекуррентным...   \n",
       "7   Для обучения Transformer использовались следую...   \n",
       "8   На задачах перевода с английского на французск...   \n",
       "9   Параллелизация в Transformer возможна из-за от...   \n",
       "10  Основная идея метода Test-Time Reinforcement L...   \n",
       "11  Оценка вознаграждения в TTRL (Test-Time Reinfo...   \n",
       "12  Метод большинства голосов в архитектуре TTRL и...   \n",
       "13  На бенчмарке AIME 2024 применение TTRL (техник...   \n",
       "14  На размеченных тестовых данных, **TTRL** (Tran...   \n",
       "15  TTRL (Temporal Reward-Driven Learning) остаётс...   \n",
       "16  Для оценки эффективности TTRL (Test-Time Reinf...   \n",
       "17  Основные причины неэффективности или сбоя в TT...   \n",
       "18  TTRL (Test-Time Reinforcement Learning) демонс...   \n",
       "19  Техника TTRL (Temporal Training with Reinforce...   \n",
       "20  В RAG (Retrieval-Augmented Generation) использ...   \n",
       "21  В качестве ретривера в RAG используется модель...   \n",
       "22  **RAG-Token** использует автокодирование, где ...   \n",
       "23  В векторном индексе Wikipedia используется 21 ...   \n",
       "24  Для оценки RAG-моделей использовались задачи, ...   \n",
       "25  Авторы считают генерацию предпочтительной, пот...   \n",
       "26  RAG (Reinforced Attention Generative Adversari...   \n",
       "27  В RAG (Retrieval-Augmented Generation) обучени...   \n",
       "28  \"Hot-swapping\" индекса в RAG (Retrieval-Augmen...   \n",
       "29  Для декодирования в RAG-Sequence и RAG-Token и...   \n",
       "30  Авторы предложили две модели для обучения вект...   \n",
       "31  Основное различие между архитектурами CBOW (Co...   \n",
       "32  В Semantic-Syntactic Word Relationship test se...   \n",
       "33  Модель Skip-gram показала точность 24% на сема...   \n",
       "34  В модели Skip-gram для выбора контекстных слов...   \n",
       "35  Формула вычислительной сложности для модели CB...   \n",
       "36  Авторы отказались от использования скрытого сл...   \n",
       "37  Масштабирование тренировки моделей в системе D...   \n",
       "38  Вопросы для тестирования word vectors были сге...   \n",
       "39  Для решения аналогий, таких как \"king - man + ...   \n",
       "40  Ключевая идея фреймворка LADDER заключается в ...   \n",
       "41  Для верификации решений интегралов в LADDER ис...   \n",
       "42  В LADDER генерация вариантов задач происходит ...   \n",
       "43  TTRL (Test-Time Recursive Learning) — это мето...   \n",
       "44  На экзамене MIT Integration Bee модель Qwen2.5...   \n",
       "45  В рамках LADDER используется функция вознаграж...   \n",
       "46  Использование RL без специальных методов и под...   \n",
       "47  Для увеличения разнообразия генерируемых задач...   \n",
       "48  LADDER масштабирует обучение, используя методы...   \n",
       "49  Основные сложности при генерации задач связаны...   \n",
       "\n",
       "                                            YandexGPT  \\\n",
       "0    Мы использовали оптимизатор Adam с параметрам...   \n",
       "1    Transformer заменяет рекуррентные слои, наибо...   \n",
       "2    Scaled Dot-Product Attention — это метод вним...   \n",
       "3    Структура encoder и decoder в Transformer сос...   \n",
       "4    Multi-head attention позволяет модели совмест...   \n",
       "5    Позиционные кодировки выполняют функцию предс...   \n",
       "6    В плане вычислительной сложности слой self-at...   \n",
       "7    При обучении Transformer использовались три т...   \n",
       "8    На задаче перевода EN→FR по WMT 2014 модель T...   \n",
       "9    Transformer позволяет значительно больше пара...   \n",
       "10   Основная идея метода Test-Time Reinforcement ...   \n",
       "11   Оценка вознаграждения в TTRL без доступа к ис...   \n",
       "12   Метод большинства голосов (majority voting) в...   \n",
       "13   Применение TTRL к Qwen2.5-Math-7B привело к у...   \n",
       "14   По результатам оценки на размеченных тестовых...   \n",
       "15   TTRL остаётся эффективным даже при неточных о...   \n",
       "16   Для оценки эффективности TTRL использовались ...   \n",
       "17   Фактором, который может привести к сбою или н...   \n",
       "18   TTRL естественно масштабируется: с увеличение...   \n",
       "19   TTRL совместим с разными алгоритмами обучения...   \n",
       "20   В RAG используется генератор $p_{\\theta} (y_i...   \n",
       "21   В RAG в качестве ретривера используется ретри...   \n",
       "22   RAG-Token можно рассматривать как стандартный...   \n",
       "23                                 21 млн документов.   \n",
       "24   Модели оценивались на широком спектре задач, ...   \n",
       "25   Авторы считают генерацию предпочтительной по ...   \n",
       "26   RAG-Token показал лучшие результаты, чем RAG-...   \n",
       "27   Оба генератора и ретривера в RAG обучаются со...   \n",
       "28   «Hot-swapping» индекса документов в RAG позво...   \n",
       "29   При декодировании в RAG-Sequence и RAG-Token ...   \n",
       "30   Авторы предложили две модели архитектур: \\n1....   \n",
       "31   CBOW предсказывает текущее слово на основе ко...   \n",
       "32   В Semantic-Syntactic Word Relationship test s...   \n",
       "33   Модель Skip-gram показала точность 55% на сем...   \n",
       "34   В Skip-gram модели используется подход, при к...   \n",
       "35                       $Q = C × (D + D × log_2(V))$   \n",
       "36   Авторы отказались от использования скрытого с...   \n",
       "37   В системе DistBelief тренировка моделей масшт...   \n",
       "38   Вопросы в тестовом наборе для оценки word vec...   \n",
       "39   Метод word offset, где выполняются простые ал...   \n",
       "40   Ключевая идея фреймворка LADDER заключается в...   \n",
       "41   Для верификации правильности решений интеграл...   \n",
       "42   Генерация вариантов задач в LADDER осуществля...   \n",
       "43   TTRL — это более эффективный метод масштабиро...   \n",
       "44   После применения LADDER и TTRL модель Qwen2.5...   \n",
       "45   В GRPO в рамках обучения в LADDER используетс...   \n",
       "46   Успех RL с вариантами задач обусловлен тщател...   \n",
       "47   Для увеличения разнообразия генерируемых вари...   \n",
       "48   LADDER масштабирует обучение без увеличения р...   \n",
       "49   При генерации вариантов задач были замечены с...   \n",
       "\n",
       "                                                Qwen3  gen_tbank_rank  \\\n",
       "0   Оптимайзер — Adam, гиперпараметры: β₁ = 0.9, β...               1   \n",
       "1                                  Рекуррентные слои.               1   \n",
       "2   Scaled Dot-Product Attention — это механизм вн...               3   \n",
       "3   Encoder состоит из стека из 6 идентичных слоев...               3   \n",
       "4   Multi-Head Attention улучшает производительнос...               2   \n",
       "5   Позиционные кодировки позволяют модели учитыва...               3   \n",
       "6   Self-attention имеет постоянное число операций...               2   \n",
       "7   В обучении Transformer использовались три типа...               1   \n",
       "8   Transformer показал BLEU-счет 41.8 на задаче E...               3   \n",
       "9   Потому что Transformer использует механизм вни...               1   \n",
       "10  Основная идея метода Test-Time Reinforcement L...               2   \n",
       "11  Оценка вознаграждения в TTRL осуществляется с ...               2   \n",
       "12  Метод большинства голосов (majority voting) в ...               1   \n",
       "13  Улучшения производительности с помощью TTRL на...               3   \n",
       "14  TTRL показывает эффективность, сравнимую с RL ...               2   \n",
       "15  Потому что награды более плотные, чем метки, ч...               3   \n",
       "16  Модели: Qwen2.5-Math-7B, DeepSeek-R1. Бенчмарк...               1   \n",
       "17  Недостаток предварительных знаний о целевой за...               2   \n",
       "18  TTRL естественно масштабируется с увеличением ...               3   \n",
       "19  TTRL совместим с алгоритмами PPO и GRPO, и в э...               1   \n",
       "20                               RAG-Sequence модель.               3   \n",
       "21  В RAG в качестве ретривера используется Dense ...               3   \n",
       "22  Архитектура RAG-Token использует токенизацию д...               1   \n",
       "23  Объем документов в векторном индексе Wikipedia...               1   \n",
       "24  Для оценки RAG-моделей использовались задачи, ...               2   \n",
       "25  Авторы считают генерацию предпочтительной по с...               3   \n",
       "26  RAG показал лучшую производительность, чем BAR...               2   \n",
       "27  Совместное обучение генератора и ретривера в R...               3   \n",
       "28  \"Hot-swapping\" индекса документов в RAG позвол...               2   \n",
       "29  В RAG-Sequence используется аппроксимация top-...               3   \n",
       "30  Две модели архитектур, предложенные авторами, ...               3   \n",
       "31  Основное различие между архитектурами CBOW и S...               2   \n",
       "32  В Semantic-Syntactic Word Relationship test se...               2   \n",
       "33  Модель Skip-gram показала точность 50.0% на се...               3   \n",
       "34  Сэмплирование с весами, где более близкие слов...               3   \n",
       "35  Формула вычислительной сложности модели CBOW: ...               1   \n",
       "36  Авторы отказались от использования скрытого сл...               3   \n",
       "37  Модели масштабировались с использованием 50 до...               1   \n",
       "38  Вопросы в тестовом наборе были сгенерированы в...               1   \n",
       "39  Метод, используемый для ответа на аналогии вро...               1   \n",
       "40  Ключевая идея фреймворка LADDER заключается в ...               3   \n",
       "41  Метод численной интеграции используется для ве...               1   \n",
       "42  Варианты задач в LADDER генерируются с использ...               1   \n",
       "43  TTRL — это метод тестового времени, который ис...               3   \n",
       "44  Модель Qwen2.5 7B достигла результата 90% на э...               1   \n",
       "45  Функция вознаграждения, используемая в GRPO в ...               3   \n",
       "46  Потому что RL без использования вариантов зада...               3   \n",
       "47  Использовались следующие техники: случайное вы...               1   \n",
       "48  LADDER масштабирует обучение, позволяя моделям...               3   \n",
       "49  При генерации вариантов задач наблюдались слож...               3   \n",
       "\n",
       "    gen_yandex_rank  gen_qwen_rank  sim_scores_tbank  sim_scores_yandex  \\\n",
       "0                 2              2          0.669123           0.570089   \n",
       "1                 2              3          0.695416           0.769922   \n",
       "2                 2              1          0.503097           0.558233   \n",
       "3                 2              1          0.355634           0.415566   \n",
       "4                 3              1          0.405849           0.377725   \n",
       "5                 2              1          0.602244           0.709361   \n",
       "6                 3              1          0.619954           0.577273   \n",
       "7                 2              2          0.342940           0.224844   \n",
       "8                 2              1          0.672282           0.662603   \n",
       "9                 3              2          0.395121           0.322822   \n",
       "10                3              1          0.817064           0.753922   \n",
       "11                2              2          0.320177           0.344438   \n",
       "12                3              2          0.466848           0.449711   \n",
       "13                2              1          0.513037           0.678006   \n",
       "14                1              3          0.527506           0.617846   \n",
       "15                2              1          0.558490           0.654931   \n",
       "16                2              3          0.636273           0.663828   \n",
       "17                3              1          0.531387           0.446694   \n",
       "18                2              1          0.725395           0.752094   \n",
       "19                3              2          0.555093           0.563449   \n",
       "20                3              3          0.188245           0.261742   \n",
       "21                2              1          0.515640           0.382114   \n",
       "22                2              3          0.609349           0.604506   \n",
       "23                3              2          0.675305           0.617678   \n",
       "24                3              1          0.355814           0.326911   \n",
       "25                1              2          0.639885           0.553435   \n",
       "26                1              3          0.625540           0.829998   \n",
       "27                2              1          0.346530           0.325784   \n",
       "28                3              1          0.308062           0.381191   \n",
       "29                2              1          0.569197           0.570432   \n",
       "30                3              3          0.307397           0.297944   \n",
       "31                1              1          0.728077           0.870906   \n",
       "32                3              1          0.557402           0.551080   \n",
       "33                2              1          0.704451           0.686502   \n",
       "34                2              1          0.497566           0.333870   \n",
       "35                2              2          0.590970           0.631210   \n",
       "36                2              1          0.551878           0.591255   \n",
       "37                2              3          0.492811           0.333205   \n",
       "38                2              3          0.579154           0.513489   \n",
       "39                3              2          0.628457           0.303511   \n",
       "40                2              1          0.372673           0.421113   \n",
       "41                3              2          0.558852           0.491127   \n",
       "42                2              3          0.459679           0.483903   \n",
       "43                1              2          0.836282           0.771014   \n",
       "44                2              2          0.531311           0.572808   \n",
       "45                1              2          0.524843           0.485310   \n",
       "46                2              1          0.514872           0.545307   \n",
       "47                2              3          0.553947           0.558200   \n",
       "48                2              1          0.378422           0.352350   \n",
       "49                1              2          0.471513           0.548490   \n",
       "\n",
       "    sim_scores_qwen  \n",
       "0          0.500410  \n",
       "1          0.370163  \n",
       "2          0.644848  \n",
       "3          0.558227  \n",
       "4          0.400534  \n",
       "5          0.736253  \n",
       "6          0.644929  \n",
       "7          0.229979  \n",
       "8          0.662860  \n",
       "9          0.407397  \n",
       "10         0.767716  \n",
       "11         0.360994  \n",
       "12         0.518320  \n",
       "13         0.539866  \n",
       "14         0.555313  \n",
       "15         0.525280  \n",
       "16         0.845781  \n",
       "17         0.452113  \n",
       "18         0.725277  \n",
       "19         0.651296  \n",
       "20         0.079123  \n",
       "21         0.499232  \n",
       "22         0.739484  \n",
       "23         0.616513  \n",
       "24         0.429089  \n",
       "25         0.556720  \n",
       "26         0.612993  \n",
       "27         0.460076  \n",
       "28         0.383768  \n",
       "29         0.620428  \n",
       "30         0.291936  \n",
       "31         0.725184  \n",
       "32         0.622326  \n",
       "33         0.709938  \n",
       "34         0.301729  \n",
       "35         0.539666  \n",
       "36         0.668123  \n",
       "37         0.441351  \n",
       "38         0.621097  \n",
       "39         0.465351  \n",
       "40         0.362873  \n",
       "41         0.533643  \n",
       "42         0.510993  \n",
       "43         0.782000  \n",
       "44         0.539494  \n",
       "45         0.511644  \n",
       "46         0.594181  \n",
       "47         0.411620  \n",
       "48         0.383792  \n",
       "49         0.566462  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9e2c0233-d78d-4b7c-85b8-072fb4286b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос: Как осуществляется совместное обучение генератора и ретривера в RAG?\n",
      "\n",
      "Эталонный ответ: Модель обучается end-to-end, минимизируя отрицательный log-likelihood. Только query-encoder BERTq и BART обучаются, document-encoder BERTd и индекс остаются фиксированными\n",
      "\n",
      "Ответ Tbank: В RAG (Retrieval-Augmented Generation) обучение генератора и ретривера происходит совместно. Генератор (например, модель на основе T5 или BART) и система поиска (ретривер) работают вместе, чтобы улучшить качество генерации текста. Оба компонента проходят обучение на одном и том же наборе данных, что позволяет им адаптироваться и взаимодействовать для создания более точных и релевантных ответов.\n",
      "\n",
      "Ответ YandexGPT:  Оба генератора и ретривера в RAG обучаются совместно путём тонкой настройки на любой seq2seq задаче.\n",
      "\n",
      "Ответ Qwen: Совместное обучение генератора и ретривера в RAG осуществляется через минимизацию отрицательного маргинального логарифмического правдоподобия целевых выходов с использованием стохастического градиентного спуска, при этом документовый энкодер фиксируется, а только query энкодер и генератор подвергаются тонкой настройке.\n"
     ]
    }
   ],
   "source": [
    "n = 27\n",
    "str_question = df['Questions'].iloc[n]\n",
    "str_gt = df['gt'].iloc[n]\n",
    "str_tbank = df['Tbank'].iloc[n]\n",
    "str_yandex = df['YandexGPT'].iloc[n]\n",
    "str_qwen = df['Qwen3'].iloc[n]\n",
    "\n",
    "print(f'Вопрос: {str_question}\\n')\n",
    "print(f'Эталонный ответ: {str_gt}\\n')\n",
    "print(f'Ответ Tbank: {str_tbank}\\n')\n",
    "print(f'Ответ YandexGPT: {str_yandex}\\n')  \n",
    "print(f'Ответ Qwen: {str_qwen}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "98e15a03-d222-48b0-915b-3b754788bdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores [1-3] чем меньше тем лучше\n",
    "scores_tbank = [1, 1, 3, 3, 2, 3, 2, 1, 3, 1, 2, 2, 1, 3, 2, 3, 1, 2, 3, 1, 3, 3, 1, 1, 2, 3, 2, 3, 2, 3, 3, 2, 2, 3, 3, 1, 3, 1, 1, 1, 3, 1, 1, 3, 1, 3, 3, 1, 3, 3]\n",
    "scores_yandex = [2, 2, 2, 2, 3, 2, 3, 2, 2, 3, 3, 2, 3, 2, 1, 2, 2, 3, 2, 3, 3, 2, 2, 3, 3, 1, 1, 2, 3, 2, 3, 1, 3, 2, 2, 2, 2, 2, 2, 3, 2, 3, 2, 1, 2, 1, 2, 2, 2, 1]\n",
    "scores_qwen = [2, 3, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 2, 1, 3, 1, 3, 1, 1, 2, 3, 1, 3, 2, 1, 2, 3, 1, 1, 1, 3, 1, 1, 1, 1, 2, 1, 3, 3, 2, 1, 2, 3, 2, 2, 2, 1, 3, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "61a3e948-3756-47d8-8fbc-29a12469f1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gen_tbank_rank'] = scores_tbank\n",
    "df['gen_yandex_rank'] = scores_yandex\n",
    "df['gen_qwen_rank'] = scores_qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "e21908af-9e06-4313-af67-cb908bd290d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_results/article_questions_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcbb966-b597-4543-808c-3b3fc92c4a11",
   "metadata": {},
   "source": [
    "## Средний ранг генерации вопросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "0791362a-405f-42fe-b43e-4a948fdf06b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gen_qwen_rank      1.74\n",
       "gen_tbank_rank     2.10\n",
       "gen_yandex_rank    2.16\n",
       "dtype: float64"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['gen_tbank_rank', 'gen_yandex_rank', 'gen_qwen_rank']].mean().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fec62bc-d82c-4c83-968a-493b9705186a",
   "metadata": {},
   "source": [
    "# Bleu/Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "20c6faf2-7c25-4cec-8fc2-7b72bfa85f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('article_questions_all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74eb4113-4923-4dcc-bafb-805730c1d9e5",
   "metadata": {},
   "source": [
    "## Bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "28e5ae47-ee33-4f1e-a878-f90d6f31fe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps = df[\"Tbank\"].tolist()\n",
    "refs = df[\"gt\"].tolist()\n",
    "bleu = BLEU(tokenize=\"intl\", smooth_method=\"exp\", effective_order=True)   \n",
    "\n",
    "df[\"bleu_tbank\"] = [\n",
    "    bleu.sentence_score(h, [r]).score for h, r in zip(hyps, refs)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3b978ab2-d456-47da-8f1f-b7ac0bef1fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps = df[\"YandexGPT\"].tolist()\n",
    "refs = df[\"gt\"].tolist()\n",
    "bleu = BLEU(tokenize=\"intl\", smooth_method=\"exp\", effective_order=True)   \n",
    "\n",
    "df[\"bleu_yandex\"] = [\n",
    "    bleu.sentence_score(h, [r]).score for h, r in zip(hyps, refs)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "407eb22e-45f7-4335-8161-b457d8159b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps = df[\"Qwen3\"].tolist()\n",
    "refs = df[\"gt\"].tolist()\n",
    "bleu = BLEU(tokenize=\"intl\", smooth_method=\"exp\", effective_order=True)   \n",
    "\n",
    "df[\"bleu_qwen\"] = [\n",
    "    bleu.sentence_score(h, [r]).score for h, r in zip(hyps, refs)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6ef6bb92-4463-479d-b239-bc1a686c2933",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bleu_tbank</th>\n",
       "      <th>bleu_yandex</th>\n",
       "      <th>bleu_qwen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.515791</td>\n",
       "      <td>0.419478</td>\n",
       "      <td>1.273276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.078440</td>\n",
       "      <td>9.514054</td>\n",
       "      <td>0.004866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.934502</td>\n",
       "      <td>1.599418</td>\n",
       "      <td>4.461248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.641894</td>\n",
       "      <td>5.860751</td>\n",
       "      <td>2.088522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.968374</td>\n",
       "      <td>1.622934</td>\n",
       "      <td>1.433300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.973466</td>\n",
       "      <td>2.734225</td>\n",
       "      <td>16.723342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.769086</td>\n",
       "      <td>5.954583</td>\n",
       "      <td>8.624407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.597629</td>\n",
       "      <td>1.232214</td>\n",
       "      <td>1.232214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.053028</td>\n",
       "      <td>4.858588</td>\n",
       "      <td>3.759195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.058758</td>\n",
       "      <td>1.888475</td>\n",
       "      <td>1.959711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.046440</td>\n",
       "      <td>2.882751</td>\n",
       "      <td>6.175258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.572570</td>\n",
       "      <td>2.098443</td>\n",
       "      <td>1.282615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.331372</td>\n",
       "      <td>3.652946</td>\n",
       "      <td>4.759465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.107234</td>\n",
       "      <td>11.620840</td>\n",
       "      <td>2.698248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.244231</td>\n",
       "      <td>5.147634</td>\n",
       "      <td>1.598436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.903036</td>\n",
       "      <td>2.611789</td>\n",
       "      <td>2.653462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>19.605243</td>\n",
       "      <td>46.263026</td>\n",
       "      <td>49.817732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.347016</td>\n",
       "      <td>2.588505</td>\n",
       "      <td>4.841656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.695273</td>\n",
       "      <td>3.385715</td>\n",
       "      <td>5.654843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.641839</td>\n",
       "      <td>7.284771</td>\n",
       "      <td>5.497001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.163803</td>\n",
       "      <td>1.877081</td>\n",
       "      <td>0.347102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7.897881</td>\n",
       "      <td>1.641035</td>\n",
       "      <td>4.017860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.725598</td>\n",
       "      <td>5.592939</td>\n",
       "      <td>8.961071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13.803050</td>\n",
       "      <td>0.385039</td>\n",
       "      <td>3.882110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.788187</td>\n",
       "      <td>1.829853</td>\n",
       "      <td>3.392269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.540918</td>\n",
       "      <td>1.373789</td>\n",
       "      <td>4.370137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13.426459</td>\n",
       "      <td>14.339771</td>\n",
       "      <td>11.921786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.878115</td>\n",
       "      <td>1.260415</td>\n",
       "      <td>1.516715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.211034</td>\n",
       "      <td>1.595565</td>\n",
       "      <td>6.456767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.199765</td>\n",
       "      <td>4.566616</td>\n",
       "      <td>6.919283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.697133</td>\n",
       "      <td>1.389737</td>\n",
       "      <td>1.476394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3.758408</td>\n",
       "      <td>10.376363</td>\n",
       "      <td>5.901431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.768887</td>\n",
       "      <td>1.677324</td>\n",
       "      <td>1.320307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>7.242918</td>\n",
       "      <td>7.079890</td>\n",
       "      <td>8.965410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.604261</td>\n",
       "      <td>1.074702</td>\n",
       "      <td>0.976693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3.732735</td>\n",
       "      <td>8.539212</td>\n",
       "      <td>9.691103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.364234</td>\n",
       "      <td>2.357668</td>\n",
       "      <td>3.767411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3.734013</td>\n",
       "      <td>1.095208</td>\n",
       "      <td>4.814649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5.208769</td>\n",
       "      <td>5.796536</td>\n",
       "      <td>6.569174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.179732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.309316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>7.709809</td>\n",
       "      <td>5.507671</td>\n",
       "      <td>3.005981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1.652685</td>\n",
       "      <td>0.639627</td>\n",
       "      <td>0.639627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.500006</td>\n",
       "      <td>1.138323</td>\n",
       "      <td>1.062417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>5.948832</td>\n",
       "      <td>1.661792</td>\n",
       "      <td>2.475904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3.451698</td>\n",
       "      <td>3.007774</td>\n",
       "      <td>2.931465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.186051</td>\n",
       "      <td>1.273270</td>\n",
       "      <td>0.990009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1.547717</td>\n",
       "      <td>1.449134</td>\n",
       "      <td>3.653615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.508215</td>\n",
       "      <td>1.536177</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>3.784219</td>\n",
       "      <td>1.709260</td>\n",
       "      <td>3.173883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.934784</td>\n",
       "      <td>1.067016</td>\n",
       "      <td>0.983757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bleu_tbank  bleu_yandex  bleu_qwen\n",
       "0     3.515791     0.419478   1.273276\n",
       "1     4.078440     9.514054   0.004866\n",
       "2     1.934502     1.599418   4.461248\n",
       "3     2.641894     5.860751   2.088522\n",
       "4     0.968374     1.622934   1.433300\n",
       "5     0.973466     2.734225  16.723342\n",
       "6     3.769086     5.954583   8.624407\n",
       "7     0.597629     1.232214   1.232214\n",
       "8     1.053028     4.858588   3.759195\n",
       "9     2.058758     1.888475   1.959711\n",
       "10    3.046440     2.882751   6.175258\n",
       "11    1.572570     2.098443   1.282615\n",
       "12    2.331372     3.652946   4.759465\n",
       "13    7.107234    11.620840   2.698248\n",
       "14    3.244231     5.147634   1.598436\n",
       "15    1.903036     2.611789   2.653462\n",
       "16   19.605243    46.263026  49.817732\n",
       "17    6.347016     2.588505   4.841656\n",
       "18    4.695273     3.385715   5.654843\n",
       "19    5.641839     7.284771   5.497001\n",
       "20    1.163803     1.877081   0.347102\n",
       "21    7.897881     1.641035   4.017860\n",
       "22    2.725598     5.592939   8.961071\n",
       "23   13.803050     0.385039   3.882110\n",
       "24    1.788187     1.829853   3.392269\n",
       "25    2.540918     1.373789   4.370137\n",
       "26   13.426459    14.339771  11.921786\n",
       "27    0.878115     1.260415   1.516715\n",
       "28    1.211034     1.595565   6.456767\n",
       "29    3.199765     4.566616   6.919283\n",
       "30    0.697133     1.389737   1.476394\n",
       "31    3.758408    10.376363   5.901431\n",
       "32    0.768887     1.677324   1.320307\n",
       "33    7.242918     7.079890   8.965410\n",
       "34    0.604261     1.074702   0.976693\n",
       "35    3.732735     8.539212   9.691103\n",
       "36    1.364234     2.357668   3.767411\n",
       "37    3.734013     1.095208   4.814649\n",
       "38    5.208769     5.796536   6.569174\n",
       "39    1.179732     0.000000   1.309316\n",
       "40    7.709809     5.507671   3.005981\n",
       "41    1.652685     0.639627   0.639627\n",
       "42    1.500006     1.138323   1.062417\n",
       "43    5.948832     1.661792   2.475904\n",
       "44    3.451698     3.007774   2.931465\n",
       "45    1.186051     1.273270   0.990009\n",
       "46    1.547717     1.449134   3.653615\n",
       "47    0.508215     1.536177   0.000000\n",
       "48    3.784219     1.709260   3.173883\n",
       "49    0.934784     1.067016   0.983757"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['bleu_tbank', 'bleu_yandex', 'bleu_qwen']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ae45330a-b608-4994-bf00-5b65c171417e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bleu_tbank     3.644703\n",
       "bleu_yandex    4.321198\n",
       "bleu_qwen      4.840649\n",
       "dtype: float64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['bleu_tbank', 'bleu_yandex', 'bleu_qwen']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d640fd99-ecbb-4214-aa80-25efd99b1b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('article_questions_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75cad79-cfe9-46a9-8691-41a26e00297a",
   "metadata": {},
   "source": [
    "## Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0f048817-bb68-4c06-a90c-8a72e6eb48fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('article_questions_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0ffdd93d-d7de-4b5b-9751-a605282a2b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stem = SnowballStemmer(\"russian\")\n",
    "\n",
    "class RussianTok(tokenizers.Tokenizer):\n",
    "    _re = re.compile(r\"[а-яё]+\", re.I)\n",
    "    def tokenize(self, txt):\n",
    "        return [stem.stem(w) for w in self._re.findall(txt.lower())]\n",
    "\n",
    "ru_tok = RussianTok()\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(\n",
    "    [\"rouge1\", \"rouge2\", \"rougeL\"],\n",
    "    use_stemmer=False,          \n",
    "    tokenizer=ru_tok            # свой токенайзер\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "847de515-b9db-4732-bf30-c85fcbbbe854",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_scores = [\n",
    "    scorer.score(ref, hyp)          \n",
    "    for hyp, ref in zip(df[\"Tbank\"], df[\"gt\"])\n",
    "]\n",
    "\n",
    "df[\"rouge1_f_tbank\"] = [s[\"rouge1\"].fmeasure for s in pair_scores]\n",
    "df[\"rouge2_f_tbank\"] = [s[\"rouge2\"].fmeasure for s in pair_scores]\n",
    "df[\"rougeL_f_tbank\"] = [s[\"rougeL\"].fmeasure for s in pair_scores]\n",
    "\n",
    "df[\"rouge1_p_tbank\"] = [s[\"rouge1\"].precision for s in pair_scores]\n",
    "df[\"rouge2_p_tbank\"] = [s[\"rouge2\"].precision for s in pair_scores]\n",
    "df[\"rougeL_p_tbank\"] = [s[\"rougeL\"].precision for s in pair_scores]\n",
    "\n",
    "df[\"rouge1_r_tbank\"] = [s[\"rouge1\"].recall for s in pair_scores]\n",
    "df[\"rouge2_r_tbank\"] = [s[\"rouge2\"].recall for s in pair_scores]\n",
    "df[\"rougeL_r_tbank\"] = [s[\"rougeL\"].recall for s in pair_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4696bc2b-43f2-43df-994d-e66c4f4928ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_scores = [\n",
    "    scorer.score(ref, hyp)          \n",
    "    for hyp, ref in zip(df[\"YandexGPT\"], df[\"gt\"])\n",
    "]\n",
    "\n",
    "df[\"rouge1_f_yandex\"] = [s[\"rouge1\"].fmeasure for s in pair_scores]\n",
    "df[\"rouge2_f_yandex\"] = [s[\"rouge2\"].fmeasure for s in pair_scores]\n",
    "df[\"rougeL_f_yandex\"] = [s[\"rougeL\"].fmeasure for s in pair_scores]\n",
    "\n",
    "df[\"rouge1_p_yandex\"] = [s[\"rouge1\"].precision for s in pair_scores]\n",
    "df[\"rouge2_p_yandex\"] = [s[\"rouge2\"].precision for s in pair_scores]\n",
    "df[\"rougeL_p_yandex\"] = [s[\"rougeL\"].precision for s in pair_scores]\n",
    "\n",
    "df[\"rouge1_r_yandex\"] = [s[\"rouge1\"].recall for s in pair_scores]\n",
    "df[\"rouge2_r_yandex\"] = [s[\"rouge2\"].recall for s in pair_scores]\n",
    "df[\"rougeL_r_yandex\"] = [s[\"rougeL\"].recall for s in pair_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "67c4cf4b-56f7-43c6-8e64-5fe029fbdac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_scores = [\n",
    "    scorer.score(ref, hyp)          \n",
    "    for hyp, ref in zip(df[\"Qwen3\"], df[\"gt\"])\n",
    "]\n",
    "\n",
    "df[\"rouge1_f_qwen\"] = [s[\"rouge1\"].fmeasure for s in pair_scores]\n",
    "df[\"rouge2_f_qwen\"] = [s[\"rouge2\"].fmeasure for s in pair_scores]\n",
    "df[\"rougeL_f_qwen\"] = [s[\"rougeL\"].fmeasure for s in pair_scores]\n",
    "\n",
    "df[\"rouge1_p_qwen\"] = [s[\"rouge1\"].precision for s in pair_scores]\n",
    "df[\"rouge2_p_qwen\"] = [s[\"rouge2\"].precision for s in pair_scores]\n",
    "df[\"rougeL_p_qwen\"] = [s[\"rougeL\"].precision for s in pair_scores]\n",
    "\n",
    "df[\"rouge1_r_qwen\"] = [s[\"rouge1\"].recall for s in pair_scores]\n",
    "df[\"rouge2_r_qwen\"] = [s[\"rouge2\"].recall for s in pair_scores]\n",
    "df[\"rougeL_r_qwen\"] = [s[\"rougeL\"].recall for s in pair_scores]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9145e78a-9053-4b4d-ab24-911ba025ae44",
   "metadata": {},
   "source": [
    "### F-measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "02377b5e-f3be-4f8e-b590-4b0fb6450b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rouge1_f_tbank    0.206473\n",
       "rouge2_f_tbank    0.038891\n",
       "rougeL_f_tbank    0.154290\n",
       "dtype: float64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['rouge1_f_tbank', 'rouge2_f_tbank', 'rougeL_f_tbank']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9aeb71f8-d920-44fb-8a05-eab56d97e5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rouge1_f_yandex    0.223548\n",
       "rouge2_f_yandex    0.037516\n",
       "rougeL_f_yandex    0.184365\n",
       "dtype: float64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['rouge1_f_yandex', 'rouge2_f_yandex', 'rougeL_f_yandex']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6d9c983e-70ea-4ae6-be72-709bc46308aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rouge1_f_qwen    0.255723\n",
       "rouge2_f_qwen    0.072566\n",
       "rougeL_f_qwen    0.202847\n",
       "dtype: float64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['rouge1_f_qwen', 'rouge2_f_qwen', 'rougeL_f_qwen']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b4881c-7cc7-4123-b3d7-04b97f9c3d15",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "20cd8640-5853-4d05-ac9a-ab4baa22ef17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rouge1_p_tbank    0.151476\n",
       "rouge2_p_tbank    0.028680\n",
       "rougeL_p_tbank    0.112875\n",
       "dtype: float64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['rouge1_p_tbank', 'rouge2_p_tbank', 'rougeL_p_tbank']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0a643867-e470-4675-ac25-8b1683174e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rouge1_p_yandex    0.234096\n",
       "rouge2_p_yandex    0.039478\n",
       "rougeL_p_yandex    0.195566\n",
       "dtype: float64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['rouge1_p_yandex', 'rouge2_p_yandex', 'rougeL_p_yandex']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "85da5c9a-4314-4388-8c72-ad49822bd029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rouge1_p_qwen    0.267341\n",
       "rouge2_p_qwen    0.073784\n",
       "rougeL_p_qwen    0.211680\n",
       "dtype: float64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['rouge1_p_qwen', 'rouge2_p_qwen', 'rougeL_p_qwen']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70508955-b64a-4b26-b492-de3abe1a6a03",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "65e972eb-8457-4120-a3c6-e88cdc63fe3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rouge1_r_tbank    0.390185\n",
       "rouge2_r_tbank    0.071249\n",
       "rougeL_r_tbank    0.298839\n",
       "dtype: float64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['rouge1_r_tbank', 'rouge2_r_tbank', 'rougeL_r_tbank']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "94fef1cf-771c-43fd-9d86-b9b4cb4976ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rouge1_r_yandex    0.259862\n",
       "rouge2_r_yandex    0.039937\n",
       "rougeL_r_yandex    0.214634\n",
       "dtype: float64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['rouge1_r_yandex', 'rouge2_r_yandex', 'rougeL_r_yandex']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f9c8550a-8075-4a41-86b4-9da691f1fa3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rouge1_r_qwen    0.276396\n",
       "rouge2_r_qwen    0.076814\n",
       "rougeL_r_qwen    0.221734\n",
       "dtype: float64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['rouge1_r_qwen', 'rouge2_r_qwen', 'rougeL_r_qwen']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d4e99aa4-89ca-4443-9de1-1ec298f69950",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('article_questions_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586b54be-ef26-41aa-877b-f3fa33bff47a",
   "metadata": {},
   "source": [
    "## Cosine Similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "677496f2-565c-4f25-8b61-4d82c8473225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "# Загрузим SOTA эмбеддер для русских текстов\n",
    "embedder = SentenceTransformer(\"ai-forever/FRIDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "57e03800-3ff2-4be4-9a83-0d46b8d33a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen = pd.read_csv('test_results/article_questions_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "a94a7dce-a4c4-482b-a01c-c170a2c012b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>gt</th>\n",
       "      <th>Tbank</th>\n",
       "      <th>YandexGPT</th>\n",
       "      <th>Qwen3</th>\n",
       "      <th>gen_tbank_rank</th>\n",
       "      <th>gen_yandex_rank</th>\n",
       "      <th>gen_qwen_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Какой оптимайзер и гиперпараметры использовали...</td>\n",
       "      <td>В оригинальной статье использовался Adam с пар...</td>\n",
       "      <td>В данном контексте использовался оптимайзер Ad...</td>\n",
       "      <td>Мы использовали оптимизатор Adam с параметрам...</td>\n",
       "      <td>Оптимайзер — Adam, гиперпараметры: β₁ = 0.9, β...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Какие архитектурные компоненты заменяет Transf...</td>\n",
       "      <td>Transformer заменяет RNN или LSTM/GRU, использ...</td>\n",
       "      <td>В традиционных sequence-to-sequence моделях, т...</td>\n",
       "      <td>Transformer заменяет рекуррентные слои, наибо...</td>\n",
       "      <td>Рекуррентные слои.</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Что такое Scaled Dot-Product Attention и зачем...</td>\n",
       "      <td>Это механизм внимания, который вычисляет:\\nAtt...</td>\n",
       "      <td>Деление на √dk в Scaled Dot-Product Attention ...</td>\n",
       "      <td>Scaled Dot-Product Attention — это метод вним...</td>\n",
       "      <td>Scaled Dot-Product Attention — это механизм вн...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Как устроена структура encoder и decoder в Tra...</td>\n",
       "      <td>Encoder: N одинаковых блоков (обычно N=6), каж...</td>\n",
       "      <td>Структура Transformer состоит из двух основных...</td>\n",
       "      <td>Структура encoder и decoder в Transformer сос...</td>\n",
       "      <td>Encoder состоит из стека из 6 идентичных слоев...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Почему Multi-Head Attention улучшает производи...</td>\n",
       "      <td>Потому что каждая \"голова\" обучается фокусиров...</td>\n",
       "      <td>Multi-Head Attention улучшает производительнос...</td>\n",
       "      <td>Multi-head attention позволяет модели совмест...</td>\n",
       "      <td>Multi-Head Attention улучшает производительнос...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Questions  \\\n",
       "0  Какой оптимайзер и гиперпараметры использовали...   \n",
       "1  Какие архитектурные компоненты заменяет Transf...   \n",
       "2  Что такое Scaled Dot-Product Attention и зачем...   \n",
       "3  Как устроена структура encoder и decoder в Tra...   \n",
       "4  Почему Multi-Head Attention улучшает производи...   \n",
       "\n",
       "                                                  gt  \\\n",
       "0  В оригинальной статье использовался Adam с пар...   \n",
       "1  Transformer заменяет RNN или LSTM/GRU, использ...   \n",
       "2  Это механизм внимания, который вычисляет:\\nAtt...   \n",
       "3  Encoder: N одинаковых блоков (обычно N=6), каж...   \n",
       "4  Потому что каждая \"голова\" обучается фокусиров...   \n",
       "\n",
       "                                               Tbank  \\\n",
       "0  В данном контексте использовался оптимайзер Ad...   \n",
       "1  В традиционных sequence-to-sequence моделях, т...   \n",
       "2  Деление на √dk в Scaled Dot-Product Attention ...   \n",
       "3  Структура Transformer состоит из двух основных...   \n",
       "4  Multi-Head Attention улучшает производительнос...   \n",
       "\n",
       "                                           YandexGPT  \\\n",
       "0   Мы использовали оптимизатор Adam с параметрам...   \n",
       "1   Transformer заменяет рекуррентные слои, наибо...   \n",
       "2   Scaled Dot-Product Attention — это метод вним...   \n",
       "3   Структура encoder и decoder в Transformer сос...   \n",
       "4   Multi-head attention позволяет модели совмест...   \n",
       "\n",
       "                                               Qwen3  gen_tbank_rank  \\\n",
       "0  Оптимайзер — Adam, гиперпараметры: β₁ = 0.9, β...               1   \n",
       "1                                 Рекуррентные слои.               1   \n",
       "2  Scaled Dot-Product Attention — это механизм вн...               3   \n",
       "3  Encoder состоит из стека из 6 идентичных слоев...               3   \n",
       "4  Multi-Head Attention улучшает производительнос...               2   \n",
       "\n",
       "   gen_yandex_rank  gen_qwen_rank  \n",
       "0                2              2  \n",
       "1                2              3  \n",
       "2                2              1  \n",
       "3                2              1  \n",
       "4                3              1  "
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gen.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf5de68-6249-413d-875d-b599cf44d720",
   "metadata": {},
   "source": [
    "## Tbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "c5e77561-e68f-4289-90f8-1646a62d973c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_answers = df_gen['gt'].tolist()\n",
    "generated_answers = df_gen['Tbank'].tolist()\n",
    "questions = df['Questions'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "cc8a3a41-a166-4b31-b9b9-433ea09bbae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from typing import List, Dict\n",
    "\n",
    "def evaluate_similarity_frida(\n",
    "    questions: List[str], \n",
    "    generated_answers: List[str],\n",
    "    reference_answers: List[str]\n",
    ") -> List[float]:\n",
    "    \"\"\"\n",
    "    Вычисляет косинусную близость между сгенерированными и эталонными ответами\n",
    "    с помощью FRIDA SentenceTransformer.\n",
    "\n",
    "    :param questions: Список вопросов\n",
    "    :param generated_answers: Список ответов, сгенерированных LLM.\n",
    "    :param reference_answers: Список эталонных ответов.\n",
    "        \n",
    "    :return: Косинусная близость по каждой паре.\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = (\n",
    "        [f\"search_document: {text}\" for text in generated_answers] +\n",
    "        [f\"search_document: {text}\" for text in reference_answers]\n",
    "    )\n",
    "\n",
    "    embeddings = embedder.encode(inputs, convert_to_tensor=True)\n",
    "\n",
    "    gen_embs = embeddings[:len(generated_answers)]\n",
    "    ref_embs = embeddings[len(generated_answers):]\n",
    "\n",
    "    sim_scores = (gen_embs @ ref_embs.T).diagonal().tolist()\n",
    "    print(len(sim_scores))\n",
    "    for i, (question, generated, reference) in enumerate(zip(questions, generated_answers, reference_answers)):\n",
    "        \n",
    "        print(f\"Вопрос: {question}:\")\n",
    "        print(f\"cosine_similarity: {sim_scores[i]:.4f}\\n\")\n",
    "        print(100 * '*')\n",
    "\n",
    "    avg_sim = sum(sim_scores) / len(sim_scores)\n",
    "    print(\"\\nОбщая оценка\")\n",
    "    print(f\"Средний similarity: {avg_sim:.4f}\")\n",
    "    \n",
    "    return sim_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "e14a4e3e-c9fd-49ed-8769-30934c69450a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "Вопрос: Какой оптимайзер и гиперпараметры использовались в модели?:\n",
      "cosine_similarity: 0.6691\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие архитектурные компоненты заменяет Transformer в традиционных sequence-to-sequence моделях?:\n",
      "cosine_similarity: 0.6954\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Что такое Scaled Dot-Product Attention и зачем в нем используется деление на √dk?:\n",
      "cosine_similarity: 0.5031\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Как устроена структура encoder и decoder в Transformer?:\n",
      "cosine_similarity: 0.3556\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Почему Multi-Head Attention улучшает производительность по сравнению с одной головой внимания?:\n",
      "cosine_similarity: 0.4058\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие функции выполняют позиционные кодировки и почему были выбраны синусоиды?:\n",
      "cosine_similarity: 0.6022\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: В чем преимущества self-attention по сравнению с рекуррентными и сверточными слоями в плане вычислительной сложности и длины пути зависимостей?:\n",
      "cosine_similarity: 0.6200\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие техники регуляризации использовались при обучении Transformer?:\n",
      "cosine_similarity: 0.3429\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие результаты Transformer показал на задачах перевода EN→DE и EN→FR по сравнению с предыдущими SOTA?:\n",
      "cosine_similarity: 0.6723\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Почему Transformer позволяет более эффективную параллелизацию при обучении?:\n",
      "cosine_similarity: 0.3951\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: В чем заключается основная идея метода Test-Time Reinforcement Learning (TTRL)?:\n",
      "cosine_similarity: 0.8171\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Каким бразом осуществляется оценка вознаграждения в TTRL без доступа к истинным меткам?:\n",
      "cosine_similarity: 0.3202\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какую роль играет метод большинства голосов (majority voting) в архитектуре TTRL?:\n",
      "cosine_similarity: 0.4668\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие улучшения производительности были достигнуты с помощью TTRL на бенчмарке AIME 2024?:\n",
      "cosine_similarity: 0.5130\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Как TTRL сравнивается с RL на размеченных тестовых данных по эффективности?:\n",
      "cosine_similarity: 0.5275\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Почему TTRL способен работать даже при неточных оценках меток?:\n",
      "cosine_similarity: 0.5585\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие модели и бенчмарки использовались для оценки эффективности TTRL?:\n",
      "cosine_similarity: 0.6363\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие факторы могут привести к сбою или неэффективности TTRL?:\n",
      "cosine_similarity: 0.5314\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Как TTRL масштабируется при увеличении размера модели?:\n",
      "cosine_similarity: 0.7254\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: С какими алгоритмами обучения с подкреплением совместим TTRL и какие из них использовались в экспериментах?:\n",
      "cosine_similarity: 0.5551\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какая модель используется в качестве генератора в RAG?:\n",
      "cosine_similarity: 0.1882\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какая модель используется в качестве ретривера в RAG и как она инициализируется?:\n",
      "cosine_similarity: 0.5156\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Чем отличаются архитектуры RAG-Token и RAG-Sequence?:\n",
      "cosine_similarity: 0.6093\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какой объем документов используется в векторном индексе Wikipedia?:\n",
      "cosine_similarity: 0.6753\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие задачи были использованы для оценки RAG-моделей?:\n",
      "cosine_similarity: 0.3558\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Почему авторы считают генерацию предпочтительной по сравнению с извлечением при ответе на вопросы?:\n",
      "cosine_similarity: 0.6399\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какую производительность показал RAG на задаче Jeopardy Question Generation по сравнению с BART?:\n",
      "cosine_similarity: 0.6255\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Как осуществляется совместное обучение генератора и ретривера в RAG?:\n",
      "cosine_similarity: 0.3465\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какой эффект даёт \"hot-swapping\" индекса документов в RAG?:\n",
      "cosine_similarity: 0.3081\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие аппроксимации используются при декодировании в RAG-Sequence и RAG-Token?:\n",
      "cosine_similarity: 0.5692\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие две модели архитектур были предложены авторами для обучения векторных представлений слов?:\n",
      "cosine_similarity: 0.3074\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: В чём основное различие между архитектурами CBOW и Skip-gram?:\n",
      "cosine_similarity: 0.7281\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие типы отношений включены в Semantic-Syntactic Word Relationship test set?:\n",
      "cosine_similarity: 0.5574\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие значения точности показала модель Skip-gram на семантических и синтаксических подзадачах?:\n",
      "cosine_similarity: 0.7045\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какой подход используется в Skip-gram модели для выбора контекстных слов?:\n",
      "cosine_similarity: 0.4976\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какова формула вычислительной сложности модели CBOW?:\n",
      "cosine_similarity: 0.5910\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Почему авторы отказались от использования скрытого слоя в новых архитектурах?:\n",
      "cosine_similarity: 0.5519\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Как масштабировалась тренировка моделей в распределённой системе DistBelief?:\n",
      "cosine_similarity: 0.4928\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Как были сгенерированы вопросы в тестовом наборе для оценки word vectors?:\n",
      "cosine_similarity: 0.5792\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какой метод используется для ответа на аналогии вроде “king - man + woman = ?”?:\n",
      "cosine_similarity: 0.6285\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: В чём заключается ключевая идея фреймворка LADDER?:\n",
      "cosine_similarity: 0.3727\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какой метод используется для верификации правильности решений интегралов в LADDER?:\n",
      "cosine_similarity: 0.5589\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Как осуществляется генерация вариантов задач в LADDER?:\n",
      "cosine_similarity: 0.4597\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Что такое TTRL и чем он отличается от LADDER?:\n",
      "cosine_similarity: 0.8363\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие результаты достигнуты моделью Qwen2.5 7B на экзамене MIT Integration Bee после применения LADDER и TTRL?:\n",
      "cosine_similarity: 0.5313\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какая функция вознаграждения используется в GRPO в рамках обучения в LADDER?:\n",
      "cosine_similarity: 0.5248\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Почему RL без использования вариантов задач показывает плохие результаты на задачах интегрирования?:\n",
      "cosine_similarity: 0.5149\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие техники использовались для увеличения разнообразия генерируемых вариантов задач?:\n",
      "cosine_similarity: 0.5539\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Как LADDER масштабирует обучение без увеличения размера модели?:\n",
      "cosine_similarity: 0.3784\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие ограничения или сложности были замечены при генерации вариантов задач?:\n",
      "cosine_similarity: 0.4715\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "Общая оценка\n",
      "Средний similarity: 0.5317\n"
     ]
    }
   ],
   "source": [
    "scores_tbank = evaluate_similarity_frida(questions, generated_answers, reference_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "352f1b83-3ccc-40e7-ad67-9acc7b469f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen['sim_scores_tbank'] = scores_tbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "cade7006-f621-45c9-9e81-cda3025220d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>gt</th>\n",
       "      <th>Tbank</th>\n",
       "      <th>YandexGPT</th>\n",
       "      <th>Qwen3</th>\n",
       "      <th>gen_tbank_rank</th>\n",
       "      <th>gen_yandex_rank</th>\n",
       "      <th>gen_qwen_rank</th>\n",
       "      <th>sim_scores_tbank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Какой оптимайзер и гиперпараметры использовали...</td>\n",
       "      <td>В оригинальной статье использовался Adam с пар...</td>\n",
       "      <td>В данном контексте использовался оптимайзер Ad...</td>\n",
       "      <td>Мы использовали оптимизатор Adam с параметрам...</td>\n",
       "      <td>Оптимайзер — Adam, гиперпараметры: β₁ = 0.9, β...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.669123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Какие архитектурные компоненты заменяет Transf...</td>\n",
       "      <td>Transformer заменяет RNN или LSTM/GRU, использ...</td>\n",
       "      <td>В традиционных sequence-to-sequence моделях, т...</td>\n",
       "      <td>Transformer заменяет рекуррентные слои, наибо...</td>\n",
       "      <td>Рекуррентные слои.</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.695416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Что такое Scaled Dot-Product Attention и зачем...</td>\n",
       "      <td>Это механизм внимания, который вычисляет:\\nAtt...</td>\n",
       "      <td>Деление на √dk в Scaled Dot-Product Attention ...</td>\n",
       "      <td>Scaled Dot-Product Attention — это метод вним...</td>\n",
       "      <td>Scaled Dot-Product Attention — это механизм вн...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.503097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Как устроена структура encoder и decoder в Tra...</td>\n",
       "      <td>Encoder: N одинаковых блоков (обычно N=6), каж...</td>\n",
       "      <td>Структура Transformer состоит из двух основных...</td>\n",
       "      <td>Структура encoder и decoder в Transformer сос...</td>\n",
       "      <td>Encoder состоит из стека из 6 идентичных слоев...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.355634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Почему Multi-Head Attention улучшает производи...</td>\n",
       "      <td>Потому что каждая \"голова\" обучается фокусиров...</td>\n",
       "      <td>Multi-Head Attention улучшает производительнос...</td>\n",
       "      <td>Multi-head attention позволяет модели совмест...</td>\n",
       "      <td>Multi-Head Attention улучшает производительнос...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.405849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Questions  \\\n",
       "0  Какой оптимайзер и гиперпараметры использовали...   \n",
       "1  Какие архитектурные компоненты заменяет Transf...   \n",
       "2  Что такое Scaled Dot-Product Attention и зачем...   \n",
       "3  Как устроена структура encoder и decoder в Tra...   \n",
       "4  Почему Multi-Head Attention улучшает производи...   \n",
       "\n",
       "                                                  gt  \\\n",
       "0  В оригинальной статье использовался Adam с пар...   \n",
       "1  Transformer заменяет RNN или LSTM/GRU, использ...   \n",
       "2  Это механизм внимания, который вычисляет:\\nAtt...   \n",
       "3  Encoder: N одинаковых блоков (обычно N=6), каж...   \n",
       "4  Потому что каждая \"голова\" обучается фокусиров...   \n",
       "\n",
       "                                               Tbank  \\\n",
       "0  В данном контексте использовался оптимайзер Ad...   \n",
       "1  В традиционных sequence-to-sequence моделях, т...   \n",
       "2  Деление на √dk в Scaled Dot-Product Attention ...   \n",
       "3  Структура Transformer состоит из двух основных...   \n",
       "4  Multi-Head Attention улучшает производительнос...   \n",
       "\n",
       "                                           YandexGPT  \\\n",
       "0   Мы использовали оптимизатор Adam с параметрам...   \n",
       "1   Transformer заменяет рекуррентные слои, наибо...   \n",
       "2   Scaled Dot-Product Attention — это метод вним...   \n",
       "3   Структура encoder и decoder в Transformer сос...   \n",
       "4   Multi-head attention позволяет модели совмест...   \n",
       "\n",
       "                                               Qwen3  gen_tbank_rank  \\\n",
       "0  Оптимайзер — Adam, гиперпараметры: β₁ = 0.9, β...               1   \n",
       "1                                 Рекуррентные слои.               1   \n",
       "2  Scaled Dot-Product Attention — это механизм вн...               3   \n",
       "3  Encoder состоит из стека из 6 идентичных слоев...               3   \n",
       "4  Multi-Head Attention улучшает производительнос...               2   \n",
       "\n",
       "   gen_yandex_rank  gen_qwen_rank  sim_scores_tbank  \n",
       "0                2              2          0.669123  \n",
       "1                2              3          0.695416  \n",
       "2                2              1          0.503097  \n",
       "3                2              1          0.355634  \n",
       "4                3              1          0.405849  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gen.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a50481-e82d-40e6-bc50-2b92fffad260",
   "metadata": {},
   "source": [
    "## Yandex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "65e1fbea-74b0-4503-8543-d4d4eedc4844",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_answers = df_gen['gt'].tolist()\n",
    "generated_answers = df_gen['YandexGPT'].tolist()\n",
    "questions = df['Questions'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "4335b294-83cc-40ab-9d2d-cf5e0429fc5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "Вопрос: Какой оптимайзер и гиперпараметры использовались в модели?:\n",
      "cosine_similarity: 0.5701\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие архитектурные компоненты заменяет Transformer в традиционных sequence-to-sequence моделях?:\n",
      "cosine_similarity: 0.7699\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Что такое Scaled Dot-Product Attention и зачем в нем используется деление на √dk?:\n",
      "cosine_similarity: 0.5582\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Как устроена структура encoder и decoder в Transformer?:\n",
      "cosine_similarity: 0.4156\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Почему Multi-Head Attention улучшает производительность по сравнению с одной головой внимания?:\n",
      "cosine_similarity: 0.3777\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие функции выполняют позиционные кодировки и почему были выбраны синусоиды?:\n",
      "cosine_similarity: 0.7094\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: В чем преимущества self-attention по сравнению с рекуррентными и сверточными слоями в плане вычислительной сложности и длины пути зависимостей?:\n",
      "cosine_similarity: 0.5773\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие техники регуляризации использовались при обучении Transformer?:\n",
      "cosine_similarity: 0.2248\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие результаты Transformer показал на задачах перевода EN→DE и EN→FR по сравнению с предыдущими SOTA?:\n",
      "cosine_similarity: 0.6626\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Почему Transformer позволяет более эффективную параллелизацию при обучении?:\n",
      "cosine_similarity: 0.3228\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: В чем заключается основная идея метода Test-Time Reinforcement Learning (TTRL)?:\n",
      "cosine_similarity: 0.7539\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Каким бразом осуществляется оценка вознаграждения в TTRL без доступа к истинным меткам?:\n",
      "cosine_similarity: 0.3444\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какую роль играет метод большинства голосов (majority voting) в архитектуре TTRL?:\n",
      "cosine_similarity: 0.4497\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие улучшения производительности были достигнуты с помощью TTRL на бенчмарке AIME 2024?:\n",
      "cosine_similarity: 0.6780\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Как TTRL сравнивается с RL на размеченных тестовых данных по эффективности?:\n",
      "cosine_similarity: 0.6178\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Почему TTRL способен работать даже при неточных оценках меток?:\n",
      "cosine_similarity: 0.6549\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие модели и бенчмарки использовались для оценки эффективности TTRL?:\n",
      "cosine_similarity: 0.6638\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие факторы могут привести к сбою или неэффективности TTRL?:\n",
      "cosine_similarity: 0.4467\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Как TTRL масштабируется при увеличении размера модели?:\n",
      "cosine_similarity: 0.7521\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: С какими алгоритмами обучения с подкреплением совместим TTRL и какие из них использовались в экспериментах?:\n",
      "cosine_similarity: 0.5634\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какая модель используется в качестве генератора в RAG?:\n",
      "cosine_similarity: 0.2617\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какая модель используется в качестве ретривера в RAG и как она инициализируется?:\n",
      "cosine_similarity: 0.3821\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Чем отличаются архитектуры RAG-Token и RAG-Sequence?:\n",
      "cosine_similarity: 0.6045\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какой объем документов используется в векторном индексе Wikipedia?:\n",
      "cosine_similarity: 0.6177\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие задачи были использованы для оценки RAG-моделей?:\n",
      "cosine_similarity: 0.3269\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Почему авторы считают генерацию предпочтительной по сравнению с извлечением при ответе на вопросы?:\n",
      "cosine_similarity: 0.5534\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какую производительность показал RAG на задаче Jeopardy Question Generation по сравнению с BART?:\n",
      "cosine_similarity: 0.8300\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Как осуществляется совместное обучение генератора и ретривера в RAG?:\n",
      "cosine_similarity: 0.3258\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какой эффект даёт \"hot-swapping\" индекса документов в RAG?:\n",
      "cosine_similarity: 0.3812\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие аппроксимации используются при декодировании в RAG-Sequence и RAG-Token?:\n",
      "cosine_similarity: 0.5704\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие две модели архитектур были предложены авторами для обучения векторных представлений слов?:\n",
      "cosine_similarity: 0.2979\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: В чём основное различие между архитектурами CBOW и Skip-gram?:\n",
      "cosine_similarity: 0.8709\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие типы отношений включены в Semantic-Syntactic Word Relationship test set?:\n",
      "cosine_similarity: 0.5511\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие значения точности показала модель Skip-gram на семантических и синтаксических подзадачах?:\n",
      "cosine_similarity: 0.6865\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какой подход используется в Skip-gram модели для выбора контекстных слов?:\n",
      "cosine_similarity: 0.3339\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какова формула вычислительной сложности модели CBOW?:\n",
      "cosine_similarity: 0.6312\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Почему авторы отказались от использования скрытого слоя в новых архитектурах?:\n",
      "cosine_similarity: 0.5913\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Как масштабировалась тренировка моделей в распределённой системе DistBelief?:\n",
      "cosine_similarity: 0.3332\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Как были сгенерированы вопросы в тестовом наборе для оценки word vectors?:\n",
      "cosine_similarity: 0.5135\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какой метод используется для ответа на аналогии вроде “king - man + woman = ?”?:\n",
      "cosine_similarity: 0.3035\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: В чём заключается ключевая идея фреймворка LADDER?:\n",
      "cosine_similarity: 0.4211\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какой метод используется для верификации правильности решений интегралов в LADDER?:\n",
      "cosine_similarity: 0.4911\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Как осуществляется генерация вариантов задач в LADDER?:\n",
      "cosine_similarity: 0.4839\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Что такое TTRL и чем он отличается от LADDER?:\n",
      "cosine_similarity: 0.7710\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие результаты достигнуты моделью Qwen2.5 7B на экзамене MIT Integration Bee после применения LADDER и TTRL?:\n",
      "cosine_similarity: 0.5728\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какая функция вознаграждения используется в GRPO в рамках обучения в LADDER?:\n",
      "cosine_similarity: 0.4853\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Почему RL без использования вариантов задач показывает плохие результаты на задачах интегрирования?:\n",
      "cosine_similarity: 0.5453\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие техники использовались для увеличения разнообразия генерируемых вариантов задач?:\n",
      "cosine_similarity: 0.5582\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Как LADDER масштабирует обучение без увеличения размера модели?:\n",
      "cosine_similarity: 0.3523\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие ограничения или сложности были замечены при генерации вариантов задач?:\n",
      "cosine_similarity: 0.5485\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "Общая оценка\n",
      "Средний similarity: 0.5262\n"
     ]
    }
   ],
   "source": [
    "scores_yandex = evaluate_similarity_frida(questions, generated_answers, reference_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "1630dd2a-38f7-43a8-808a-8375695398b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen['sim_scores_yandex'] = scores_yandex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46be01a8-4255-4e6e-b714-75ab10e025d6",
   "metadata": {},
   "source": [
    "## Qwen3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "e3d09e62-300f-44f5-8b5a-512377837cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_answers = df_gen['gt'].tolist()\n",
    "generated_answers = df_gen['Qwen3'].tolist()\n",
    "questions = df['Questions'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "cea016db-d5ce-42d0-898e-39b98528fbd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "Вопрос: Какой оптимайзер и гиперпараметры использовались в модели?:\n",
      "cosine_similarity: 0.5004\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие архитектурные компоненты заменяет Transformer в традиционных sequence-to-sequence моделях?:\n",
      "cosine_similarity: 0.3702\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Что такое Scaled Dot-Product Attention и зачем в нем используется деление на √dk?:\n",
      "cosine_similarity: 0.6448\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Как устроена структура encoder и decoder в Transformer?:\n",
      "cosine_similarity: 0.5582\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Почему Multi-Head Attention улучшает производительность по сравнению с одной головой внимания?:\n",
      "cosine_similarity: 0.4005\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие функции выполняют позиционные кодировки и почему были выбраны синусоиды?:\n",
      "cosine_similarity: 0.7363\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: В чем преимущества self-attention по сравнению с рекуррентными и сверточными слоями в плане вычислительной сложности и длины пути зависимостей?:\n",
      "cosine_similarity: 0.6449\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие техники регуляризации использовались при обучении Transformer?:\n",
      "cosine_similarity: 0.2300\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие результаты Transformer показал на задачах перевода EN→DE и EN→FR по сравнению с предыдущими SOTA?:\n",
      "cosine_similarity: 0.6629\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Почему Transformer позволяет более эффективную параллелизацию при обучении?:\n",
      "cosine_similarity: 0.4074\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: В чем заключается основная идея метода Test-Time Reinforcement Learning (TTRL)?:\n",
      "cosine_similarity: 0.7677\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Каким бразом осуществляется оценка вознаграждения в TTRL без доступа к истинным меткам?:\n",
      "cosine_similarity: 0.3610\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какую роль играет метод большинства голосов (majority voting) в архитектуре TTRL?:\n",
      "cosine_similarity: 0.5183\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие улучшения производительности были достигнуты с помощью TTRL на бенчмарке AIME 2024?:\n",
      "cosine_similarity: 0.5399\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Как TTRL сравнивается с RL на размеченных тестовых данных по эффективности?:\n",
      "cosine_similarity: 0.5553\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Почему TTRL способен работать даже при неточных оценках меток?:\n",
      "cosine_similarity: 0.5253\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие модели и бенчмарки использовались для оценки эффективности TTRL?:\n",
      "cosine_similarity: 0.8458\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие факторы могут привести к сбою или неэффективности TTRL?:\n",
      "cosine_similarity: 0.4521\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Как TTRL масштабируется при увеличении размера модели?:\n",
      "cosine_similarity: 0.7253\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: С какими алгоритмами обучения с подкреплением совместим TTRL и какие из них использовались в экспериментах?:\n",
      "cosine_similarity: 0.6513\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какая модель используется в качестве генератора в RAG?:\n",
      "cosine_similarity: 0.0791\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какая модель используется в качестве ретривера в RAG и как она инициализируется?:\n",
      "cosine_similarity: 0.4992\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Чем отличаются архитектуры RAG-Token и RAG-Sequence?:\n",
      "cosine_similarity: 0.7395\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какой объем документов используется в векторном индексе Wikipedia?:\n",
      "cosine_similarity: 0.6165\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие задачи были использованы для оценки RAG-моделей?:\n",
      "cosine_similarity: 0.4291\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Почему авторы считают генерацию предпочтительной по сравнению с извлечением при ответе на вопросы?:\n",
      "cosine_similarity: 0.5567\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какую производительность показал RAG на задаче Jeopardy Question Generation по сравнению с BART?:\n",
      "cosine_similarity: 0.6130\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Как осуществляется совместное обучение генератора и ретривера в RAG?:\n",
      "cosine_similarity: 0.4601\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какой эффект даёт \"hot-swapping\" индекса документов в RAG?:\n",
      "cosine_similarity: 0.3838\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие аппроксимации используются при декодировании в RAG-Sequence и RAG-Token?:\n",
      "cosine_similarity: 0.6204\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие две модели архитектур были предложены авторами для обучения векторных представлений слов?:\n",
      "cosine_similarity: 0.2919\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: В чём основное различие между архитектурами CBOW и Skip-gram?:\n",
      "cosine_similarity: 0.7252\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие типы отношений включены в Semantic-Syntactic Word Relationship test set?:\n",
      "cosine_similarity: 0.6223\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие значения точности показала модель Skip-gram на семантических и синтаксических подзадачах?:\n",
      "cosine_similarity: 0.7099\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какой подход используется в Skip-gram модели для выбора контекстных слов?:\n",
      "cosine_similarity: 0.3017\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какова формула вычислительной сложности модели CBOW?:\n",
      "cosine_similarity: 0.5397\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Почему авторы отказались от использования скрытого слоя в новых архитектурах?:\n",
      "cosine_similarity: 0.6681\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Как масштабировалась тренировка моделей в распределённой системе DistBelief?:\n",
      "cosine_similarity: 0.4414\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Как были сгенерированы вопросы в тестовом наборе для оценки word vectors?:\n",
      "cosine_similarity: 0.6211\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какой метод используется для ответа на аналогии вроде “king - man + woman = ?”?:\n",
      "cosine_similarity: 0.4654\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: В чём заключается ключевая идея фреймворка LADDER?:\n",
      "cosine_similarity: 0.3629\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какой метод используется для верификации правильности решений интегралов в LADDER?:\n",
      "cosine_similarity: 0.5336\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Как осуществляется генерация вариантов задач в LADDER?:\n",
      "cosine_similarity: 0.5110\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Что такое TTRL и чем он отличается от LADDER?:\n",
      "cosine_similarity: 0.7820\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие результаты достигнуты моделью Qwen2.5 7B на экзамене MIT Integration Bee после применения LADDER и TTRL?:\n",
      "cosine_similarity: 0.5395\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какая функция вознаграждения используется в GRPO в рамках обучения в LADDER?:\n",
      "cosine_similarity: 0.5116\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Почему RL без использования вариантов задач показывает плохие результаты на задачах интегрирования?:\n",
      "cosine_similarity: 0.5942\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие техники использовались для увеличения разнообразия генерируемых вариантов задач?:\n",
      "cosine_similarity: 0.4116\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Как LADDER масштабирует обучение без увеличения размера модели?:\n",
      "cosine_similarity: 0.3838\n",
      "\n",
      "****************************************************************************************************\n",
      "Вопрос: Какие ограничения или сложности были замечены при генерации вариантов задач?:\n",
      "cosine_similarity: 0.5665\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "Общая оценка\n",
      "Средний similarity: 0.5336\n"
     ]
    }
   ],
   "source": [
    "scores_qwen = evaluate_similarity_frida(questions, generated_answers, reference_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "e4fed998-f5f2-48e8-81c3-4545e88d65c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen['sim_scores_qwen'] = scores_qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "be4976ea-9a4e-4e85-b83b-dcb59d875763",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gen.to_csv('test_results/article_questions_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c84478-983c-47e6-ad55-b316875d316b",
   "metadata": {},
   "source": [
    "# Средние sim_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "68e282e7-1a8b-4a6e-b201-df32ec8a4336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sim_scores_qwen      0.533568\n",
       "sim_scores_tbank     0.531741\n",
       "sim_scores_yandex    0.526195\n",
       "dtype: float64"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gen[['sim_scores_tbank', 'sim_scores_yandex', 'sim_scores_qwen']].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37eeb04c-d940-4a36-b735-ddda10a4c314",
   "metadata": {},
   "source": [
    "# Средние ранги на основе similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "51609a98-36fe-485e-b749-7c0a6063b6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked = df_gen[['sim_scores_tbank', 'sim_scores_yandex', 'sim_scores_qwen']].rank(axis=1, method='min', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "f1448c7a-eba9-4d8b-9f9b-80235ffddb01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sim_scores_qwen      1.82\n",
       "sim_scores_tbank     1.98\n",
       "sim_scores_yandex    2.20\n",
       "dtype: float64"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked.mean().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6470d7-d0f8-4011-bd47-ff353ace1145",
   "metadata": {},
   "source": [
    "# Средние ранги на основе собственной проверки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "d90f3dcb-2609-4d19-9d29-0a6c55d24c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gen_qwen_rank      1.74\n",
       "gen_tbank_rank     2.10\n",
       "gen_yandex_rank    2.16\n",
       "dtype: float64"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gen[['gen_tbank_rank', 'gen_yandex_rank', 'gen_qwen_rank']].mean().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870886f9-faf6-4750-92ab-7ba3c2dc2598",
   "metadata": {},
   "source": [
    "# Соберем все результаты в одну таблицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "bc32fc43-40a6-4660-a530-3652b401a038",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "9276f330-257c-4c0d-93c9-88750cb20ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = ['YandexGPT 5', 'T-Lite', 'Qwen 3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "d718236e-3962-4e0e-8222-dea37d939fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Средний ранг на основе оценки Gpt4o (суммаризация) (10 статей)'] = [2.1, 2.2, 1.7]\n",
    "df['Средний ранг на основе косинусной близости (суммаризация) (10 статей)'] = [2.0, 2.3, 1.7]\n",
    "\n",
    "df['Средний ранг на основе оценки Gpt4o (генерация ответов) (50 вопросов)'] = [2.16, 2.1, 1.74]\n",
    "df['Средний ранг на основе косинусной близости (генерация ответов) (50 вопросов)'] = [2.2, 1.98, 1.82]\n",
    "\n",
    "df['Среднее время инференса (суммаризация) (10 статей)'] = [12, 15, 17]\n",
    "df['Среднее время инференса (генерация ответов) (50 вопросов)'] = [4.2, 8.5, 7.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "85937150-1008-464f-9a52-acd668e68fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Средний ранг на основе оценки Gpt4o (суммаризация) (10 статей)</th>\n",
       "      <th>Средний ранг на основе косинусной близости (суммаризация) (10 статей)</th>\n",
       "      <th>Средний ранг на основе оценки Gpt4o (генерация ответов) (50 вопросов)</th>\n",
       "      <th>Средний ранг на основе косинусной близости (генерация ответов) (50 вопросов)</th>\n",
       "      <th>Среднее время инференса (суммаризация) (10 статей)</th>\n",
       "      <th>Среднее время инференса (генерация ответов) (50 вопросов)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>YandexGPT 5</th>\n",
       "      <td>2.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.20</td>\n",
       "      <td>12</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-Lite</th>\n",
       "      <td>2.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.98</td>\n",
       "      <td>15</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qwen 3</th>\n",
       "      <td>1.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.82</td>\n",
       "      <td>17</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Средний ранг на основе оценки Gpt4o (суммаризация) (10 статей)  \\\n",
       "YandexGPT 5                                                2.1                \n",
       "T-Lite                                                     2.2                \n",
       "Qwen 3                                                     1.7                \n",
       "\n",
       "             Средний ранг на основе косинусной близости (суммаризация) (10 статей)  \\\n",
       "YandexGPT 5                                                2.0                       \n",
       "T-Lite                                                     2.3                       \n",
       "Qwen 3                                                     1.7                       \n",
       "\n",
       "             Средний ранг на основе оценки Gpt4o (генерация ответов) (50 вопросов)  \\\n",
       "YandexGPT 5                                               2.16                       \n",
       "T-Lite                                                    2.10                       \n",
       "Qwen 3                                                    1.74                       \n",
       "\n",
       "             Средний ранг на основе косинусной близости (генерация ответов) (50 вопросов)  \\\n",
       "YandexGPT 5                                               2.20                              \n",
       "T-Lite                                                    1.98                              \n",
       "Qwen 3                                                    1.82                              \n",
       "\n",
       "             Среднее время инференса (суммаризация) (10 статей)  \\\n",
       "YandexGPT 5                                                 12    \n",
       "T-Lite                                                      15    \n",
       "Qwen 3                                                      17    \n",
       "\n",
       "             Среднее время инференса (генерация ответов) (50 вопросов)  \n",
       "YandexGPT 5                                                4.2          \n",
       "T-Lite                                                     8.5          \n",
       "Qwen 3                                                     7.7          "
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "54f7bdb2-ac54-4b20-ac4d-0ed11fa10c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_results/agg_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
